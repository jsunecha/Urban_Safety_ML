{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "from skorch import NeuralNetClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "import folium\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"San_Francisco.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and preprocess data\n",
    "\n",
    "\n",
    "data[\"Time\"] = pd.to_datetime(data[\"Time\"]).astype(int) / 10**9\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "data[\"Category\"] = encoder.fit_transform(data[\"Category\"])\n",
    "data[\"Part_of_Day\"] = encoder.fit_transform(data[\"Part_of_Day\"])\n",
    "data[\"Day_of_Week\"] = encoder.fit_transform(data[\"Day_of_Week\"])\n",
    "\n",
    "#Drop date\n",
    "data.drop([\"Date\"], axis=1, inplace=True)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "data[[\"Time\", \"Day_of_Week\", \"Part_of_Day\", \"Latitude\", \"Longitude\"]] = scaler.fit_transform(\n",
    "    data[[\"Time\", \"Day_of_Week\", \"Part_of_Day\",\"Latitude\", \"Longitude\"]]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare dataset and dataloader\n",
    "class CrimeDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if idx >= len(self.data):\n",
    "            raise IndexError\n",
    "        features = torch.tensor(\n",
    "            self.data.loc[idx, ['Time','Day_of_Week','Part_of_Day','Latitude','Longitude']].values, dtype=torch.float\n",
    "        )\n",
    "        label = torch.tensor(self.data.loc[idx, 'Category'], dtype=torch.long)\n",
    "        return features, label\n",
    "\n",
    "\n",
    "dataset = CrimeDataset(data)\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "# Split dataset into train and test sets\n",
    "train_data, test_data = train_test_split(data, test_size=0.2, random_state=42)\n",
    "\n",
    "train_data = train_data.reset_index(drop=True)\n",
    "test_data = test_data.reset_index(drop=True)\n",
    "\n",
    "train_dataset = CrimeDataset(train_data)\n",
    "test_dataset = CrimeDataset(test_data)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Feedforward Neural Network\n",
    "class CrimeNet(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(CrimeNet, self).__init__()\n",
    "        self.layer1 = nn.Linear(input_size, hidden_size)\n",
    "        self.layer2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.layer3 = nn.Linear(hidden_size, num_classes)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.layer3(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "# Model parameters\n",
    "input_size = 5\n",
    "hidden_size = 32\n",
    "num_classes = len(data[\"Category\"].unique())\n",
    "\n",
    "# Initialize model, loss function, and optimizer\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model = CrimeNet(input_size, hidden_size, num_classes).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Step [100/24597], Loss: 1.6020\n",
      "Epoch [1/100], Step [200/24597], Loss: 1.7564\n",
      "Epoch [1/100], Step [300/24597], Loss: 1.8460\n",
      "Epoch [1/100], Step [400/24597], Loss: 1.6827\n",
      "Epoch [1/100], Step [500/24597], Loss: 1.6968\n",
      "Epoch [1/100], Step [600/24597], Loss: 1.7034\n",
      "Epoch [1/100], Step [700/24597], Loss: 1.7645\n",
      "Epoch [1/100], Step [800/24597], Loss: 1.7325\n",
      "Epoch [1/100], Step [900/24597], Loss: 1.5281\n",
      "Epoch [1/100], Step [1000/24597], Loss: 1.6017\n",
      "Epoch [1/100], Step [1100/24597], Loss: 1.6606\n",
      "Epoch [1/100], Step [1200/24597], Loss: 1.5338\n",
      "Epoch [1/100], Step [1300/24597], Loss: 1.8715\n",
      "Epoch [1/100], Step [1400/24597], Loss: 1.7230\n",
      "Epoch [1/100], Step [1500/24597], Loss: 1.6083\n",
      "Epoch [1/100], Step [1600/24597], Loss: 1.4874\n",
      "Epoch [1/100], Step [1700/24597], Loss: 1.7606\n",
      "Epoch [1/100], Step [1800/24597], Loss: 1.6171\n",
      "Epoch [1/100], Step [1900/24597], Loss: 1.5824\n",
      "Epoch [1/100], Step [2000/24597], Loss: 1.8462\n",
      "Epoch [1/100], Step [2100/24597], Loss: 1.6694\n",
      "Epoch [1/100], Step [2200/24597], Loss: 1.5884\n",
      "Epoch [1/100], Step [2300/24597], Loss: 1.6941\n",
      "Epoch [1/100], Step [2400/24597], Loss: 1.7051\n",
      "Epoch [1/100], Step [2500/24597], Loss: 1.7468\n",
      "Epoch [1/100], Step [2600/24597], Loss: 1.6957\n",
      "Epoch [1/100], Step [2700/24597], Loss: 1.7269\n",
      "Epoch [1/100], Step [2800/24597], Loss: 1.8762\n",
      "Epoch [1/100], Step [2900/24597], Loss: 1.8186\n",
      "Epoch [1/100], Step [3000/24597], Loss: 1.5870\n",
      "Epoch [1/100], Step [3100/24597], Loss: 1.6204\n",
      "Epoch [1/100], Step [3200/24597], Loss: 1.8112\n",
      "Epoch [1/100], Step [3300/24597], Loss: 1.6833\n",
      "Epoch [1/100], Step [3400/24597], Loss: 1.7560\n",
      "Epoch [1/100], Step [3500/24597], Loss: 1.7842\n",
      "Epoch [1/100], Step [3600/24597], Loss: 1.7639\n",
      "Epoch [1/100], Step [3700/24597], Loss: 1.5479\n",
      "Epoch [1/100], Step [3800/24597], Loss: 1.6665\n",
      "Epoch [1/100], Step [3900/24597], Loss: 1.5735\n",
      "Epoch [1/100], Step [4000/24597], Loss: 1.6954\n",
      "Epoch [1/100], Step [4100/24597], Loss: 1.5792\n",
      "Epoch [1/100], Step [4200/24597], Loss: 1.6099\n",
      "Epoch [1/100], Step [4300/24597], Loss: 1.5390\n",
      "Epoch [1/100], Step [4400/24597], Loss: 1.6829\n",
      "Epoch [1/100], Step [4500/24597], Loss: 1.8361\n",
      "Epoch [1/100], Step [4600/24597], Loss: 1.7719\n",
      "Epoch [1/100], Step [4700/24597], Loss: 1.6017\n",
      "Epoch [1/100], Step [4800/24597], Loss: 1.6188\n",
      "Epoch [1/100], Step [4900/24597], Loss: 1.5826\n",
      "Epoch [1/100], Step [5000/24597], Loss: 1.6401\n",
      "Epoch [1/100], Step [5100/24597], Loss: 1.6256\n",
      "Epoch [1/100], Step [5200/24597], Loss: 1.6515\n",
      "Epoch [1/100], Step [5300/24597], Loss: 1.8895\n",
      "Epoch [1/100], Step [5400/24597], Loss: 1.6601\n",
      "Epoch [1/100], Step [5500/24597], Loss: 1.7979\n",
      "Epoch [1/100], Step [5600/24597], Loss: 1.7232\n",
      "Epoch [1/100], Step [5700/24597], Loss: 1.6710\n",
      "Epoch [1/100], Step [5800/24597], Loss: 1.7133\n",
      "Epoch [1/100], Step [5900/24597], Loss: 1.4558\n",
      "Epoch [1/100], Step [6000/24597], Loss: 1.5060\n",
      "Epoch [1/100], Step [6100/24597], Loss: 1.7524\n",
      "Epoch [1/100], Step [6200/24597], Loss: 1.5870\n",
      "Epoch [1/100], Step [6300/24597], Loss: 1.6284\n",
      "Epoch [1/100], Step [6400/24597], Loss: 1.8259\n",
      "Epoch [1/100], Step [6500/24597], Loss: 1.5738\n",
      "Epoch [1/100], Step [6600/24597], Loss: 1.6258\n",
      "Epoch [1/100], Step [6700/24597], Loss: 1.8936\n",
      "Epoch [1/100], Step [6800/24597], Loss: 1.7267\n",
      "Epoch [1/100], Step [6900/24597], Loss: 1.5498\n",
      "Epoch [1/100], Step [7000/24597], Loss: 1.5016\n",
      "Epoch [1/100], Step [7100/24597], Loss: 1.6357\n",
      "Epoch [1/100], Step [7200/24597], Loss: 1.6764\n",
      "Epoch [1/100], Step [7300/24597], Loss: 1.6212\n",
      "Epoch [1/100], Step [7400/24597], Loss: 1.6371\n",
      "Epoch [1/100], Step [7500/24597], Loss: 1.7180\n",
      "Epoch [1/100], Step [7600/24597], Loss: 1.7352\n",
      "Epoch [1/100], Step [7700/24597], Loss: 1.6605\n",
      "Epoch [1/100], Step [7800/24597], Loss: 1.8868\n",
      "Epoch [1/100], Step [7900/24597], Loss: 1.7377\n",
      "Epoch [1/100], Step [8000/24597], Loss: 1.5852\n",
      "Epoch [1/100], Step [8100/24597], Loss: 1.7768\n",
      "Epoch [1/100], Step [8200/24597], Loss: 1.8330\n",
      "Epoch [1/100], Step [8300/24597], Loss: 1.7325\n",
      "Epoch [1/100], Step [8400/24597], Loss: 1.7951\n",
      "Epoch [1/100], Step [8500/24597], Loss: 1.9092\n",
      "Epoch [1/100], Step [8600/24597], Loss: 1.7144\n",
      "Epoch [1/100], Step [8700/24597], Loss: 1.8461\n",
      "Epoch [1/100], Step [8800/24597], Loss: 1.7133\n",
      "Epoch [1/100], Step [8900/24597], Loss: 1.7751\n",
      "Epoch [1/100], Step [9000/24597], Loss: 1.6798\n",
      "Epoch [1/100], Step [9100/24597], Loss: 1.6472\n",
      "Epoch [1/100], Step [9200/24597], Loss: 1.6302\n",
      "Epoch [1/100], Step [9300/24597], Loss: 1.7325\n",
      "Epoch [1/100], Step [9400/24597], Loss: 1.6213\n",
      "Epoch [1/100], Step [9500/24597], Loss: 1.7358\n",
      "Epoch [1/100], Step [9600/24597], Loss: 1.7021\n",
      "Epoch [1/100], Step [9700/24597], Loss: 1.5856\n",
      "Epoch [1/100], Step [9800/24597], Loss: 1.7795\n",
      "Epoch [1/100], Step [9900/24597], Loss: 1.6958\n",
      "Epoch [1/100], Step [10000/24597], Loss: 1.5386\n",
      "Epoch [1/100], Step [10100/24597], Loss: 1.6041\n",
      "Epoch [1/100], Step [10200/24597], Loss: 1.6500\n",
      "Epoch [1/100], Step [10300/24597], Loss: 1.9048\n",
      "Epoch [1/100], Step [10400/24597], Loss: 1.3852\n",
      "Epoch [1/100], Step [10500/24597], Loss: 1.7774\n",
      "Epoch [1/100], Step [10600/24597], Loss: 1.5532\n",
      "Epoch [1/100], Step [10700/24597], Loss: 1.6315\n",
      "Epoch [1/100], Step [10800/24597], Loss: 1.6297\n",
      "Epoch [1/100], Step [10900/24597], Loss: 1.7031\n",
      "Epoch [1/100], Step [11000/24597], Loss: 1.5098\n",
      "Epoch [1/100], Step [11100/24597], Loss: 1.8625\n",
      "Epoch [1/100], Step [11200/24597], Loss: 1.7118\n",
      "Epoch [1/100], Step [11300/24597], Loss: 1.5882\n",
      "Epoch [1/100], Step [11400/24597], Loss: 1.7726\n",
      "Epoch [1/100], Step [11500/24597], Loss: 1.6205\n",
      "Epoch [1/100], Step [11600/24597], Loss: 1.6865\n",
      "Epoch [1/100], Step [11700/24597], Loss: 1.5379\n",
      "Epoch [1/100], Step [11800/24597], Loss: 1.6619\n",
      "Epoch [1/100], Step [11900/24597], Loss: 1.9027\n",
      "Epoch [1/100], Step [12000/24597], Loss: 1.6969\n",
      "Epoch [1/100], Step [12100/24597], Loss: 1.7657\n",
      "Epoch [1/100], Step [12200/24597], Loss: 1.5727\n",
      "Epoch [1/100], Step [12300/24597], Loss: 1.5575\n",
      "Epoch [1/100], Step [12400/24597], Loss: 1.6713\n",
      "Epoch [1/100], Step [12500/24597], Loss: 1.6372\n",
      "Epoch [1/100], Step [12600/24597], Loss: 1.6343\n",
      "Epoch [1/100], Step [12700/24597], Loss: 1.6824\n",
      "Epoch [1/100], Step [12800/24597], Loss: 1.6224\n",
      "Epoch [1/100], Step [12900/24597], Loss: 1.5323\n",
      "Epoch [1/100], Step [13000/24597], Loss: 1.5433\n",
      "Epoch [1/100], Step [13100/24597], Loss: 1.6971\n",
      "Epoch [1/100], Step [13200/24597], Loss: 1.5632\n",
      "Epoch [1/100], Step [13300/24597], Loss: 1.8608\n",
      "Epoch [1/100], Step [13400/24597], Loss: 1.6694\n",
      "Epoch [1/100], Step [13500/24597], Loss: 1.8374\n",
      "Epoch [1/100], Step [13600/24597], Loss: 1.5414\n",
      "Epoch [1/100], Step [13700/24597], Loss: 2.0086\n",
      "Epoch [1/100], Step [13800/24597], Loss: 1.6806\n",
      "Epoch [1/100], Step [13900/24597], Loss: 1.7358\n",
      "Epoch [1/100], Step [14000/24597], Loss: 1.5809\n",
      "Epoch [1/100], Step [14100/24597], Loss: 1.8427\n",
      "Epoch [1/100], Step [14200/24597], Loss: 1.7236\n",
      "Epoch [1/100], Step [14300/24597], Loss: 1.6511\n",
      "Epoch [1/100], Step [14400/24597], Loss: 1.8425\n",
      "Epoch [1/100], Step [14500/24597], Loss: 1.5906\n",
      "Epoch [1/100], Step [14600/24597], Loss: 1.6804\n",
      "Epoch [1/100], Step [14700/24597], Loss: 1.6015\n",
      "Epoch [1/100], Step [14800/24597], Loss: 1.6414\n",
      "Epoch [1/100], Step [14900/24597], Loss: 1.8540\n",
      "Epoch [1/100], Step [15000/24597], Loss: 1.7317\n",
      "Epoch [1/100], Step [15100/24597], Loss: 1.7745\n",
      "Epoch [1/100], Step [15200/24597], Loss: 1.6370\n",
      "Epoch [1/100], Step [15300/24597], Loss: 1.7139\n",
      "Epoch [1/100], Step [15400/24597], Loss: 1.7359\n",
      "Epoch [1/100], Step [15500/24597], Loss: 1.7305\n",
      "Epoch [1/100], Step [15600/24597], Loss: 1.7215\n",
      "Epoch [1/100], Step [15700/24597], Loss: 1.7072\n",
      "Epoch [1/100], Step [15800/24597], Loss: 1.6830\n",
      "Epoch [1/100], Step [15900/24597], Loss: 1.6409\n",
      "Epoch [1/100], Step [16000/24597], Loss: 1.6553\n",
      "Epoch [1/100], Step [16100/24597], Loss: 1.5854\n",
      "Epoch [1/100], Step [16200/24597], Loss: 1.6776\n",
      "Epoch [1/100], Step [16300/24597], Loss: 1.7545\n",
      "Epoch [1/100], Step [16400/24597], Loss: 1.9040\n",
      "Epoch [1/100], Step [16500/24597], Loss: 1.5782\n",
      "Epoch [1/100], Step [16600/24597], Loss: 1.7355\n",
      "Epoch [1/100], Step [16700/24597], Loss: 1.7246\n",
      "Epoch [1/100], Step [16800/24597], Loss: 1.5977\n",
      "Epoch [1/100], Step [16900/24597], Loss: 1.4784\n",
      "Epoch [1/100], Step [17000/24597], Loss: 1.5580\n",
      "Epoch [1/100], Step [17100/24597], Loss: 1.6629\n",
      "Epoch [1/100], Step [17200/24597], Loss: 1.5661\n",
      "Epoch [1/100], Step [17300/24597], Loss: 1.5561\n",
      "Epoch [1/100], Step [17400/24597], Loss: 1.6868\n",
      "Epoch [1/100], Step [17500/24597], Loss: 1.6086\n",
      "Epoch [1/100], Step [17600/24597], Loss: 1.6358\n",
      "Epoch [1/100], Step [17700/24597], Loss: 1.6823\n",
      "Epoch [1/100], Step [17800/24597], Loss: 1.7310\n",
      "Epoch [1/100], Step [17900/24597], Loss: 1.4737\n",
      "Epoch [1/100], Step [18000/24597], Loss: 1.7559\n",
      "Epoch [1/100], Step [18100/24597], Loss: 1.5999\n",
      "Epoch [1/100], Step [18200/24597], Loss: 1.7605\n",
      "Epoch [1/100], Step [18300/24597], Loss: 1.6278\n",
      "Epoch [1/100], Step [18400/24597], Loss: 1.8418\n",
      "Epoch [1/100], Step [18500/24597], Loss: 1.7398\n",
      "Epoch [1/100], Step [18600/24597], Loss: 1.8132\n",
      "Epoch [1/100], Step [18700/24597], Loss: 1.6929\n",
      "Epoch [1/100], Step [18800/24597], Loss: 1.7215\n",
      "Epoch [1/100], Step [18900/24597], Loss: 1.4732\n",
      "Epoch [1/100], Step [19000/24597], Loss: 1.6528\n",
      "Epoch [1/100], Step [19100/24597], Loss: 1.8633\n",
      "Epoch [1/100], Step [19200/24597], Loss: 1.6074\n",
      "Epoch [1/100], Step [19300/24597], Loss: 1.5941\n",
      "Epoch [1/100], Step [19400/24597], Loss: 1.5483\n",
      "Epoch [1/100], Step [19500/24597], Loss: 1.7325\n",
      "Epoch [1/100], Step [19600/24597], Loss: 1.7213\n",
      "Epoch [1/100], Step [19700/24597], Loss: 1.6313\n",
      "Epoch [1/100], Step [19800/24597], Loss: 1.6121\n",
      "Epoch [1/100], Step [19900/24597], Loss: 1.7454\n",
      "Epoch [1/100], Step [20000/24597], Loss: 1.5556\n",
      "Epoch [1/100], Step [20100/24597], Loss: 1.8513\n",
      "Epoch [1/100], Step [20200/24597], Loss: 1.5763\n",
      "Epoch [1/100], Step [20300/24597], Loss: 1.4784\n",
      "Epoch [1/100], Step [20400/24597], Loss: 1.5250\n",
      "Epoch [1/100], Step [20500/24597], Loss: 1.7234\n",
      "Epoch [1/100], Step [20600/24597], Loss: 1.5784\n",
      "Epoch [1/100], Step [20700/24597], Loss: 1.7423\n",
      "Epoch [1/100], Step [20800/24597], Loss: 1.8174\n",
      "Epoch [1/100], Step [20900/24597], Loss: 1.5553\n",
      "Epoch [1/100], Step [21000/24597], Loss: 1.7217\n",
      "Epoch [1/100], Step [21100/24597], Loss: 1.5398\n",
      "Epoch [1/100], Step [21200/24597], Loss: 1.7705\n",
      "Epoch [1/100], Step [21300/24597], Loss: 1.5710\n",
      "Epoch [1/100], Step [21400/24597], Loss: 1.5783\n",
      "Epoch [1/100], Step [21500/24597], Loss: 1.6496\n",
      "Epoch [1/100], Step [21600/24597], Loss: 1.9431\n",
      "Epoch [1/100], Step [21700/24597], Loss: 1.6467\n",
      "Epoch [1/100], Step [21800/24597], Loss: 1.7745\n",
      "Epoch [1/100], Step [21900/24597], Loss: 1.6274\n",
      "Epoch [1/100], Step [22000/24597], Loss: 1.8687\n",
      "Epoch [1/100], Step [22100/24597], Loss: 1.7228\n",
      "Epoch [1/100], Step [22200/24597], Loss: 1.7254\n",
      "Epoch [1/100], Step [22300/24597], Loss: 1.5965\n",
      "Epoch [1/100], Step [22400/24597], Loss: 1.6584\n",
      "Epoch [1/100], Step [22500/24597], Loss: 1.7395\n",
      "Epoch [1/100], Step [22600/24597], Loss: 1.5544\n",
      "Epoch [1/100], Step [22700/24597], Loss: 1.7026\n",
      "Epoch [1/100], Step [22800/24597], Loss: 1.8286\n",
      "Epoch [1/100], Step [22900/24597], Loss: 1.6438\n",
      "Epoch [1/100], Step [23000/24597], Loss: 1.6311\n",
      "Epoch [1/100], Step [23100/24597], Loss: 1.5630\n",
      "Epoch [1/100], Step [23200/24597], Loss: 1.8467\n",
      "Epoch [1/100], Step [23300/24597], Loss: 1.8711\n",
      "Epoch [1/100], Step [23400/24597], Loss: 1.6230\n",
      "Epoch [1/100], Step [23500/24597], Loss: 1.5474\n",
      "Epoch [1/100], Step [23600/24597], Loss: 1.6578\n",
      "Epoch [1/100], Step [23700/24597], Loss: 1.6855\n",
      "Epoch [1/100], Step [23800/24597], Loss: 1.6341\n",
      "Epoch [1/100], Step [23900/24597], Loss: 1.5495\n",
      "Epoch [1/100], Step [24000/24597], Loss: 1.5909\n",
      "Epoch [1/100], Step [24100/24597], Loss: 1.5998\n",
      "Epoch [1/100], Step [24200/24597], Loss: 1.6515\n",
      "Epoch [1/100], Step [24300/24597], Loss: 1.9004\n",
      "Epoch [1/100], Step [24400/24597], Loss: 1.7723\n",
      "Epoch [1/100], Step [24500/24597], Loss: 1.7690\n",
      "Epoch [2/100], Step [100/24597], Loss: 1.6345\n",
      "Epoch [2/100], Step [200/24597], Loss: 1.6867\n",
      "Epoch [2/100], Step [300/24597], Loss: 1.5230\n",
      "Epoch [2/100], Step [400/24597], Loss: 1.6853\n",
      "Epoch [2/100], Step [500/24597], Loss: 1.9257\n",
      "Epoch [2/100], Step [600/24597], Loss: 1.5363\n",
      "Epoch [2/100], Step [700/24597], Loss: 1.6925\n",
      "Epoch [2/100], Step [800/24597], Loss: 1.5496\n",
      "Epoch [2/100], Step [900/24597], Loss: 1.7018\n",
      "Epoch [2/100], Step [1000/24597], Loss: 1.6192\n",
      "Epoch [2/100], Step [1100/24597], Loss: 1.6554\n",
      "Epoch [2/100], Step [1200/24597], Loss: 1.6597\n",
      "Epoch [2/100], Step [1300/24597], Loss: 1.7056\n",
      "Epoch [2/100], Step [1400/24597], Loss: 1.3603\n",
      "Epoch [2/100], Step [1500/24597], Loss: 1.5144\n",
      "Epoch [2/100], Step [1600/24597], Loss: 1.8165\n",
      "Epoch [2/100], Step [1700/24597], Loss: 1.5841\n",
      "Epoch [2/100], Step [1800/24597], Loss: 1.5180\n",
      "Epoch [2/100], Step [1900/24597], Loss: 1.8476\n",
      "Epoch [2/100], Step [2000/24597], Loss: 1.7033\n",
      "Epoch [2/100], Step [2100/24597], Loss: 1.6842\n",
      "Epoch [2/100], Step [2200/24597], Loss: 1.7145\n",
      "Epoch [2/100], Step [2300/24597], Loss: 1.6630\n",
      "Epoch [2/100], Step [2400/24597], Loss: 1.7357\n",
      "Epoch [2/100], Step [2500/24597], Loss: 1.8272\n",
      "Epoch [2/100], Step [2600/24597], Loss: 1.7459\n",
      "Epoch [2/100], Step [2700/24597], Loss: 1.9759\n",
      "Epoch [2/100], Step [2800/24597], Loss: 1.6347\n",
      "Epoch [2/100], Step [2900/24597], Loss: 1.6491\n",
      "Epoch [2/100], Step [3000/24597], Loss: 1.4937\n",
      "Epoch [2/100], Step [3100/24597], Loss: 1.4348\n",
      "Epoch [2/100], Step [3200/24597], Loss: 1.8259\n",
      "Epoch [2/100], Step [3300/24597], Loss: 1.5804\n",
      "Epoch [2/100], Step [3400/24597], Loss: 1.4712\n",
      "Epoch [2/100], Step [3500/24597], Loss: 1.5817\n",
      "Epoch [2/100], Step [3600/24597], Loss: 1.6760\n",
      "Epoch [2/100], Step [3700/24597], Loss: 1.6886\n",
      "Epoch [2/100], Step [3800/24597], Loss: 1.5791\n",
      "Epoch [2/100], Step [3900/24597], Loss: 1.7612\n",
      "Epoch [2/100], Step [4000/24597], Loss: 1.7034\n",
      "Epoch [2/100], Step [4100/24597], Loss: 1.5774\n",
      "Epoch [2/100], Step [4200/24597], Loss: 1.6991\n",
      "Epoch [2/100], Step [4300/24597], Loss: 1.8544\n",
      "Epoch [2/100], Step [4400/24597], Loss: 1.6545\n",
      "Epoch [2/100], Step [4500/24597], Loss: 1.6495\n",
      "Epoch [2/100], Step [4600/24597], Loss: 1.5789\n",
      "Epoch [2/100], Step [4700/24597], Loss: 1.7336\n",
      "Epoch [2/100], Step [4800/24597], Loss: 1.5955\n",
      "Epoch [2/100], Step [4900/24597], Loss: 1.5223\n",
      "Epoch [2/100], Step [5000/24597], Loss: 1.7280\n",
      "Epoch [2/100], Step [5100/24597], Loss: 1.4783\n",
      "Epoch [2/100], Step [5200/24597], Loss: 1.4647\n",
      "Epoch [2/100], Step [5300/24597], Loss: 1.5508\n",
      "Epoch [2/100], Step [5400/24597], Loss: 1.7795\n",
      "Epoch [2/100], Step [5500/24597], Loss: 1.6794\n",
      "Epoch [2/100], Step [5600/24597], Loss: 1.7084\n",
      "Epoch [2/100], Step [5700/24597], Loss: 1.4336\n",
      "Epoch [2/100], Step [5800/24597], Loss: 1.8099\n",
      "Epoch [2/100], Step [5900/24597], Loss: 1.7567\n",
      "Epoch [2/100], Step [6000/24597], Loss: 1.5643\n",
      "Epoch [2/100], Step [6100/24597], Loss: 1.7393\n",
      "Epoch [2/100], Step [6200/24597], Loss: 1.5541\n",
      "Epoch [2/100], Step [6300/24597], Loss: 1.7405\n",
      "Epoch [2/100], Step [6400/24597], Loss: 1.5462\n",
      "Epoch [2/100], Step [6500/24597], Loss: 1.6521\n",
      "Epoch [2/100], Step [6600/24597], Loss: 1.7801\n",
      "Epoch [2/100], Step [6700/24597], Loss: 1.6726\n",
      "Epoch [2/100], Step [6800/24597], Loss: 1.6081\n",
      "Epoch [2/100], Step [6900/24597], Loss: 1.6628\n",
      "Epoch [2/100], Step [7000/24597], Loss: 1.7019\n",
      "Epoch [2/100], Step [7100/24597], Loss: 1.8241\n",
      "Epoch [2/100], Step [7200/24597], Loss: 1.6899\n",
      "Epoch [2/100], Step [7300/24597], Loss: 1.7042\n",
      "Epoch [2/100], Step [7400/24597], Loss: 1.5641\n",
      "Epoch [2/100], Step [7500/24597], Loss: 1.5795\n",
      "Epoch [2/100], Step [7600/24597], Loss: 1.8686\n",
      "Epoch [2/100], Step [7700/24597], Loss: 1.6510\n",
      "Epoch [2/100], Step [7800/24597], Loss: 1.5308\n",
      "Epoch [2/100], Step [7900/24597], Loss: 1.6019\n",
      "Epoch [2/100], Step [8000/24597], Loss: 1.6218\n",
      "Epoch [2/100], Step [8100/24597], Loss: 1.5487\n",
      "Epoch [2/100], Step [8200/24597], Loss: 1.6928\n",
      "Epoch [2/100], Step [8300/24597], Loss: 1.8632\n",
      "Epoch [2/100], Step [8400/24597], Loss: 1.7514\n",
      "Epoch [2/100], Step [8500/24597], Loss: 1.6991\n",
      "Epoch [2/100], Step [8600/24597], Loss: 1.8362\n",
      "Epoch [2/100], Step [8700/24597], Loss: 1.8622\n",
      "Epoch [2/100], Step [8800/24597], Loss: 1.6687\n",
      "Epoch [2/100], Step [8900/24597], Loss: 1.6581\n",
      "Epoch [2/100], Step [9000/24597], Loss: 1.8130\n",
      "Epoch [2/100], Step [9100/24597], Loss: 1.7440\n",
      "Epoch [2/100], Step [9200/24597], Loss: 1.6502\n",
      "Epoch [2/100], Step [9300/24597], Loss: 1.7369\n",
      "Epoch [2/100], Step [9400/24597], Loss: 1.4528\n",
      "Epoch [2/100], Step [9500/24597], Loss: 1.4713\n",
      "Epoch [2/100], Step [9600/24597], Loss: 1.5092\n",
      "Epoch [2/100], Step [9700/24597], Loss: 1.8016\n",
      "Epoch [2/100], Step [9800/24597], Loss: 1.4566\n",
      "Epoch [2/100], Step [9900/24597], Loss: 1.7921\n",
      "Epoch [2/100], Step [10000/24597], Loss: 1.5587\n",
      "Epoch [2/100], Step [10100/24597], Loss: 1.7268\n",
      "Epoch [2/100], Step [10200/24597], Loss: 1.5884\n",
      "Epoch [2/100], Step [10300/24597], Loss: 1.9067\n",
      "Epoch [2/100], Step [10400/24597], Loss: 1.6946\n",
      "Epoch [2/100], Step [10500/24597], Loss: 1.7789\n",
      "Epoch [2/100], Step [10600/24597], Loss: 1.5853\n",
      "Epoch [2/100], Step [10700/24597], Loss: 1.5597\n",
      "Epoch [2/100], Step [10800/24597], Loss: 1.7936\n",
      "Epoch [2/100], Step [10900/24597], Loss: 1.6255\n",
      "Epoch [2/100], Step [11000/24597], Loss: 1.5756\n",
      "Epoch [2/100], Step [11100/24597], Loss: 1.5233\n",
      "Epoch [2/100], Step [11200/24597], Loss: 1.5891\n",
      "Epoch [2/100], Step [11300/24597], Loss: 1.6411\n",
      "Epoch [2/100], Step [11400/24597], Loss: 1.7439\n",
      "Epoch [2/100], Step [11500/24597], Loss: 1.6401\n",
      "Epoch [2/100], Step [11600/24597], Loss: 1.6242\n",
      "Epoch [2/100], Step [11700/24597], Loss: 1.6024\n",
      "Epoch [2/100], Step [11800/24597], Loss: 1.6174\n",
      "Epoch [2/100], Step [11900/24597], Loss: 1.6745\n",
      "Epoch [2/100], Step [12000/24597], Loss: 1.6385\n",
      "Epoch [2/100], Step [12100/24597], Loss: 1.6847\n",
      "Epoch [2/100], Step [12200/24597], Loss: 1.4073\n",
      "Epoch [2/100], Step [12300/24597], Loss: 1.5507\n",
      "Epoch [2/100], Step [12400/24597], Loss: 1.5073\n",
      "Epoch [2/100], Step [12500/24597], Loss: 1.6146\n",
      "Epoch [2/100], Step [12600/24597], Loss: 1.6837\n",
      "Epoch [2/100], Step [12700/24597], Loss: 1.7129\n",
      "Epoch [2/100], Step [12800/24597], Loss: 1.5402\n",
      "Epoch [2/100], Step [12900/24597], Loss: 1.5745\n",
      "Epoch [2/100], Step [13000/24597], Loss: 1.4969\n",
      "Epoch [2/100], Step [13100/24597], Loss: 1.7012\n",
      "Epoch [2/100], Step [13200/24597], Loss: 1.6465\n",
      "Epoch [2/100], Step [13300/24597], Loss: 1.9256\n",
      "Epoch [2/100], Step [13400/24597], Loss: 1.8498\n",
      "Epoch [2/100], Step [13500/24597], Loss: 1.5103\n",
      "Epoch [2/100], Step [13600/24597], Loss: 1.5256\n",
      "Epoch [2/100], Step [13700/24597], Loss: 1.8060\n",
      "Epoch [2/100], Step [13800/24597], Loss: 1.6683\n",
      "Epoch [2/100], Step [13900/24597], Loss: 1.7390\n",
      "Epoch [2/100], Step [14000/24597], Loss: 1.7133\n",
      "Epoch [2/100], Step [14100/24597], Loss: 1.6796\n",
      "Epoch [2/100], Step [14200/24597], Loss: 1.5979\n",
      "Epoch [2/100], Step [14300/24597], Loss: 1.7416\n",
      "Epoch [2/100], Step [14400/24597], Loss: 1.4699\n",
      "Epoch [2/100], Step [14500/24597], Loss: 1.6607\n",
      "Epoch [2/100], Step [14600/24597], Loss: 1.6867\n",
      "Epoch [2/100], Step [14700/24597], Loss: 1.5906\n",
      "Epoch [2/100], Step [14800/24597], Loss: 1.7926\n",
      "Epoch [2/100], Step [14900/24597], Loss: 1.6074\n",
      "Epoch [2/100], Step [15000/24597], Loss: 1.8777\n",
      "Epoch [2/100], Step [15100/24597], Loss: 1.7023\n",
      "Epoch [2/100], Step [15200/24597], Loss: 1.7252\n",
      "Epoch [2/100], Step [15300/24597], Loss: 1.7169\n",
      "Epoch [2/100], Step [15400/24597], Loss: 1.6480\n",
      "Epoch [2/100], Step [15500/24597], Loss: 1.6746\n",
      "Epoch [2/100], Step [15600/24597], Loss: 1.6496\n",
      "Epoch [2/100], Step [15700/24597], Loss: 1.7128\n",
      "Epoch [2/100], Step [15800/24597], Loss: 1.6502\n",
      "Epoch [2/100], Step [15900/24597], Loss: 1.9055\n",
      "Epoch [2/100], Step [16000/24597], Loss: 1.7845\n",
      "Epoch [2/100], Step [16100/24597], Loss: 1.7287\n",
      "Epoch [2/100], Step [16200/24597], Loss: 1.5419\n",
      "Epoch [2/100], Step [16300/24597], Loss: 1.8261\n",
      "Epoch [2/100], Step [16400/24597], Loss: 1.6284\n",
      "Epoch [2/100], Step [16500/24597], Loss: 1.7469\n",
      "Epoch [2/100], Step [16600/24597], Loss: 1.6405\n",
      "Epoch [2/100], Step [16700/24597], Loss: 1.6756\n",
      "Epoch [2/100], Step [16800/24597], Loss: 1.6106\n",
      "Epoch [2/100], Step [16900/24597], Loss: 1.9629\n",
      "Epoch [2/100], Step [17000/24597], Loss: 1.8252\n",
      "Epoch [2/100], Step [17100/24597], Loss: 1.4335\n",
      "Epoch [2/100], Step [17200/24597], Loss: 1.7199\n",
      "Epoch [2/100], Step [17300/24597], Loss: 1.8392\n",
      "Epoch [2/100], Step [17400/24597], Loss: 1.7793\n",
      "Epoch [2/100], Step [17500/24597], Loss: 1.5723\n",
      "Epoch [2/100], Step [17600/24597], Loss: 1.6869\n",
      "Epoch [2/100], Step [17700/24597], Loss: 1.6594\n",
      "Epoch [2/100], Step [17800/24597], Loss: 1.5101\n",
      "Epoch [2/100], Step [17900/24597], Loss: 1.7882\n",
      "Epoch [2/100], Step [18000/24597], Loss: 1.6328\n",
      "Epoch [2/100], Step [18100/24597], Loss: 1.5143\n",
      "Epoch [2/100], Step [18200/24597], Loss: 1.4969\n",
      "Epoch [2/100], Step [18300/24597], Loss: 1.4839\n",
      "Epoch [2/100], Step [18400/24597], Loss: 1.6295\n",
      "Epoch [2/100], Step [18500/24597], Loss: 1.5036\n",
      "Epoch [2/100], Step [18600/24597], Loss: 1.6019\n",
      "Epoch [2/100], Step [18700/24597], Loss: 1.7854\n",
      "Epoch [2/100], Step [18800/24597], Loss: 1.7081\n",
      "Epoch [2/100], Step [18900/24597], Loss: 1.5932\n",
      "Epoch [2/100], Step [19000/24597], Loss: 1.8562\n",
      "Epoch [2/100], Step [19100/24597], Loss: 1.5094\n",
      "Epoch [2/100], Step [19200/24597], Loss: 1.6552\n",
      "Epoch [2/100], Step [19300/24597], Loss: 1.4705\n",
      "Epoch [2/100], Step [19400/24597], Loss: 1.8528\n",
      "Epoch [2/100], Step [19500/24597], Loss: 1.5961\n",
      "Epoch [2/100], Step [19600/24597], Loss: 1.5833\n",
      "Epoch [2/100], Step [19700/24597], Loss: 1.4264\n",
      "Epoch [2/100], Step [19800/24597], Loss: 1.6584\n",
      "Epoch [2/100], Step [19900/24597], Loss: 1.6874\n",
      "Epoch [2/100], Step [20000/24597], Loss: 1.6201\n",
      "Epoch [2/100], Step [20100/24597], Loss: 1.8345\n",
      "Epoch [2/100], Step [20200/24597], Loss: 1.7054\n",
      "Epoch [2/100], Step [20300/24597], Loss: 1.7333\n",
      "Epoch [2/100], Step [20400/24597], Loss: 1.6734\n",
      "Epoch [2/100], Step [20500/24597], Loss: 1.5704\n",
      "Epoch [2/100], Step [20600/24597], Loss: 1.6780\n",
      "Epoch [2/100], Step [20700/24597], Loss: 1.5722\n",
      "Epoch [2/100], Step [20800/24597], Loss: 1.5934\n",
      "Epoch [2/100], Step [20900/24597], Loss: 1.7086\n",
      "Epoch [2/100], Step [21000/24597], Loss: 1.6444\n",
      "Epoch [2/100], Step [21100/24597], Loss: 1.6827\n",
      "Epoch [2/100], Step [21200/24597], Loss: 1.8137\n",
      "Epoch [2/100], Step [21300/24597], Loss: 1.5456\n",
      "Epoch [2/100], Step [21400/24597], Loss: 1.8176\n",
      "Epoch [2/100], Step [21500/24597], Loss: 1.7074\n",
      "Epoch [2/100], Step [21600/24597], Loss: 1.6350\n",
      "Epoch [2/100], Step [21700/24597], Loss: 1.6534\n",
      "Epoch [2/100], Step [21800/24597], Loss: 1.5427\n",
      "Epoch [2/100], Step [21900/24597], Loss: 1.5650\n",
      "Epoch [2/100], Step [22000/24597], Loss: 1.3885\n",
      "Epoch [2/100], Step [22100/24597], Loss: 1.6496\n",
      "Epoch [2/100], Step [22200/24597], Loss: 1.4040\n",
      "Epoch [2/100], Step [22300/24597], Loss: 1.7212\n",
      "Epoch [2/100], Step [22400/24597], Loss: 1.8560\n",
      "Epoch [2/100], Step [22500/24597], Loss: 1.4769\n",
      "Epoch [2/100], Step [22600/24597], Loss: 1.7319\n",
      "Epoch [2/100], Step [22700/24597], Loss: 1.4964\n",
      "Epoch [2/100], Step [22800/24597], Loss: 1.7194\n",
      "Epoch [2/100], Step [22900/24597], Loss: 1.7307\n",
      "Epoch [2/100], Step [23000/24597], Loss: 1.4232\n",
      "Epoch [2/100], Step [23100/24597], Loss: 1.5248\n",
      "Epoch [2/100], Step [23200/24597], Loss: 1.4092\n",
      "Epoch [2/100], Step [23300/24597], Loss: 1.6890\n",
      "Epoch [2/100], Step [23400/24597], Loss: 1.6302\n",
      "Epoch [2/100], Step [23500/24597], Loss: 1.7538\n",
      "Epoch [2/100], Step [23600/24597], Loss: 1.7863\n",
      "Epoch [2/100], Step [23700/24597], Loss: 1.6068\n",
      "Epoch [2/100], Step [23800/24597], Loss: 1.8544\n",
      "Epoch [2/100], Step [23900/24597], Loss: 1.6895\n",
      "Epoch [2/100], Step [24000/24597], Loss: 1.5859\n",
      "Epoch [2/100], Step [24100/24597], Loss: 1.6158\n",
      "Epoch [2/100], Step [24200/24597], Loss: 1.6677\n",
      "Epoch [2/100], Step [24300/24597], Loss: 1.4285\n",
      "Epoch [2/100], Step [24400/24597], Loss: 1.7407\n",
      "Epoch [2/100], Step [24500/24597], Loss: 1.7410\n",
      "Epoch [3/100], Step [100/24597], Loss: 1.7326\n",
      "Epoch [3/100], Step [200/24597], Loss: 1.6384\n",
      "Epoch [3/100], Step [300/24597], Loss: 1.7063\n",
      "Epoch [3/100], Step [400/24597], Loss: 1.6020\n",
      "Epoch [3/100], Step [500/24597], Loss: 1.6047\n",
      "Epoch [3/100], Step [600/24597], Loss: 1.5963\n",
      "Epoch [3/100], Step [700/24597], Loss: 1.6001\n",
      "Epoch [3/100], Step [800/24597], Loss: 1.7607\n",
      "Epoch [3/100], Step [900/24597], Loss: 1.7798\n",
      "Epoch [3/100], Step [1000/24597], Loss: 1.3657\n",
      "Epoch [3/100], Step [1100/24597], Loss: 1.8140\n",
      "Epoch [3/100], Step [1200/24597], Loss: 1.6286\n",
      "Epoch [3/100], Step [1300/24597], Loss: 1.6535\n",
      "Epoch [3/100], Step [1400/24597], Loss: 1.6009\n",
      "Epoch [3/100], Step [1500/24597], Loss: 1.7385\n",
      "Epoch [3/100], Step [1600/24597], Loss: 1.6536\n",
      "Epoch [3/100], Step [1700/24597], Loss: 1.6429\n",
      "Epoch [3/100], Step [1800/24597], Loss: 1.6407\n",
      "Epoch [3/100], Step [1900/24597], Loss: 1.8358\n",
      "Epoch [3/100], Step [2000/24597], Loss: 1.5292\n",
      "Epoch [3/100], Step [2100/24597], Loss: 1.5845\n",
      "Epoch [3/100], Step [2200/24597], Loss: 1.6131\n",
      "Epoch [3/100], Step [2300/24597], Loss: 1.6776\n",
      "Epoch [3/100], Step [2400/24597], Loss: 1.4658\n",
      "Epoch [3/100], Step [2500/24597], Loss: 1.8048\n",
      "Epoch [3/100], Step [2600/24597], Loss: 1.6845\n",
      "Epoch [3/100], Step [2700/24597], Loss: 1.7065\n",
      "Epoch [3/100], Step [2800/24597], Loss: 1.5654\n",
      "Epoch [3/100], Step [2900/24597], Loss: 1.5955\n",
      "Epoch [3/100], Step [3000/24597], Loss: 1.8047\n",
      "Epoch [3/100], Step [3100/24597], Loss: 1.7756\n",
      "Epoch [3/100], Step [3200/24597], Loss: 1.7327\n",
      "Epoch [3/100], Step [3300/24597], Loss: 1.6414\n",
      "Epoch [3/100], Step [3400/24597], Loss: 1.8469\n",
      "Epoch [3/100], Step [3500/24597], Loss: 1.6109\n",
      "Epoch [3/100], Step [3600/24597], Loss: 1.5341\n",
      "Epoch [3/100], Step [3700/24597], Loss: 1.6501\n",
      "Epoch [3/100], Step [3800/24597], Loss: 1.4347\n",
      "Epoch [3/100], Step [3900/24597], Loss: 1.4976\n",
      "Epoch [3/100], Step [4000/24597], Loss: 1.6288\n",
      "Epoch [3/100], Step [4100/24597], Loss: 1.5394\n",
      "Epoch [3/100], Step [4200/24597], Loss: 1.5806\n",
      "Epoch [3/100], Step [4300/24597], Loss: 1.8371\n",
      "Epoch [3/100], Step [4400/24597], Loss: 1.6775\n",
      "Epoch [3/100], Step [4500/24597], Loss: 1.6279\n",
      "Epoch [3/100], Step [4600/24597], Loss: 1.6957\n",
      "Epoch [3/100], Step [4700/24597], Loss: 1.6120\n",
      "Epoch [3/100], Step [4800/24597], Loss: 1.7258\n",
      "Epoch [3/100], Step [4900/24597], Loss: 1.5524\n",
      "Epoch [3/100], Step [5000/24597], Loss: 1.8060\n",
      "Epoch [3/100], Step [5100/24597], Loss: 1.6141\n",
      "Epoch [3/100], Step [5200/24597], Loss: 1.7384\n",
      "Epoch [3/100], Step [5300/24597], Loss: 1.6059\n",
      "Epoch [3/100], Step [5400/24597], Loss: 1.8493\n",
      "Epoch [3/100], Step [5500/24597], Loss: 1.6752\n",
      "Epoch [3/100], Step [5600/24597], Loss: 1.5473\n",
      "Epoch [3/100], Step [5700/24597], Loss: 1.6264\n",
      "Epoch [3/100], Step [5800/24597], Loss: 1.6291\n",
      "Epoch [3/100], Step [5900/24597], Loss: 1.6331\n",
      "Epoch [3/100], Step [6000/24597], Loss: 1.4750\n",
      "Epoch [3/100], Step [6100/24597], Loss: 1.5573\n",
      "Epoch [3/100], Step [6200/24597], Loss: 1.5004\n",
      "Epoch [3/100], Step [6300/24597], Loss: 1.8077\n",
      "Epoch [3/100], Step [6400/24597], Loss: 1.6094\n",
      "Epoch [3/100], Step [6500/24597], Loss: 1.3541\n",
      "Epoch [3/100], Step [6600/24597], Loss: 1.7006\n",
      "Epoch [3/100], Step [6700/24597], Loss: 1.4790\n",
      "Epoch [3/100], Step [6800/24597], Loss: 1.5642\n",
      "Epoch [3/100], Step [6900/24597], Loss: 1.4900\n",
      "Epoch [3/100], Step [7000/24597], Loss: 1.7927\n",
      "Epoch [3/100], Step [7100/24597], Loss: 1.7617\n",
      "Epoch [3/100], Step [7200/24597], Loss: 1.6412\n",
      "Epoch [3/100], Step [7300/24597], Loss: 1.5211\n",
      "Epoch [3/100], Step [7400/24597], Loss: 1.7356\n",
      "Epoch [3/100], Step [7500/24597], Loss: 1.6989\n",
      "Epoch [3/100], Step [7600/24597], Loss: 1.7523\n",
      "Epoch [3/100], Step [7700/24597], Loss: 1.7859\n",
      "Epoch [3/100], Step [7800/24597], Loss: 1.6984\n",
      "Epoch [3/100], Step [7900/24597], Loss: 1.6422\n",
      "Epoch [3/100], Step [8000/24597], Loss: 1.4943\n",
      "Epoch [3/100], Step [8100/24597], Loss: 1.7084\n",
      "Epoch [3/100], Step [8200/24597], Loss: 1.6284\n",
      "Epoch [3/100], Step [8300/24597], Loss: 1.4970\n",
      "Epoch [3/100], Step [8400/24597], Loss: 1.8053\n",
      "Epoch [3/100], Step [8500/24597], Loss: 1.7219\n",
      "Epoch [3/100], Step [8600/24597], Loss: 1.5966\n",
      "Epoch [3/100], Step [8700/24597], Loss: 1.7811\n",
      "Epoch [3/100], Step [8800/24597], Loss: 1.6041\n",
      "Epoch [3/100], Step [8900/24597], Loss: 1.5867\n",
      "Epoch [3/100], Step [9000/24597], Loss: 1.6661\n",
      "Epoch [3/100], Step [9100/24597], Loss: 1.7378\n",
      "Epoch [3/100], Step [9200/24597], Loss: 1.5227\n",
      "Epoch [3/100], Step [9300/24597], Loss: 1.4475\n",
      "Epoch [3/100], Step [9400/24597], Loss: 1.6904\n",
      "Epoch [3/100], Step [9500/24597], Loss: 1.8210\n",
      "Epoch [3/100], Step [9600/24597], Loss: 1.5428\n",
      "Epoch [3/100], Step [9700/24597], Loss: 1.6394\n",
      "Epoch [3/100], Step [9800/24597], Loss: 1.6494\n",
      "Epoch [3/100], Step [9900/24597], Loss: 1.7938\n",
      "Epoch [3/100], Step [10000/24597], Loss: 1.4993\n",
      "Epoch [3/100], Step [10100/24597], Loss: 1.6514\n",
      "Epoch [3/100], Step [10200/24597], Loss: 1.5643\n",
      "Epoch [3/100], Step [10300/24597], Loss: 1.5691\n",
      "Epoch [3/100], Step [10400/24597], Loss: 1.8859\n",
      "Epoch [3/100], Step [10500/24597], Loss: 1.5188\n",
      "Epoch [3/100], Step [10600/24597], Loss: 1.8743\n",
      "Epoch [3/100], Step [10700/24597], Loss: 1.5473\n",
      "Epoch [3/100], Step [10800/24597], Loss: 1.8255\n",
      "Epoch [3/100], Step [10900/24597], Loss: 1.7614\n",
      "Epoch [3/100], Step [11000/24597], Loss: 1.5360\n",
      "Epoch [3/100], Step [11100/24597], Loss: 1.5629\n",
      "Epoch [3/100], Step [11200/24597], Loss: 1.5381\n",
      "Epoch [3/100], Step [11300/24597], Loss: 1.8187\n",
      "Epoch [3/100], Step [11400/24597], Loss: 1.5738\n",
      "Epoch [3/100], Step [11500/24597], Loss: 1.8454\n",
      "Epoch [3/100], Step [11600/24597], Loss: 1.5137\n",
      "Epoch [3/100], Step [11700/24597], Loss: 1.6007\n",
      "Epoch [3/100], Step [11800/24597], Loss: 1.5763\n",
      "Epoch [3/100], Step [11900/24597], Loss: 1.7339\n",
      "Epoch [3/100], Step [12000/24597], Loss: 1.5838\n",
      "Epoch [3/100], Step [12100/24597], Loss: 1.7170\n",
      "Epoch [3/100], Step [12200/24597], Loss: 1.5941\n",
      "Epoch [3/100], Step [12300/24597], Loss: 1.4530\n",
      "Epoch [3/100], Step [12400/24597], Loss: 1.6625\n",
      "Epoch [3/100], Step [12500/24597], Loss: 1.6564\n",
      "Epoch [3/100], Step [12600/24597], Loss: 1.8071\n",
      "Epoch [3/100], Step [12700/24597], Loss: 1.8617\n",
      "Epoch [3/100], Step [12800/24597], Loss: 1.9035\n",
      "Epoch [3/100], Step [12900/24597], Loss: 1.5951\n",
      "Epoch [3/100], Step [13000/24597], Loss: 1.6269\n",
      "Epoch [3/100], Step [13100/24597], Loss: 1.7022\n",
      "Epoch [3/100], Step [13200/24597], Loss: 1.8662\n",
      "Epoch [3/100], Step [13300/24597], Loss: 1.5826\n",
      "Epoch [3/100], Step [13400/24597], Loss: 1.8246\n",
      "Epoch [3/100], Step [13500/24597], Loss: 1.6358\n",
      "Epoch [3/100], Step [13600/24597], Loss: 1.5333\n",
      "Epoch [3/100], Step [13700/24597], Loss: 1.8054\n",
      "Epoch [3/100], Step [13800/24597], Loss: 1.5891\n",
      "Epoch [3/100], Step [13900/24597], Loss: 1.6912\n",
      "Epoch [3/100], Step [14000/24597], Loss: 1.6551\n",
      "Epoch [3/100], Step [14100/24597], Loss: 1.7662\n",
      "Epoch [3/100], Step [14200/24597], Loss: 1.7142\n",
      "Epoch [3/100], Step [14300/24597], Loss: 1.7527\n",
      "Epoch [3/100], Step [14400/24597], Loss: 1.6827\n",
      "Epoch [3/100], Step [14500/24597], Loss: 1.6107\n",
      "Epoch [3/100], Step [14600/24597], Loss: 1.6997\n",
      "Epoch [3/100], Step [14700/24597], Loss: 1.6162\n",
      "Epoch [3/100], Step [14800/24597], Loss: 1.5764\n",
      "Epoch [3/100], Step [14900/24597], Loss: 1.5619\n",
      "Epoch [3/100], Step [15000/24597], Loss: 1.9383\n",
      "Epoch [3/100], Step [15100/24597], Loss: 1.6158\n",
      "Epoch [3/100], Step [15200/24597], Loss: 1.5752\n",
      "Epoch [3/100], Step [15300/24597], Loss: 1.5267\n",
      "Epoch [3/100], Step [15400/24597], Loss: 1.6358\n",
      "Epoch [3/100], Step [15500/24597], Loss: 1.6083\n",
      "Epoch [3/100], Step [15600/24597], Loss: 1.5174\n",
      "Epoch [3/100], Step [15700/24597], Loss: 1.6457\n",
      "Epoch [3/100], Step [15800/24597], Loss: 1.7646\n",
      "Epoch [3/100], Step [15900/24597], Loss: 1.5514\n",
      "Epoch [3/100], Step [16000/24597], Loss: 1.5658\n",
      "Epoch [3/100], Step [16100/24597], Loss: 1.7045\n",
      "Epoch [3/100], Step [16200/24597], Loss: 1.6043\n",
      "Epoch [3/100], Step [16300/24597], Loss: 1.5863\n",
      "Epoch [3/100], Step [16400/24597], Loss: 1.4850\n",
      "Epoch [3/100], Step [16500/24597], Loss: 1.6230\n",
      "Epoch [3/100], Step [16600/24597], Loss: 1.5276\n",
      "Epoch [3/100], Step [16700/24597], Loss: 1.6632\n",
      "Epoch [3/100], Step [16800/24597], Loss: 1.5304\n",
      "Epoch [3/100], Step [16900/24597], Loss: 1.3915\n",
      "Epoch [3/100], Step [17000/24597], Loss: 1.6797\n",
      "Epoch [3/100], Step [17100/24597], Loss: 1.4292\n",
      "Epoch [3/100], Step [17200/24597], Loss: 1.6310\n",
      "Epoch [3/100], Step [17300/24597], Loss: 1.8982\n",
      "Epoch [3/100], Step [17400/24597], Loss: 1.4893\n",
      "Epoch [3/100], Step [17500/24597], Loss: 1.8235\n",
      "Epoch [3/100], Step [17600/24597], Loss: 1.8431\n",
      "Epoch [3/100], Step [17700/24597], Loss: 1.7139\n",
      "Epoch [3/100], Step [17800/24597], Loss: 1.5640\n",
      "Epoch [3/100], Step [17900/24597], Loss: 1.6110\n",
      "Epoch [3/100], Step [18000/24597], Loss: 1.7396\n",
      "Epoch [3/100], Step [18100/24597], Loss: 1.7893\n",
      "Epoch [3/100], Step [18200/24597], Loss: 1.7451\n",
      "Epoch [3/100], Step [18300/24597], Loss: 1.7252\n",
      "Epoch [3/100], Step [18400/24597], Loss: 1.5810\n",
      "Epoch [3/100], Step [18500/24597], Loss: 1.7770\n",
      "Epoch [3/100], Step [18600/24597], Loss: 1.7217\n",
      "Epoch [3/100], Step [18700/24597], Loss: 1.5432\n",
      "Epoch [3/100], Step [18800/24597], Loss: 1.7768\n",
      "Epoch [3/100], Step [18900/24597], Loss: 1.4887\n",
      "Epoch [3/100], Step [19000/24597], Loss: 1.6240\n",
      "Epoch [3/100], Step [19100/24597], Loss: 1.8189\n",
      "Epoch [3/100], Step [19200/24597], Loss: 1.8250\n",
      "Epoch [3/100], Step [19300/24597], Loss: 1.6429\n",
      "Epoch [3/100], Step [19400/24597], Loss: 1.8539\n",
      "Epoch [3/100], Step [19500/24597], Loss: 1.5311\n",
      "Epoch [3/100], Step [19600/24597], Loss: 1.7636\n",
      "Epoch [3/100], Step [19700/24597], Loss: 1.6661\n",
      "Epoch [3/100], Step [19800/24597], Loss: 1.7157\n",
      "Epoch [3/100], Step [19900/24597], Loss: 1.5424\n",
      "Epoch [3/100], Step [20000/24597], Loss: 1.6848\n",
      "Epoch [3/100], Step [20100/24597], Loss: 1.7309\n",
      "Epoch [3/100], Step [20200/24597], Loss: 1.4260\n",
      "Epoch [3/100], Step [20300/24597], Loss: 1.7697\n",
      "Epoch [3/100], Step [20400/24597], Loss: 1.8318\n",
      "Epoch [3/100], Step [20500/24597], Loss: 1.7172\n",
      "Epoch [3/100], Step [20600/24597], Loss: 1.5587\n",
      "Epoch [3/100], Step [20700/24597], Loss: 1.8627\n",
      "Epoch [3/100], Step [20800/24597], Loss: 1.6203\n",
      "Epoch [3/100], Step [20900/24597], Loss: 1.5878\n",
      "Epoch [3/100], Step [21000/24597], Loss: 1.6652\n",
      "Epoch [3/100], Step [21100/24597], Loss: 1.4929\n",
      "Epoch [3/100], Step [21200/24597], Loss: 1.7480\n",
      "Epoch [3/100], Step [21300/24597], Loss: 1.6919\n",
      "Epoch [3/100], Step [21400/24597], Loss: 1.6583\n",
      "Epoch [3/100], Step [21500/24597], Loss: 1.6398\n",
      "Epoch [3/100], Step [21600/24597], Loss: 1.5936\n",
      "Epoch [3/100], Step [21700/24597], Loss: 1.6765\n",
      "Epoch [3/100], Step [21800/24597], Loss: 1.6449\n",
      "Epoch [3/100], Step [21900/24597], Loss: 1.6336\n",
      "Epoch [3/100], Step [22000/24597], Loss: 1.5411\n",
      "Epoch [3/100], Step [22100/24597], Loss: 1.6090\n",
      "Epoch [3/100], Step [22200/24597], Loss: 1.6633\n",
      "Epoch [3/100], Step [22300/24597], Loss: 1.6005\n",
      "Epoch [3/100], Step [22400/24597], Loss: 1.5727\n",
      "Epoch [3/100], Step [22500/24597], Loss: 1.6393\n",
      "Epoch [3/100], Step [22600/24597], Loss: 1.6103\n",
      "Epoch [3/100], Step [22700/24597], Loss: 1.6007\n",
      "Epoch [3/100], Step [22800/24597], Loss: 1.6047\n",
      "Epoch [3/100], Step [22900/24597], Loss: 1.5652\n",
      "Epoch [3/100], Step [23000/24597], Loss: 1.9344\n",
      "Epoch [3/100], Step [23100/24597], Loss: 1.5689\n",
      "Epoch [3/100], Step [23200/24597], Loss: 2.0630\n",
      "Epoch [3/100], Step [23300/24597], Loss: 1.5820\n",
      "Epoch [3/100], Step [23400/24597], Loss: 1.5201\n",
      "Epoch [3/100], Step [23500/24597], Loss: 1.6428\n",
      "Epoch [3/100], Step [23600/24597], Loss: 1.5633\n",
      "Epoch [3/100], Step [23700/24597], Loss: 1.6055\n",
      "Epoch [3/100], Step [23800/24597], Loss: 1.5689\n",
      "Epoch [3/100], Step [23900/24597], Loss: 1.7243\n",
      "Epoch [3/100], Step [24000/24597], Loss: 1.6900\n",
      "Epoch [3/100], Step [24100/24597], Loss: 1.6312\n",
      "Epoch [3/100], Step [24200/24597], Loss: 1.7263\n",
      "Epoch [3/100], Step [24300/24597], Loss: 1.5375\n",
      "Epoch [3/100], Step [24400/24597], Loss: 1.6075\n",
      "Epoch [3/100], Step [24500/24597], Loss: 1.5501\n",
      "Epoch [4/100], Step [100/24597], Loss: 1.5278\n",
      "Epoch [4/100], Step [200/24597], Loss: 1.7837\n",
      "Epoch [4/100], Step [300/24597], Loss: 1.8532\n",
      "Epoch [4/100], Step [400/24597], Loss: 1.6471\n",
      "Epoch [4/100], Step [500/24597], Loss: 1.7033\n",
      "Epoch [4/100], Step [600/24597], Loss: 1.6588\n",
      "Epoch [4/100], Step [700/24597], Loss: 1.6694\n",
      "Epoch [4/100], Step [800/24597], Loss: 1.8827\n",
      "Epoch [4/100], Step [900/24597], Loss: 1.6163\n",
      "Epoch [4/100], Step [1000/24597], Loss: 1.6387\n",
      "Epoch [4/100], Step [1100/24597], Loss: 1.7605\n",
      "Epoch [4/100], Step [1200/24597], Loss: 1.8540\n",
      "Epoch [4/100], Step [1300/24597], Loss: 1.4893\n",
      "Epoch [4/100], Step [1400/24597], Loss: 1.5872\n",
      "Epoch [4/100], Step [1500/24597], Loss: 1.5096\n",
      "Epoch [4/100], Step [1600/24597], Loss: 1.5568\n",
      "Epoch [4/100], Step [1700/24597], Loss: 1.7001\n",
      "Epoch [4/100], Step [1800/24597], Loss: 1.7990\n",
      "Epoch [4/100], Step [1900/24597], Loss: 1.6230\n",
      "Epoch [4/100], Step [2000/24597], Loss: 1.8333\n",
      "Epoch [4/100], Step [2100/24597], Loss: 1.6015\n",
      "Epoch [4/100], Step [2200/24597], Loss: 1.5146\n",
      "Epoch [4/100], Step [2300/24597], Loss: 1.7973\n",
      "Epoch [4/100], Step [2400/24597], Loss: 1.6843\n",
      "Epoch [4/100], Step [2500/24597], Loss: 1.8738\n",
      "Epoch [4/100], Step [2600/24597], Loss: 1.7384\n",
      "Epoch [4/100], Step [2700/24597], Loss: 1.6788\n",
      "Epoch [4/100], Step [2800/24597], Loss: 1.5805\n",
      "Epoch [4/100], Step [2900/24597], Loss: 1.6508\n",
      "Epoch [4/100], Step [3000/24597], Loss: 1.6877\n",
      "Epoch [4/100], Step [3100/24597], Loss: 1.8204\n",
      "Epoch [4/100], Step [3200/24597], Loss: 1.6334\n",
      "Epoch [4/100], Step [3300/24597], Loss: 1.7427\n",
      "Epoch [4/100], Step [3400/24597], Loss: 1.6066\n",
      "Epoch [4/100], Step [3500/24597], Loss: 1.3844\n",
      "Epoch [4/100], Step [3600/24597], Loss: 1.6294\n",
      "Epoch [4/100], Step [3700/24597], Loss: 1.8438\n",
      "Epoch [4/100], Step [3800/24597], Loss: 1.6014\n",
      "Epoch [4/100], Step [3900/24597], Loss: 1.5862\n",
      "Epoch [4/100], Step [4000/24597], Loss: 1.6891\n",
      "Epoch [4/100], Step [4100/24597], Loss: 1.5159\n",
      "Epoch [4/100], Step [4200/24597], Loss: 1.6235\n",
      "Epoch [4/100], Step [4300/24597], Loss: 1.8006\n",
      "Epoch [4/100], Step [4400/24597], Loss: 1.7369\n",
      "Epoch [4/100], Step [4500/24597], Loss: 1.6262\n",
      "Epoch [4/100], Step [4600/24597], Loss: 1.8214\n",
      "Epoch [4/100], Step [4700/24597], Loss: 1.6784\n",
      "Epoch [4/100], Step [4800/24597], Loss: 1.5973\n",
      "Epoch [4/100], Step [4900/24597], Loss: 1.5116\n",
      "Epoch [4/100], Step [5000/24597], Loss: 1.4181\n",
      "Epoch [4/100], Step [5100/24597], Loss: 1.8930\n",
      "Epoch [4/100], Step [5200/24597], Loss: 1.4701\n",
      "Epoch [4/100], Step [5300/24597], Loss: 1.5307\n",
      "Epoch [4/100], Step [5400/24597], Loss: 1.5665\n",
      "Epoch [4/100], Step [5500/24597], Loss: 1.6367\n",
      "Epoch [4/100], Step [5600/24597], Loss: 1.6115\n",
      "Epoch [4/100], Step [5700/24597], Loss: 1.7582\n",
      "Epoch [4/100], Step [5800/24597], Loss: 1.7721\n",
      "Epoch [4/100], Step [5900/24597], Loss: 1.5448\n",
      "Epoch [4/100], Step [6000/24597], Loss: 1.5324\n",
      "Epoch [4/100], Step [6100/24597], Loss: 1.6505\n",
      "Epoch [4/100], Step [6200/24597], Loss: 1.6747\n",
      "Epoch [4/100], Step [6300/24597], Loss: 1.7101\n",
      "Epoch [4/100], Step [6400/24597], Loss: 1.5249\n",
      "Epoch [4/100], Step [6500/24597], Loss: 1.5722\n",
      "Epoch [4/100], Step [6600/24597], Loss: 1.5917\n",
      "Epoch [4/100], Step [6700/24597], Loss: 1.6977\n",
      "Epoch [4/100], Step [6800/24597], Loss: 1.6333\n",
      "Epoch [4/100], Step [6900/24597], Loss: 1.7282\n",
      "Epoch [4/100], Step [7000/24597], Loss: 1.7090\n",
      "Epoch [4/100], Step [7100/24597], Loss: 1.5758\n",
      "Epoch [4/100], Step [7200/24597], Loss: 1.6763\n",
      "Epoch [4/100], Step [7300/24597], Loss: 1.8353\n",
      "Epoch [4/100], Step [7400/24597], Loss: 1.5487\n",
      "Epoch [4/100], Step [7500/24597], Loss: 1.6706\n",
      "Epoch [4/100], Step [7600/24597], Loss: 1.6816\n",
      "Epoch [4/100], Step [7700/24597], Loss: 1.5653\n",
      "Epoch [4/100], Step [7800/24597], Loss: 1.7046\n",
      "Epoch [4/100], Step [7900/24597], Loss: 1.7322\n",
      "Epoch [4/100], Step [8000/24597], Loss: 1.9158\n",
      "Epoch [4/100], Step [8100/24597], Loss: 1.7759\n",
      "Epoch [4/100], Step [8200/24597], Loss: 1.4378\n",
      "Epoch [4/100], Step [8300/24597], Loss: 1.6615\n",
      "Epoch [4/100], Step [8400/24597], Loss: 1.7155\n",
      "Epoch [4/100], Step [8500/24597], Loss: 1.7086\n",
      "Epoch [4/100], Step [8600/24597], Loss: 1.7017\n",
      "Epoch [4/100], Step [8700/24597], Loss: 1.6177\n",
      "Epoch [4/100], Step [8800/24597], Loss: 1.3199\n",
      "Epoch [4/100], Step [8900/24597], Loss: 1.6043\n",
      "Epoch [4/100], Step [9000/24597], Loss: 1.6788\n",
      "Epoch [4/100], Step [9100/24597], Loss: 1.5782\n",
      "Epoch [4/100], Step [9200/24597], Loss: 1.6457\n",
      "Epoch [4/100], Step [9300/24597], Loss: 1.9874\n",
      "Epoch [4/100], Step [9400/24597], Loss: 1.7765\n",
      "Epoch [4/100], Step [9500/24597], Loss: 1.6352\n",
      "Epoch [4/100], Step [9600/24597], Loss: 1.4102\n",
      "Epoch [4/100], Step [9700/24597], Loss: 1.4647\n",
      "Epoch [4/100], Step [9800/24597], Loss: 1.5359\n",
      "Epoch [4/100], Step [9900/24597], Loss: 1.6594\n",
      "Epoch [4/100], Step [10000/24597], Loss: 1.6496\n",
      "Epoch [4/100], Step [10100/24597], Loss: 1.5129\n",
      "Epoch [4/100], Step [10200/24597], Loss: 1.8842\n",
      "Epoch [4/100], Step [10300/24597], Loss: 1.6219\n",
      "Epoch [4/100], Step [10400/24597], Loss: 1.5578\n",
      "Epoch [4/100], Step [10500/24597], Loss: 1.6856\n",
      "Epoch [4/100], Step [10600/24597], Loss: 1.5539\n",
      "Epoch [4/100], Step [10700/24597], Loss: 1.7707\n",
      "Epoch [4/100], Step [10800/24597], Loss: 1.5823\n",
      "Epoch [4/100], Step [10900/24597], Loss: 1.7203\n",
      "Epoch [4/100], Step [11000/24597], Loss: 1.9158\n",
      "Epoch [4/100], Step [11100/24597], Loss: 1.7144\n",
      "Epoch [4/100], Step [11200/24597], Loss: 1.8081\n",
      "Epoch [4/100], Step [11300/24597], Loss: 1.6747\n",
      "Epoch [4/100], Step [11400/24597], Loss: 1.6550\n",
      "Epoch [4/100], Step [11500/24597], Loss: 1.7202\n",
      "Epoch [4/100], Step [11600/24597], Loss: 1.5154\n",
      "Epoch [4/100], Step [11700/24597], Loss: 1.6088\n",
      "Epoch [4/100], Step [11800/24597], Loss: 1.5809\n",
      "Epoch [4/100], Step [11900/24597], Loss: 1.6398\n",
      "Epoch [4/100], Step [12000/24597], Loss: 1.7151\n",
      "Epoch [4/100], Step [12100/24597], Loss: 1.9167\n",
      "Epoch [4/100], Step [12200/24597], Loss: 1.8152\n",
      "Epoch [4/100], Step [12300/24597], Loss: 1.5568\n",
      "Epoch [4/100], Step [12400/24597], Loss: 1.5894\n",
      "Epoch [4/100], Step [12500/24597], Loss: 1.5860\n",
      "Epoch [4/100], Step [12600/24597], Loss: 1.5749\n",
      "Epoch [4/100], Step [12700/24597], Loss: 1.4442\n",
      "Epoch [4/100], Step [12800/24597], Loss: 1.5661\n",
      "Epoch [4/100], Step [12900/24597], Loss: 1.7562\n",
      "Epoch [4/100], Step [13000/24597], Loss: 1.6056\n",
      "Epoch [4/100], Step [13100/24597], Loss: 1.6054\n",
      "Epoch [4/100], Step [13200/24597], Loss: 1.4953\n",
      "Epoch [4/100], Step [13300/24597], Loss: 1.5335\n",
      "Epoch [4/100], Step [13400/24597], Loss: 1.6249\n",
      "Epoch [4/100], Step [13500/24597], Loss: 1.7039\n",
      "Epoch [4/100], Step [13600/24597], Loss: 2.0202\n",
      "Epoch [4/100], Step [13700/24597], Loss: 1.5213\n",
      "Epoch [4/100], Step [13800/24597], Loss: 1.5381\n",
      "Epoch [4/100], Step [13900/24597], Loss: 1.5175\n",
      "Epoch [4/100], Step [14000/24597], Loss: 1.6028\n",
      "Epoch [4/100], Step [14100/24597], Loss: 1.5652\n",
      "Epoch [4/100], Step [14200/24597], Loss: 1.4992\n",
      "Epoch [4/100], Step [14300/24597], Loss: 1.6288\n",
      "Epoch [4/100], Step [14400/24597], Loss: 1.5530\n",
      "Epoch [4/100], Step [14500/24597], Loss: 1.6765\n",
      "Epoch [4/100], Step [14600/24597], Loss: 1.6719\n",
      "Epoch [4/100], Step [14700/24597], Loss: 1.7950\n",
      "Epoch [4/100], Step [14800/24597], Loss: 1.6181\n",
      "Epoch [4/100], Step [14900/24597], Loss: 1.6924\n",
      "Epoch [4/100], Step [15000/24597], Loss: 1.5642\n",
      "Epoch [4/100], Step [15100/24597], Loss: 1.5687\n",
      "Epoch [4/100], Step [15200/24597], Loss: 1.6990\n",
      "Epoch [4/100], Step [15300/24597], Loss: 1.5396\n",
      "Epoch [4/100], Step [15400/24597], Loss: 1.7232\n",
      "Epoch [4/100], Step [15500/24597], Loss: 1.6682\n",
      "Epoch [4/100], Step [15600/24597], Loss: 1.8345\n",
      "Epoch [4/100], Step [15700/24597], Loss: 1.6186\n",
      "Epoch [4/100], Step [15800/24597], Loss: 1.8454\n",
      "Epoch [4/100], Step [15900/24597], Loss: 1.3894\n",
      "Epoch [4/100], Step [16000/24597], Loss: 1.5308\n",
      "Epoch [4/100], Step [16100/24597], Loss: 1.5248\n",
      "Epoch [4/100], Step [16200/24597], Loss: 1.8035\n",
      "Epoch [4/100], Step [16300/24597], Loss: 1.3858\n",
      "Epoch [4/100], Step [16400/24597], Loss: 1.6525\n",
      "Epoch [4/100], Step [16500/24597], Loss: 1.4794\n",
      "Epoch [4/100], Step [16600/24597], Loss: 1.4286\n",
      "Epoch [4/100], Step [16700/24597], Loss: 1.7461\n",
      "Epoch [4/100], Step [16800/24597], Loss: 1.6572\n",
      "Epoch [4/100], Step [16900/24597], Loss: 1.6412\n",
      "Epoch [4/100], Step [17000/24597], Loss: 1.6173\n",
      "Epoch [4/100], Step [17100/24597], Loss: 1.6893\n",
      "Epoch [4/100], Step [17200/24597], Loss: 1.8126\n",
      "Epoch [4/100], Step [17300/24597], Loss: 1.5537\n",
      "Epoch [4/100], Step [17400/24597], Loss: 1.6861\n",
      "Epoch [4/100], Step [17500/24597], Loss: 1.6310\n",
      "Epoch [4/100], Step [17600/24597], Loss: 1.5772\n",
      "Epoch [4/100], Step [17700/24597], Loss: 1.6620\n",
      "Epoch [4/100], Step [17800/24597], Loss: 1.9325\n",
      "Epoch [4/100], Step [17900/24597], Loss: 1.6320\n",
      "Epoch [4/100], Step [18000/24597], Loss: 1.5764\n",
      "Epoch [4/100], Step [18100/24597], Loss: 1.5093\n",
      "Epoch [4/100], Step [18200/24597], Loss: 1.5688\n",
      "Epoch [4/100], Step [18300/24597], Loss: 1.6325\n",
      "Epoch [4/100], Step [18400/24597], Loss: 1.9485\n",
      "Epoch [4/100], Step [18500/24597], Loss: 1.4984\n",
      "Epoch [4/100], Step [18600/24597], Loss: 1.7488\n",
      "Epoch [4/100], Step [18700/24597], Loss: 1.6587\n",
      "Epoch [4/100], Step [18800/24597], Loss: 1.7187\n",
      "Epoch [4/100], Step [18900/24597], Loss: 1.9092\n",
      "Epoch [4/100], Step [19000/24597], Loss: 1.6684\n",
      "Epoch [4/100], Step [19100/24597], Loss: 1.6116\n",
      "Epoch [4/100], Step [19200/24597], Loss: 1.6381\n",
      "Epoch [4/100], Step [19300/24597], Loss: 1.6558\n",
      "Epoch [4/100], Step [19400/24597], Loss: 1.6258\n",
      "Epoch [4/100], Step [19500/24597], Loss: 1.6740\n",
      "Epoch [4/100], Step [19600/24597], Loss: 1.8019\n",
      "Epoch [4/100], Step [19700/24597], Loss: 1.7269\n",
      "Epoch [4/100], Step [19800/24597], Loss: 1.7050\n",
      "Epoch [4/100], Step [19900/24597], Loss: 1.5310\n",
      "Epoch [4/100], Step [20000/24597], Loss: 1.6642\n",
      "Epoch [4/100], Step [20100/24597], Loss: 1.5152\n",
      "Epoch [4/100], Step [20200/24597], Loss: 1.5936\n",
      "Epoch [4/100], Step [20300/24597], Loss: 1.4772\n",
      "Epoch [4/100], Step [20400/24597], Loss: 1.5420\n",
      "Epoch [4/100], Step [20500/24597], Loss: 1.4799\n",
      "Epoch [4/100], Step [20600/24597], Loss: 1.5309\n",
      "Epoch [4/100], Step [20700/24597], Loss: 1.5439\n",
      "Epoch [4/100], Step [20800/24597], Loss: 1.5937\n",
      "Epoch [4/100], Step [20900/24597], Loss: 1.5903\n",
      "Epoch [4/100], Step [21000/24597], Loss: 1.5399\n",
      "Epoch [4/100], Step [21100/24597], Loss: 1.4547\n",
      "Epoch [4/100], Step [21200/24597], Loss: 1.7546\n",
      "Epoch [4/100], Step [21300/24597], Loss: 1.6803\n",
      "Epoch [4/100], Step [21400/24597], Loss: 1.4950\n",
      "Epoch [4/100], Step [21500/24597], Loss: 1.5524\n",
      "Epoch [4/100], Step [21600/24597], Loss: 1.8992\n",
      "Epoch [4/100], Step [21700/24597], Loss: 1.6553\n",
      "Epoch [4/100], Step [21800/24597], Loss: 1.5121\n",
      "Epoch [4/100], Step [21900/24597], Loss: 1.6353\n",
      "Epoch [4/100], Step [22000/24597], Loss: 1.7332\n",
      "Epoch [4/100], Step [22100/24597], Loss: 1.7007\n",
      "Epoch [4/100], Step [22200/24597], Loss: 1.6997\n",
      "Epoch [4/100], Step [22300/24597], Loss: 1.7407\n",
      "Epoch [4/100], Step [22400/24597], Loss: 1.7887\n",
      "Epoch [4/100], Step [22500/24597], Loss: 1.5688\n",
      "Epoch [4/100], Step [22600/24597], Loss: 1.7699\n",
      "Epoch [4/100], Step [22700/24597], Loss: 1.5684\n",
      "Epoch [4/100], Step [22800/24597], Loss: 1.6405\n",
      "Epoch [4/100], Step [22900/24597], Loss: 1.5694\n",
      "Epoch [4/100], Step [23000/24597], Loss: 1.7054\n",
      "Epoch [4/100], Step [23100/24597], Loss: 1.6870\n",
      "Epoch [4/100], Step [23200/24597], Loss: 1.5467\n",
      "Epoch [4/100], Step [23300/24597], Loss: 1.6009\n",
      "Epoch [4/100], Step [23400/24597], Loss: 1.6156\n",
      "Epoch [4/100], Step [23500/24597], Loss: 1.7183\n",
      "Epoch [4/100], Step [23600/24597], Loss: 1.6280\n",
      "Epoch [4/100], Step [23700/24597], Loss: 1.6698\n",
      "Epoch [4/100], Step [23800/24597], Loss: 1.5523\n",
      "Epoch [4/100], Step [23900/24597], Loss: 1.6965\n",
      "Epoch [4/100], Step [24000/24597], Loss: 1.7923\n",
      "Epoch [4/100], Step [24100/24597], Loss: 1.6618\n",
      "Epoch [4/100], Step [24200/24597], Loss: 1.8803\n",
      "Epoch [4/100], Step [24300/24597], Loss: 1.7276\n",
      "Epoch [4/100], Step [24400/24597], Loss: 1.5760\n",
      "Epoch [4/100], Step [24500/24597], Loss: 1.5259\n",
      "Epoch [5/100], Step [100/24597], Loss: 1.6796\n",
      "Epoch [5/100], Step [200/24597], Loss: 1.9623\n",
      "Epoch [5/100], Step [300/24597], Loss: 1.4863\n",
      "Epoch [5/100], Step [400/24597], Loss: 1.6796\n",
      "Epoch [5/100], Step [500/24597], Loss: 1.3440\n",
      "Epoch [5/100], Step [600/24597], Loss: 1.4314\n",
      "Epoch [5/100], Step [700/24597], Loss: 1.6103\n",
      "Epoch [5/100], Step [800/24597], Loss: 1.4335\n",
      "Epoch [5/100], Step [900/24597], Loss: 1.6362\n",
      "Epoch [5/100], Step [1000/24597], Loss: 1.6806\n",
      "Epoch [5/100], Step [1100/24597], Loss: 1.6086\n",
      "Epoch [5/100], Step [1200/24597], Loss: 1.8124\n",
      "Epoch [5/100], Step [1300/24597], Loss: 1.6226\n",
      "Epoch [5/100], Step [1400/24597], Loss: 1.5595\n",
      "Epoch [5/100], Step [1500/24597], Loss: 1.5833\n",
      "Epoch [5/100], Step [1600/24597], Loss: 1.5356\n",
      "Epoch [5/100], Step [1700/24597], Loss: 1.6548\n",
      "Epoch [5/100], Step [1800/24597], Loss: 1.4869\n",
      "Epoch [5/100], Step [1900/24597], Loss: 1.6113\n",
      "Epoch [5/100], Step [2000/24597], Loss: 1.5305\n",
      "Epoch [5/100], Step [2100/24597], Loss: 1.6706\n",
      "Epoch [5/100], Step [2200/24597], Loss: 1.7614\n",
      "Epoch [5/100], Step [2300/24597], Loss: 1.6569\n",
      "Epoch [5/100], Step [2400/24597], Loss: 1.7829\n",
      "Epoch [5/100], Step [2500/24597], Loss: 1.5816\n",
      "Epoch [5/100], Step [2600/24597], Loss: 1.6819\n",
      "Epoch [5/100], Step [2700/24597], Loss: 1.7249\n",
      "Epoch [5/100], Step [2800/24597], Loss: 1.5905\n",
      "Epoch [5/100], Step [2900/24597], Loss: 1.5838\n",
      "Epoch [5/100], Step [3000/24597], Loss: 1.5718\n",
      "Epoch [5/100], Step [3100/24597], Loss: 1.4838\n",
      "Epoch [5/100], Step [3200/24597], Loss: 1.5653\n",
      "Epoch [5/100], Step [3300/24597], Loss: 1.6103\n",
      "Epoch [5/100], Step [3400/24597], Loss: 1.8636\n",
      "Epoch [5/100], Step [3500/24597], Loss: 1.7623\n",
      "Epoch [5/100], Step [3600/24597], Loss: 1.5967\n",
      "Epoch [5/100], Step [3700/24597], Loss: 1.4413\n",
      "Epoch [5/100], Step [3800/24597], Loss: 1.7358\n",
      "Epoch [5/100], Step [3900/24597], Loss: 1.8085\n",
      "Epoch [5/100], Step [4000/24597], Loss: 1.6869\n",
      "Epoch [5/100], Step [4100/24597], Loss: 1.8407\n",
      "Epoch [5/100], Step [4200/24597], Loss: 1.7106\n",
      "Epoch [5/100], Step [4300/24597], Loss: 1.5985\n",
      "Epoch [5/100], Step [4400/24597], Loss: 1.6281\n",
      "Epoch [5/100], Step [4500/24597], Loss: 1.5387\n",
      "Epoch [5/100], Step [4600/24597], Loss: 1.5902\n",
      "Epoch [5/100], Step [4700/24597], Loss: 1.4965\n",
      "Epoch [5/100], Step [4800/24597], Loss: 1.4962\n",
      "Epoch [5/100], Step [4900/24597], Loss: 1.6564\n",
      "Epoch [5/100], Step [5000/24597], Loss: 1.6393\n",
      "Epoch [5/100], Step [5100/24597], Loss: 1.6185\n",
      "Epoch [5/100], Step [5200/24597], Loss: 1.8160\n",
      "Epoch [5/100], Step [5300/24597], Loss: 1.6355\n",
      "Epoch [5/100], Step [5400/24597], Loss: 1.5783\n",
      "Epoch [5/100], Step [5500/24597], Loss: 1.5841\n",
      "Epoch [5/100], Step [5600/24597], Loss: 1.5893\n",
      "Epoch [5/100], Step [5700/24597], Loss: 1.5834\n",
      "Epoch [5/100], Step [5800/24597], Loss: 1.7030\n",
      "Epoch [5/100], Step [5900/24597], Loss: 1.5184\n",
      "Epoch [5/100], Step [6000/24597], Loss: 1.8170\n",
      "Epoch [5/100], Step [6100/24597], Loss: 1.4805\n",
      "Epoch [5/100], Step [6200/24597], Loss: 1.5886\n",
      "Epoch [5/100], Step [6300/24597], Loss: 1.6397\n",
      "Epoch [5/100], Step [6400/24597], Loss: 1.4791\n",
      "Epoch [5/100], Step [6500/24597], Loss: 1.6462\n",
      "Epoch [5/100], Step [6600/24597], Loss: 1.6010\n",
      "Epoch [5/100], Step [6700/24597], Loss: 1.7878\n",
      "Epoch [5/100], Step [6800/24597], Loss: 1.6450\n",
      "Epoch [5/100], Step [6900/24597], Loss: 1.7236\n",
      "Epoch [5/100], Step [7000/24597], Loss: 1.6190\n",
      "Epoch [5/100], Step [7100/24597], Loss: 1.6845\n",
      "Epoch [5/100], Step [7200/24597], Loss: 1.5667\n",
      "Epoch [5/100], Step [7300/24597], Loss: 1.6611\n",
      "Epoch [5/100], Step [7400/24597], Loss: 1.5661\n",
      "Epoch [5/100], Step [7500/24597], Loss: 1.5912\n",
      "Epoch [5/100], Step [7600/24597], Loss: 1.5035\n",
      "Epoch [5/100], Step [7700/24597], Loss: 1.6130\n",
      "Epoch [5/100], Step [7800/24597], Loss: 1.6818\n",
      "Epoch [5/100], Step [7900/24597], Loss: 1.5503\n",
      "Epoch [5/100], Step [8000/24597], Loss: 1.6568\n",
      "Epoch [5/100], Step [8100/24597], Loss: 1.7297\n",
      "Epoch [5/100], Step [8200/24597], Loss: 1.6729\n",
      "Epoch [5/100], Step [8300/24597], Loss: 1.4902\n",
      "Epoch [5/100], Step [8400/24597], Loss: 1.6308\n",
      "Epoch [5/100], Step [8500/24597], Loss: 1.5687\n",
      "Epoch [5/100], Step [8600/24597], Loss: 1.5441\n",
      "Epoch [5/100], Step [8700/24597], Loss: 1.6437\n",
      "Epoch [5/100], Step [8800/24597], Loss: 1.6040\n",
      "Epoch [5/100], Step [8900/24597], Loss: 1.6971\n",
      "Epoch [5/100], Step [9000/24597], Loss: 1.4790\n",
      "Epoch [5/100], Step [9100/24597], Loss: 1.9229\n",
      "Epoch [5/100], Step [9200/24597], Loss: 1.7014\n",
      "Epoch [5/100], Step [9300/24597], Loss: 1.9257\n",
      "Epoch [5/100], Step [9400/24597], Loss: 1.6300\n",
      "Epoch [5/100], Step [9500/24597], Loss: 1.5803\n",
      "Epoch [5/100], Step [9600/24597], Loss: 1.6378\n",
      "Epoch [5/100], Step [9700/24597], Loss: 1.6296\n",
      "Epoch [5/100], Step [9800/24597], Loss: 1.7738\n",
      "Epoch [5/100], Step [9900/24597], Loss: 1.7574\n",
      "Epoch [5/100], Step [10000/24597], Loss: 1.5427\n",
      "Epoch [5/100], Step [10100/24597], Loss: 1.7623\n",
      "Epoch [5/100], Step [10200/24597], Loss: 1.5760\n",
      "Epoch [5/100], Step [10300/24597], Loss: 1.9303\n",
      "Epoch [5/100], Step [10400/24597], Loss: 1.5979\n",
      "Epoch [5/100], Step [10500/24597], Loss: 1.7519\n",
      "Epoch [5/100], Step [10600/24597], Loss: 1.5120\n",
      "Epoch [5/100], Step [10700/24597], Loss: 1.6769\n",
      "Epoch [5/100], Step [10800/24597], Loss: 1.6439\n",
      "Epoch [5/100], Step [10900/24597], Loss: 1.5964\n",
      "Epoch [5/100], Step [11000/24597], Loss: 1.5220\n",
      "Epoch [5/100], Step [11100/24597], Loss: 1.7384\n",
      "Epoch [5/100], Step [11200/24597], Loss: 1.5449\n",
      "Epoch [5/100], Step [11300/24597], Loss: 1.5351\n",
      "Epoch [5/100], Step [11400/24597], Loss: 1.5162\n",
      "Epoch [5/100], Step [11500/24597], Loss: 1.6077\n",
      "Epoch [5/100], Step [11600/24597], Loss: 1.6874\n",
      "Epoch [5/100], Step [11700/24597], Loss: 1.7288\n",
      "Epoch [5/100], Step [11800/24597], Loss: 1.4671\n",
      "Epoch [5/100], Step [11900/24597], Loss: 1.6211\n",
      "Epoch [5/100], Step [12000/24597], Loss: 1.6781\n",
      "Epoch [5/100], Step [12100/24597], Loss: 1.5667\n",
      "Epoch [5/100], Step [12200/24597], Loss: 1.4174\n",
      "Epoch [5/100], Step [12300/24597], Loss: 1.7429\n",
      "Epoch [5/100], Step [12400/24597], Loss: 1.7671\n",
      "Epoch [5/100], Step [12500/24597], Loss: 1.4951\n",
      "Epoch [5/100], Step [12600/24597], Loss: 1.6321\n",
      "Epoch [5/100], Step [12700/24597], Loss: 1.9346\n",
      "Epoch [5/100], Step [12800/24597], Loss: 1.9012\n",
      "Epoch [5/100], Step [12900/24597], Loss: 1.4901\n",
      "Epoch [5/100], Step [13000/24597], Loss: 1.6125\n",
      "Epoch [5/100], Step [13100/24597], Loss: 1.5929\n",
      "Epoch [5/100], Step [13200/24597], Loss: 1.8896\n",
      "Epoch [5/100], Step [13300/24597], Loss: 1.7769\n",
      "Epoch [5/100], Step [13400/24597], Loss: 1.4963\n",
      "Epoch [5/100], Step [13500/24597], Loss: 1.8060\n",
      "Epoch [5/100], Step [13600/24597], Loss: 1.7079\n",
      "Epoch [5/100], Step [13700/24597], Loss: 1.5764\n",
      "Epoch [5/100], Step [13800/24597], Loss: 1.8348\n",
      "Epoch [5/100], Step [13900/24597], Loss: 1.7724\n",
      "Epoch [5/100], Step [14000/24597], Loss: 1.6344\n",
      "Epoch [5/100], Step [14100/24597], Loss: 1.6471\n",
      "Epoch [5/100], Step [14200/24597], Loss: 1.5997\n",
      "Epoch [5/100], Step [14300/24597], Loss: 1.6809\n",
      "Epoch [5/100], Step [14400/24597], Loss: 1.5543\n",
      "Epoch [5/100], Step [14500/24597], Loss: 2.1128\n",
      "Epoch [5/100], Step [14600/24597], Loss: 1.8100\n",
      "Epoch [5/100], Step [14700/24597], Loss: 1.4968\n",
      "Epoch [5/100], Step [14800/24597], Loss: 1.8672\n",
      "Epoch [5/100], Step [14900/24597], Loss: 1.5318\n",
      "Epoch [5/100], Step [15000/24597], Loss: 1.6051\n",
      "Epoch [5/100], Step [15100/24597], Loss: 1.6174\n",
      "Epoch [5/100], Step [15200/24597], Loss: 1.5479\n",
      "Epoch [5/100], Step [15300/24597], Loss: 1.7346\n",
      "Epoch [5/100], Step [15400/24597], Loss: 1.6335\n",
      "Epoch [5/100], Step [15500/24597], Loss: 1.5135\n",
      "Epoch [5/100], Step [15600/24597], Loss: 1.6893\n",
      "Epoch [5/100], Step [15700/24597], Loss: 1.5770\n",
      "Epoch [5/100], Step [15800/24597], Loss: 1.9924\n",
      "Epoch [5/100], Step [15900/24597], Loss: 1.7074\n",
      "Epoch [5/100], Step [16000/24597], Loss: 1.5897\n",
      "Epoch [5/100], Step [16100/24597], Loss: 1.7856\n",
      "Epoch [5/100], Step [16200/24597], Loss: 1.5827\n",
      "Epoch [5/100], Step [16300/24597], Loss: 1.5677\n",
      "Epoch [5/100], Step [16400/24597], Loss: 1.6096\n",
      "Epoch [5/100], Step [16500/24597], Loss: 1.8159\n",
      "Epoch [5/100], Step [16600/24597], Loss: 1.6479\n",
      "Epoch [5/100], Step [16700/24597], Loss: 1.7877\n",
      "Epoch [5/100], Step [16800/24597], Loss: 1.5767\n",
      "Epoch [5/100], Step [16900/24597], Loss: 1.6282\n",
      "Epoch [5/100], Step [17000/24597], Loss: 1.7219\n",
      "Epoch [5/100], Step [17100/24597], Loss: 1.4550\n",
      "Epoch [5/100], Step [17200/24597], Loss: 1.3715\n",
      "Epoch [5/100], Step [17300/24597], Loss: 1.5532\n",
      "Epoch [5/100], Step [17400/24597], Loss: 1.4657\n",
      "Epoch [5/100], Step [17500/24597], Loss: 1.8250\n",
      "Epoch [5/100], Step [17600/24597], Loss: 1.5103\n",
      "Epoch [5/100], Step [17700/24597], Loss: 1.3200\n",
      "Epoch [5/100], Step [17800/24597], Loss: 1.5294\n",
      "Epoch [5/100], Step [17900/24597], Loss: 1.7727\n",
      "Epoch [5/100], Step [18000/24597], Loss: 1.6994\n",
      "Epoch [5/100], Step [18100/24597], Loss: 1.6099\n",
      "Epoch [5/100], Step [18200/24597], Loss: 1.5272\n",
      "Epoch [5/100], Step [18300/24597], Loss: 1.4885\n",
      "Epoch [5/100], Step [18400/24597], Loss: 1.4708\n",
      "Epoch [5/100], Step [18500/24597], Loss: 1.5742\n",
      "Epoch [5/100], Step [18600/24597], Loss: 1.4364\n",
      "Epoch [5/100], Step [18700/24597], Loss: 1.6328\n",
      "Epoch [5/100], Step [18800/24597], Loss: 1.8502\n",
      "Epoch [5/100], Step [18900/24597], Loss: 1.5677\n",
      "Epoch [5/100], Step [19000/24597], Loss: 1.7759\n",
      "Epoch [5/100], Step [19100/24597], Loss: 1.6817\n",
      "Epoch [5/100], Step [19200/24597], Loss: 1.6503\n",
      "Epoch [5/100], Step [19300/24597], Loss: 1.4191\n",
      "Epoch [5/100], Step [19400/24597], Loss: 1.6651\n",
      "Epoch [5/100], Step [19500/24597], Loss: 1.5547\n",
      "Epoch [5/100], Step [19600/24597], Loss: 1.8595\n",
      "Epoch [5/100], Step [19700/24597], Loss: 1.7689\n",
      "Epoch [5/100], Step [19800/24597], Loss: 1.5918\n",
      "Epoch [5/100], Step [19900/24597], Loss: 1.6540\n",
      "Epoch [5/100], Step [20000/24597], Loss: 1.3853\n",
      "Epoch [5/100], Step [20100/24597], Loss: 1.7759\n",
      "Epoch [5/100], Step [20200/24597], Loss: 1.7585\n",
      "Epoch [5/100], Step [20300/24597], Loss: 1.6941\n",
      "Epoch [5/100], Step [20400/24597], Loss: 1.6312\n",
      "Epoch [5/100], Step [20500/24597], Loss: 1.5052\n",
      "Epoch [5/100], Step [20600/24597], Loss: 1.4769\n",
      "Epoch [5/100], Step [20700/24597], Loss: 1.6451\n",
      "Epoch [5/100], Step [20800/24597], Loss: 1.5246\n",
      "Epoch [5/100], Step [20900/24597], Loss: 1.5917\n",
      "Epoch [5/100], Step [21000/24597], Loss: 1.6118\n",
      "Epoch [5/100], Step [21100/24597], Loss: 1.7462\n",
      "Epoch [5/100], Step [21200/24597], Loss: 1.6885\n",
      "Epoch [5/100], Step [21300/24597], Loss: 1.6392\n",
      "Epoch [5/100], Step [21400/24597], Loss: 1.6354\n",
      "Epoch [5/100], Step [21500/24597], Loss: 1.7010\n",
      "Epoch [5/100], Step [21600/24597], Loss: 1.6947\n",
      "Epoch [5/100], Step [21700/24597], Loss: 1.5615\n",
      "Epoch [5/100], Step [21800/24597], Loss: 1.6080\n",
      "Epoch [5/100], Step [21900/24597], Loss: 1.6574\n",
      "Epoch [5/100], Step [22000/24597], Loss: 1.6600\n",
      "Epoch [5/100], Step [22100/24597], Loss: 1.5734\n",
      "Epoch [5/100], Step [22200/24597], Loss: 1.5316\n",
      "Epoch [5/100], Step [22300/24597], Loss: 1.7011\n",
      "Epoch [5/100], Step [22400/24597], Loss: 1.5034\n",
      "Epoch [5/100], Step [22500/24597], Loss: 1.6309\n",
      "Epoch [5/100], Step [22600/24597], Loss: 1.6431\n",
      "Epoch [5/100], Step [22700/24597], Loss: 1.5363\n",
      "Epoch [5/100], Step [22800/24597], Loss: 1.5537\n",
      "Epoch [5/100], Step [22900/24597], Loss: 1.5439\n",
      "Epoch [5/100], Step [23000/24597], Loss: 1.6741\n",
      "Epoch [5/100], Step [23100/24597], Loss: 1.3295\n",
      "Epoch [5/100], Step [23200/24597], Loss: 1.7270\n",
      "Epoch [5/100], Step [23300/24597], Loss: 1.8487\n",
      "Epoch [5/100], Step [23400/24597], Loss: 1.4394\n",
      "Epoch [5/100], Step [23500/24597], Loss: 1.2646\n",
      "Epoch [5/100], Step [23600/24597], Loss: 1.7186\n",
      "Epoch [5/100], Step [23700/24597], Loss: 1.6220\n",
      "Epoch [5/100], Step [23800/24597], Loss: 1.9331\n",
      "Epoch [5/100], Step [23900/24597], Loss: 1.6431\n",
      "Epoch [5/100], Step [24000/24597], Loss: 1.8171\n",
      "Epoch [5/100], Step [24100/24597], Loss: 1.5715\n",
      "Epoch [5/100], Step [24200/24597], Loss: 1.7381\n",
      "Epoch [5/100], Step [24300/24597], Loss: 1.6254\n",
      "Epoch [5/100], Step [24400/24597], Loss: 1.8265\n",
      "Epoch [5/100], Step [24500/24597], Loss: 1.6167\n",
      "Epoch [6/100], Step [100/24597], Loss: 1.6702\n",
      "Epoch [6/100], Step [200/24597], Loss: 1.7537\n",
      "Epoch [6/100], Step [300/24597], Loss: 1.6991\n",
      "Epoch [6/100], Step [400/24597], Loss: 1.6356\n",
      "Epoch [6/100], Step [500/24597], Loss: 1.6732\n",
      "Epoch [6/100], Step [600/24597], Loss: 1.8163\n",
      "Epoch [6/100], Step [700/24597], Loss: 1.7961\n",
      "Epoch [6/100], Step [800/24597], Loss: 1.6533\n",
      "Epoch [6/100], Step [900/24597], Loss: 1.6038\n",
      "Epoch [6/100], Step [1000/24597], Loss: 1.6421\n",
      "Epoch [6/100], Step [1100/24597], Loss: 1.6404\n",
      "Epoch [6/100], Step [1200/24597], Loss: 1.5307\n",
      "Epoch [6/100], Step [1300/24597], Loss: 1.6164\n",
      "Epoch [6/100], Step [1400/24597], Loss: 1.7738\n",
      "Epoch [6/100], Step [1500/24597], Loss: 1.5108\n",
      "Epoch [6/100], Step [1600/24597], Loss: 1.3998\n",
      "Epoch [6/100], Step [1700/24597], Loss: 1.7070\n",
      "Epoch [6/100], Step [1800/24597], Loss: 1.5725\n",
      "Epoch [6/100], Step [1900/24597], Loss: 1.7545\n",
      "Epoch [6/100], Step [2000/24597], Loss: 1.4977\n",
      "Epoch [6/100], Step [2100/24597], Loss: 1.6191\n",
      "Epoch [6/100], Step [2200/24597], Loss: 1.7427\n",
      "Epoch [6/100], Step [2300/24597], Loss: 1.5372\n",
      "Epoch [6/100], Step [2400/24597], Loss: 1.6988\n",
      "Epoch [6/100], Step [2500/24597], Loss: 1.6013\n",
      "Epoch [6/100], Step [2600/24597], Loss: 1.4739\n",
      "Epoch [6/100], Step [2700/24597], Loss: 1.7545\n",
      "Epoch [6/100], Step [2800/24597], Loss: 1.7840\n",
      "Epoch [6/100], Step [2900/24597], Loss: 1.5153\n",
      "Epoch [6/100], Step [3000/24597], Loss: 1.6704\n",
      "Epoch [6/100], Step [3100/24597], Loss: 1.6765\n",
      "Epoch [6/100], Step [3200/24597], Loss: 1.6143\n",
      "Epoch [6/100], Step [3300/24597], Loss: 1.6029\n",
      "Epoch [6/100], Step [3400/24597], Loss: 1.5225\n",
      "Epoch [6/100], Step [3500/24597], Loss: 1.5338\n",
      "Epoch [6/100], Step [3600/24597], Loss: 1.3273\n",
      "Epoch [6/100], Step [3700/24597], Loss: 1.5604\n",
      "Epoch [6/100], Step [3800/24597], Loss: 1.5275\n",
      "Epoch [6/100], Step [3900/24597], Loss: 1.8659\n",
      "Epoch [6/100], Step [4000/24597], Loss: 1.6933\n",
      "Epoch [6/100], Step [4100/24597], Loss: 1.5836\n",
      "Epoch [6/100], Step [4200/24597], Loss: 1.7728\n",
      "Epoch [6/100], Step [4300/24597], Loss: 1.5400\n",
      "Epoch [6/100], Step [4400/24597], Loss: 1.6771\n",
      "Epoch [6/100], Step [4500/24597], Loss: 1.8988\n",
      "Epoch [6/100], Step [4600/24597], Loss: 1.5571\n",
      "Epoch [6/100], Step [4700/24597], Loss: 1.9264\n",
      "Epoch [6/100], Step [4800/24597], Loss: 1.5987\n",
      "Epoch [6/100], Step [4900/24597], Loss: 1.8351\n",
      "Epoch [6/100], Step [5000/24597], Loss: 1.8007\n",
      "Epoch [6/100], Step [5100/24597], Loss: 1.4469\n",
      "Epoch [6/100], Step [5200/24597], Loss: 1.7726\n",
      "Epoch [6/100], Step [5300/24597], Loss: 1.9179\n",
      "Epoch [6/100], Step [5400/24597], Loss: 1.5711\n",
      "Epoch [6/100], Step [5500/24597], Loss: 1.7043\n",
      "Epoch [6/100], Step [5600/24597], Loss: 1.7710\n",
      "Epoch [6/100], Step [5700/24597], Loss: 1.8562\n",
      "Epoch [6/100], Step [5800/24597], Loss: 1.6438\n",
      "Epoch [6/100], Step [5900/24597], Loss: 1.6952\n",
      "Epoch [6/100], Step [6000/24597], Loss: 1.7499\n",
      "Epoch [6/100], Step [6100/24597], Loss: 1.5863\n",
      "Epoch [6/100], Step [6200/24597], Loss: 1.3714\n",
      "Epoch [6/100], Step [6300/24597], Loss: 1.8061\n",
      "Epoch [6/100], Step [6400/24597], Loss: 1.7642\n",
      "Epoch [6/100], Step [6500/24597], Loss: 1.5255\n",
      "Epoch [6/100], Step [6600/24597], Loss: 1.4661\n",
      "Epoch [6/100], Step [6700/24597], Loss: 1.5184\n",
      "Epoch [6/100], Step [6800/24597], Loss: 1.6558\n",
      "Epoch [6/100], Step [6900/24597], Loss: 1.6534\n",
      "Epoch [6/100], Step [7000/24597], Loss: 1.5896\n",
      "Epoch [6/100], Step [7100/24597], Loss: 1.5432\n",
      "Epoch [6/100], Step [7200/24597], Loss: 1.9864\n",
      "Epoch [6/100], Step [7300/24597], Loss: 1.6357\n",
      "Epoch [6/100], Step [7400/24597], Loss: 1.6157\n",
      "Epoch [6/100], Step [7500/24597], Loss: 1.9174\n",
      "Epoch [6/100], Step [7600/24597], Loss: 1.8290\n",
      "Epoch [6/100], Step [7700/24597], Loss: 1.3876\n",
      "Epoch [6/100], Step [7800/24597], Loss: 1.7214\n",
      "Epoch [6/100], Step [7900/24597], Loss: 1.7465\n",
      "Epoch [6/100], Step [8000/24597], Loss: 1.6884\n",
      "Epoch [6/100], Step [8100/24597], Loss: 1.6006\n",
      "Epoch [6/100], Step [8200/24597], Loss: 1.8111\n",
      "Epoch [6/100], Step [8300/24597], Loss: 1.7029\n",
      "Epoch [6/100], Step [8400/24597], Loss: 1.6963\n",
      "Epoch [6/100], Step [8500/24597], Loss: 1.6627\n",
      "Epoch [6/100], Step [8600/24597], Loss: 1.6743\n",
      "Epoch [6/100], Step [8700/24597], Loss: 1.8400\n",
      "Epoch [6/100], Step [8800/24597], Loss: 1.5162\n",
      "Epoch [6/100], Step [8900/24597], Loss: 1.6655\n",
      "Epoch [6/100], Step [9000/24597], Loss: 1.8183\n",
      "Epoch [6/100], Step [9100/24597], Loss: 1.6271\n",
      "Epoch [6/100], Step [9200/24597], Loss: 1.5418\n",
      "Epoch [6/100], Step [9300/24597], Loss: 1.5368\n",
      "Epoch [6/100], Step [9400/24597], Loss: 1.6655\n",
      "Epoch [6/100], Step [9500/24597], Loss: 1.7656\n",
      "Epoch [6/100], Step [9600/24597], Loss: 1.6369\n",
      "Epoch [6/100], Step [9700/24597], Loss: 1.6165\n",
      "Epoch [6/100], Step [9800/24597], Loss: 1.8229\n",
      "Epoch [6/100], Step [9900/24597], Loss: 1.5592\n",
      "Epoch [6/100], Step [10000/24597], Loss: 1.5709\n",
      "Epoch [6/100], Step [10100/24597], Loss: 1.6337\n",
      "Epoch [6/100], Step [10200/24597], Loss: 1.5833\n",
      "Epoch [6/100], Step [10300/24597], Loss: 1.6127\n",
      "Epoch [6/100], Step [10400/24597], Loss: 1.6117\n",
      "Epoch [6/100], Step [10500/24597], Loss: 1.5945\n",
      "Epoch [6/100], Step [10600/24597], Loss: 1.6824\n",
      "Epoch [6/100], Step [10700/24597], Loss: 1.7366\n",
      "Epoch [6/100], Step [10800/24597], Loss: 1.6858\n",
      "Epoch [6/100], Step [10900/24597], Loss: 1.6054\n",
      "Epoch [6/100], Step [11000/24597], Loss: 1.3776\n",
      "Epoch [6/100], Step [11100/24597], Loss: 1.6984\n",
      "Epoch [6/100], Step [11200/24597], Loss: 1.7130\n",
      "Epoch [6/100], Step [11300/24597], Loss: 1.5353\n",
      "Epoch [6/100], Step [11400/24597], Loss: 1.6519\n",
      "Epoch [6/100], Step [11500/24597], Loss: 1.5461\n",
      "Epoch [6/100], Step [11600/24597], Loss: 1.9296\n",
      "Epoch [6/100], Step [11700/24597], Loss: 1.4083\n",
      "Epoch [6/100], Step [11800/24597], Loss: 1.8056\n",
      "Epoch [6/100], Step [11900/24597], Loss: 1.4943\n",
      "Epoch [6/100], Step [12000/24597], Loss: 1.7138\n",
      "Epoch [6/100], Step [12100/24597], Loss: 1.5498\n",
      "Epoch [6/100], Step [12200/24597], Loss: 1.5907\n",
      "Epoch [6/100], Step [12300/24597], Loss: 1.6750\n",
      "Epoch [6/100], Step [12400/24597], Loss: 1.7867\n",
      "Epoch [6/100], Step [12500/24597], Loss: 1.5873\n",
      "Epoch [6/100], Step [12600/24597], Loss: 1.5459\n",
      "Epoch [6/100], Step [12700/24597], Loss: 1.5897\n",
      "Epoch [6/100], Step [12800/24597], Loss: 1.7916\n",
      "Epoch [6/100], Step [12900/24597], Loss: 1.7575\n",
      "Epoch [6/100], Step [13000/24597], Loss: 1.5990\n",
      "Epoch [6/100], Step [13100/24597], Loss: 1.6055\n",
      "Epoch [6/100], Step [13200/24597], Loss: 1.5736\n",
      "Epoch [6/100], Step [13300/24597], Loss: 1.5846\n",
      "Epoch [6/100], Step [13400/24597], Loss: 1.6974\n",
      "Epoch [6/100], Step [13500/24597], Loss: 1.6975\n",
      "Epoch [6/100], Step [13600/24597], Loss: 1.6594\n",
      "Epoch [6/100], Step [13700/24597], Loss: 1.5864\n",
      "Epoch [6/100], Step [13800/24597], Loss: 1.7399\n",
      "Epoch [6/100], Step [13900/24597], Loss: 1.4763\n",
      "Epoch [6/100], Step [14000/24597], Loss: 1.5175\n",
      "Epoch [6/100], Step [14100/24597], Loss: 1.5479\n",
      "Epoch [6/100], Step [14200/24597], Loss: 1.7072\n",
      "Epoch [6/100], Step [14300/24597], Loss: 1.8893\n",
      "Epoch [6/100], Step [14400/24597], Loss: 1.8100\n",
      "Epoch [6/100], Step [14500/24597], Loss: 1.6665\n",
      "Epoch [6/100], Step [14600/24597], Loss: 1.7947\n",
      "Epoch [6/100], Step [14700/24597], Loss: 1.4689\n",
      "Epoch [6/100], Step [14800/24597], Loss: 1.5968\n",
      "Epoch [6/100], Step [14900/24597], Loss: 1.7227\n",
      "Epoch [6/100], Step [15000/24597], Loss: 1.5091\n",
      "Epoch [6/100], Step [15100/24597], Loss: 1.5095\n",
      "Epoch [6/100], Step [15200/24597], Loss: 1.5028\n",
      "Epoch [6/100], Step [15300/24597], Loss: 1.7806\n",
      "Epoch [6/100], Step [15400/24597], Loss: 1.3936\n",
      "Epoch [6/100], Step [15500/24597], Loss: 1.7011\n",
      "Epoch [6/100], Step [15600/24597], Loss: 1.4820\n",
      "Epoch [6/100], Step [15700/24597], Loss: 1.7727\n",
      "Epoch [6/100], Step [15800/24597], Loss: 1.5234\n",
      "Epoch [6/100], Step [15900/24597], Loss: 1.7360\n",
      "Epoch [6/100], Step [16000/24597], Loss: 1.7283\n",
      "Epoch [6/100], Step [16100/24597], Loss: 1.6847\n",
      "Epoch [6/100], Step [16200/24597], Loss: 1.6408\n",
      "Epoch [6/100], Step [16300/24597], Loss: 1.5450\n",
      "Epoch [6/100], Step [16400/24597], Loss: 1.5585\n",
      "Epoch [6/100], Step [16500/24597], Loss: 1.7516\n",
      "Epoch [6/100], Step [16600/24597], Loss: 1.8814\n",
      "Epoch [6/100], Step [16700/24597], Loss: 1.6962\n",
      "Epoch [6/100], Step [16800/24597], Loss: 1.6105\n",
      "Epoch [6/100], Step [16900/24597], Loss: 1.6864\n",
      "Epoch [6/100], Step [17000/24597], Loss: 1.7083\n",
      "Epoch [6/100], Step [17100/24597], Loss: 1.5624\n",
      "Epoch [6/100], Step [17200/24597], Loss: 1.6380\n",
      "Epoch [6/100], Step [17300/24597], Loss: 1.6864\n",
      "Epoch [6/100], Step [17400/24597], Loss: 1.7970\n",
      "Epoch [6/100], Step [17500/24597], Loss: 1.4400\n",
      "Epoch [6/100], Step [17600/24597], Loss: 1.7722\n",
      "Epoch [6/100], Step [17700/24597], Loss: 1.4587\n",
      "Epoch [6/100], Step [17800/24597], Loss: 1.5537\n",
      "Epoch [6/100], Step [17900/24597], Loss: 1.7789\n",
      "Epoch [6/100], Step [18000/24597], Loss: 1.5660\n",
      "Epoch [6/100], Step [18100/24597], Loss: 1.4556\n",
      "Epoch [6/100], Step [18200/24597], Loss: 1.6475\n",
      "Epoch [6/100], Step [18300/24597], Loss: 1.6811\n",
      "Epoch [6/100], Step [18400/24597], Loss: 1.5188\n",
      "Epoch [6/100], Step [18500/24597], Loss: 1.5250\n",
      "Epoch [6/100], Step [18600/24597], Loss: 1.5571\n",
      "Epoch [6/100], Step [18700/24597], Loss: 1.5866\n",
      "Epoch [6/100], Step [18800/24597], Loss: 1.7613\n",
      "Epoch [6/100], Step [18900/24597], Loss: 1.5231\n",
      "Epoch [6/100], Step [19000/24597], Loss: 1.7366\n",
      "Epoch [6/100], Step [19100/24597], Loss: 1.3991\n",
      "Epoch [6/100], Step [19200/24597], Loss: 1.6909\n",
      "Epoch [6/100], Step [19300/24597], Loss: 1.7925\n",
      "Epoch [6/100], Step [19400/24597], Loss: 1.5712\n",
      "Epoch [6/100], Step [19500/24597], Loss: 2.0213\n",
      "Epoch [6/100], Step [19600/24597], Loss: 1.6589\n",
      "Epoch [6/100], Step [19700/24597], Loss: 1.7006\n",
      "Epoch [6/100], Step [19800/24597], Loss: 1.6049\n",
      "Epoch [6/100], Step [19900/24597], Loss: 1.6437\n",
      "Epoch [6/100], Step [20000/24597], Loss: 1.7007\n",
      "Epoch [6/100], Step [20100/24597], Loss: 1.7241\n",
      "Epoch [6/100], Step [20200/24597], Loss: 1.5677\n",
      "Epoch [6/100], Step [20300/24597], Loss: 1.7659\n",
      "Epoch [6/100], Step [20400/24597], Loss: 1.8417\n",
      "Epoch [6/100], Step [20500/24597], Loss: 1.4173\n",
      "Epoch [6/100], Step [20600/24597], Loss: 1.6300\n",
      "Epoch [6/100], Step [20700/24597], Loss: 1.6326\n",
      "Epoch [6/100], Step [20800/24597], Loss: 1.6540\n",
      "Epoch [6/100], Step [20900/24597], Loss: 1.5487\n",
      "Epoch [6/100], Step [21000/24597], Loss: 1.6132\n",
      "Epoch [6/100], Step [21100/24597], Loss: 1.6549\n",
      "Epoch [6/100], Step [21200/24597], Loss: 1.5590\n",
      "Epoch [6/100], Step [21300/24597], Loss: 1.9000\n",
      "Epoch [6/100], Step [21400/24597], Loss: 1.4226\n",
      "Epoch [6/100], Step [21500/24597], Loss: 1.7004\n",
      "Epoch [6/100], Step [21600/24597], Loss: 1.5047\n",
      "Epoch [6/100], Step [21700/24597], Loss: 1.5315\n",
      "Epoch [6/100], Step [21800/24597], Loss: 1.6427\n",
      "Epoch [6/100], Step [21900/24597], Loss: 1.6690\n",
      "Epoch [6/100], Step [22000/24597], Loss: 1.6468\n",
      "Epoch [6/100], Step [22100/24597], Loss: 1.6703\n",
      "Epoch [6/100], Step [22200/24597], Loss: 1.4730\n",
      "Epoch [6/100], Step [22300/24597], Loss: 1.7566\n",
      "Epoch [6/100], Step [22400/24597], Loss: 1.7516\n",
      "Epoch [6/100], Step [22500/24597], Loss: 1.4566\n",
      "Epoch [6/100], Step [22600/24597], Loss: 1.6069\n",
      "Epoch [6/100], Step [22700/24597], Loss: 1.9035\n",
      "Epoch [6/100], Step [22800/24597], Loss: 1.4790\n",
      "Epoch [6/100], Step [22900/24597], Loss: 1.5761\n",
      "Epoch [6/100], Step [23000/24597], Loss: 1.6202\n",
      "Epoch [6/100], Step [23100/24597], Loss: 1.6391\n",
      "Epoch [6/100], Step [23200/24597], Loss: 1.5249\n",
      "Epoch [6/100], Step [23300/24597], Loss: 1.5868\n",
      "Epoch [6/100], Step [23400/24597], Loss: 1.7122\n",
      "Epoch [6/100], Step [23500/24597], Loss: 1.8631\n",
      "Epoch [6/100], Step [23600/24597], Loss: 1.7524\n",
      "Epoch [6/100], Step [23700/24597], Loss: 1.4346\n",
      "Epoch [6/100], Step [23800/24597], Loss: 1.6623\n",
      "Epoch [6/100], Step [23900/24597], Loss: 1.6810\n",
      "Epoch [6/100], Step [24000/24597], Loss: 1.5729\n",
      "Epoch [6/100], Step [24100/24597], Loss: 1.5740\n",
      "Epoch [6/100], Step [24200/24597], Loss: 1.7897\n",
      "Epoch [6/100], Step [24300/24597], Loss: 1.5469\n",
      "Epoch [6/100], Step [24400/24597], Loss: 1.5037\n",
      "Epoch [6/100], Step [24500/24597], Loss: 1.7312\n",
      "Epoch [7/100], Step [100/24597], Loss: 1.6391\n",
      "Epoch [7/100], Step [200/24597], Loss: 1.6462\n",
      "Epoch [7/100], Step [300/24597], Loss: 1.5903\n",
      "Epoch [7/100], Step [400/24597], Loss: 1.6331\n",
      "Epoch [7/100], Step [500/24597], Loss: 1.6654\n",
      "Epoch [7/100], Step [600/24597], Loss: 1.5341\n",
      "Epoch [7/100], Step [700/24597], Loss: 1.5555\n",
      "Epoch [7/100], Step [800/24597], Loss: 1.4456\n",
      "Epoch [7/100], Step [900/24597], Loss: 1.5833\n",
      "Epoch [7/100], Step [1000/24597], Loss: 1.4935\n",
      "Epoch [7/100], Step [1100/24597], Loss: 1.5054\n",
      "Epoch [7/100], Step [1200/24597], Loss: 1.6222\n",
      "Epoch [7/100], Step [1300/24597], Loss: 1.8642\n",
      "Epoch [7/100], Step [1400/24597], Loss: 1.4919\n",
      "Epoch [7/100], Step [1500/24597], Loss: 1.6064\n",
      "Epoch [7/100], Step [1600/24597], Loss: 1.4916\n",
      "Epoch [7/100], Step [1700/24597], Loss: 1.5684\n",
      "Epoch [7/100], Step [1800/24597], Loss: 1.7444\n",
      "Epoch [7/100], Step [1900/24597], Loss: 1.4754\n",
      "Epoch [7/100], Step [2000/24597], Loss: 1.6468\n",
      "Epoch [7/100], Step [2100/24597], Loss: 1.8344\n",
      "Epoch [7/100], Step [2200/24597], Loss: 1.8129\n",
      "Epoch [7/100], Step [2300/24597], Loss: 1.4526\n",
      "Epoch [7/100], Step [2400/24597], Loss: 1.6906\n",
      "Epoch [7/100], Step [2500/24597], Loss: 1.5559\n",
      "Epoch [7/100], Step [2600/24597], Loss: 1.5085\n",
      "Epoch [7/100], Step [2700/24597], Loss: 1.6222\n",
      "Epoch [7/100], Step [2800/24597], Loss: 1.6227\n",
      "Epoch [7/100], Step [2900/24597], Loss: 1.6022\n",
      "Epoch [7/100], Step [3000/24597], Loss: 1.5626\n",
      "Epoch [7/100], Step [3100/24597], Loss: 1.7781\n",
      "Epoch [7/100], Step [3200/24597], Loss: 1.5914\n",
      "Epoch [7/100], Step [3300/24597], Loss: 1.7633\n",
      "Epoch [7/100], Step [3400/24597], Loss: 1.6797\n",
      "Epoch [7/100], Step [3500/24597], Loss: 1.6444\n",
      "Epoch [7/100], Step [3600/24597], Loss: 1.7867\n",
      "Epoch [7/100], Step [3700/24597], Loss: 1.7427\n",
      "Epoch [7/100], Step [3800/24597], Loss: 1.4222\n",
      "Epoch [7/100], Step [3900/24597], Loss: 1.5698\n",
      "Epoch [7/100], Step [4000/24597], Loss: 1.6149\n",
      "Epoch [7/100], Step [4100/24597], Loss: 1.6029\n",
      "Epoch [7/100], Step [4200/24597], Loss: 1.6760\n",
      "Epoch [7/100], Step [4300/24597], Loss: 1.6713\n",
      "Epoch [7/100], Step [4400/24597], Loss: 1.6154\n",
      "Epoch [7/100], Step [4500/24597], Loss: 1.7684\n",
      "Epoch [7/100], Step [4600/24597], Loss: 1.5619\n",
      "Epoch [7/100], Step [4700/24597], Loss: 1.4389\n",
      "Epoch [7/100], Step [4800/24597], Loss: 1.5282\n",
      "Epoch [7/100], Step [4900/24597], Loss: 1.6299\n",
      "Epoch [7/100], Step [5000/24597], Loss: 1.4238\n",
      "Epoch [7/100], Step [5100/24597], Loss: 1.7963\n",
      "Epoch [7/100], Step [5200/24597], Loss: 1.6175\n",
      "Epoch [7/100], Step [5300/24597], Loss: 1.5459\n",
      "Epoch [7/100], Step [5400/24597], Loss: 1.8218\n",
      "Epoch [7/100], Step [5500/24597], Loss: 1.5641\n",
      "Epoch [7/100], Step [5600/24597], Loss: 1.5567\n",
      "Epoch [7/100], Step [5700/24597], Loss: 1.6455\n",
      "Epoch [7/100], Step [5800/24597], Loss: 1.5849\n",
      "Epoch [7/100], Step [5900/24597], Loss: 1.6982\n",
      "Epoch [7/100], Step [6000/24597], Loss: 1.9804\n",
      "Epoch [7/100], Step [6100/24597], Loss: 1.4363\n",
      "Epoch [7/100], Step [6200/24597], Loss: 1.6407\n",
      "Epoch [7/100], Step [6300/24597], Loss: 1.6641\n",
      "Epoch [7/100], Step [6400/24597], Loss: 1.6615\n",
      "Epoch [7/100], Step [6500/24597], Loss: 1.9164\n",
      "Epoch [7/100], Step [6600/24597], Loss: 1.6988\n",
      "Epoch [7/100], Step [6700/24597], Loss: 1.4044\n",
      "Epoch [7/100], Step [6800/24597], Loss: 1.5231\n",
      "Epoch [7/100], Step [6900/24597], Loss: 1.5841\n",
      "Epoch [7/100], Step [7000/24597], Loss: 1.5867\n",
      "Epoch [7/100], Step [7100/24597], Loss: 1.6129\n",
      "Epoch [7/100], Step [7200/24597], Loss: 1.6631\n",
      "Epoch [7/100], Step [7300/24597], Loss: 1.6921\n",
      "Epoch [7/100], Step [7400/24597], Loss: 1.6548\n",
      "Epoch [7/100], Step [7500/24597], Loss: 1.6003\n",
      "Epoch [7/100], Step [7600/24597], Loss: 1.6759\n",
      "Epoch [7/100], Step [7700/24597], Loss: 1.7046\n",
      "Epoch [7/100], Step [7800/24597], Loss: 1.5833\n",
      "Epoch [7/100], Step [7900/24597], Loss: 1.7879\n",
      "Epoch [7/100], Step [8000/24597], Loss: 1.5296\n",
      "Epoch [7/100], Step [8100/24597], Loss: 1.6253\n",
      "Epoch [7/100], Step [8200/24597], Loss: 1.6110\n",
      "Epoch [7/100], Step [8300/24597], Loss: 1.4700\n",
      "Epoch [7/100], Step [8400/24597], Loss: 1.5443\n",
      "Epoch [7/100], Step [8500/24597], Loss: 1.8091\n",
      "Epoch [7/100], Step [8600/24597], Loss: 1.7132\n",
      "Epoch [7/100], Step [8700/24597], Loss: 1.8906\n",
      "Epoch [7/100], Step [8800/24597], Loss: 1.6732\n",
      "Epoch [7/100], Step [8900/24597], Loss: 1.6098\n",
      "Epoch [7/100], Step [9000/24597], Loss: 1.7500\n",
      "Epoch [7/100], Step [9100/24597], Loss: 1.7364\n",
      "Epoch [7/100], Step [9200/24597], Loss: 1.5051\n",
      "Epoch [7/100], Step [9300/24597], Loss: 1.6648\n",
      "Epoch [7/100], Step [9400/24597], Loss: 1.5224\n",
      "Epoch [7/100], Step [9500/24597], Loss: 1.6497\n",
      "Epoch [7/100], Step [9600/24597], Loss: 1.5675\n",
      "Epoch [7/100], Step [9700/24597], Loss: 1.6371\n",
      "Epoch [7/100], Step [9800/24597], Loss: 1.5550\n",
      "Epoch [7/100], Step [9900/24597], Loss: 1.7329\n",
      "Epoch [7/100], Step [10000/24597], Loss: 1.5152\n",
      "Epoch [7/100], Step [10100/24597], Loss: 1.6674\n",
      "Epoch [7/100], Step [10200/24597], Loss: 1.5437\n",
      "Epoch [7/100], Step [10300/24597], Loss: 1.7788\n",
      "Epoch [7/100], Step [10400/24597], Loss: 1.5349\n",
      "Epoch [7/100], Step [10500/24597], Loss: 1.4909\n",
      "Epoch [7/100], Step [10600/24597], Loss: 1.6302\n",
      "Epoch [7/100], Step [10700/24597], Loss: 1.6533\n",
      "Epoch [7/100], Step [10800/24597], Loss: 1.7493\n",
      "Epoch [7/100], Step [10900/24597], Loss: 1.6898\n",
      "Epoch [7/100], Step [11000/24597], Loss: 1.6038\n",
      "Epoch [7/100], Step [11100/24597], Loss: 1.6907\n",
      "Epoch [7/100], Step [11200/24597], Loss: 1.5553\n",
      "Epoch [7/100], Step [11300/24597], Loss: 1.5404\n",
      "Epoch [7/100], Step [11400/24597], Loss: 1.6882\n",
      "Epoch [7/100], Step [11500/24597], Loss: 1.8432\n",
      "Epoch [7/100], Step [11600/24597], Loss: 1.6144\n",
      "Epoch [7/100], Step [11700/24597], Loss: 1.6607\n",
      "Epoch [7/100], Step [11800/24597], Loss: 1.5713\n",
      "Epoch [7/100], Step [11900/24597], Loss: 1.6118\n",
      "Epoch [7/100], Step [12000/24597], Loss: 1.6542\n",
      "Epoch [7/100], Step [12100/24597], Loss: 1.6283\n",
      "Epoch [7/100], Step [12200/24597], Loss: 1.6908\n",
      "Epoch [7/100], Step [12300/24597], Loss: 1.5181\n",
      "Epoch [7/100], Step [12400/24597], Loss: 1.4548\n",
      "Epoch [7/100], Step [12500/24597], Loss: 1.5475\n",
      "Epoch [7/100], Step [12600/24597], Loss: 1.6206\n",
      "Epoch [7/100], Step [12700/24597], Loss: 1.8415\n",
      "Epoch [7/100], Step [12800/24597], Loss: 1.6179\n",
      "Epoch [7/100], Step [12900/24597], Loss: 1.8905\n",
      "Epoch [7/100], Step [13000/24597], Loss: 1.6421\n",
      "Epoch [7/100], Step [13100/24597], Loss: 1.7827\n",
      "Epoch [7/100], Step [13200/24597], Loss: 1.6607\n",
      "Epoch [7/100], Step [13300/24597], Loss: 1.5754\n",
      "Epoch [7/100], Step [13400/24597], Loss: 1.6040\n",
      "Epoch [7/100], Step [13500/24597], Loss: 1.7544\n",
      "Epoch [7/100], Step [13600/24597], Loss: 1.6814\n",
      "Epoch [7/100], Step [13700/24597], Loss: 1.6923\n",
      "Epoch [7/100], Step [13800/24597], Loss: 1.7113\n",
      "Epoch [7/100], Step [13900/24597], Loss: 1.7835\n",
      "Epoch [7/100], Step [14000/24597], Loss: 1.6537\n",
      "Epoch [7/100], Step [14100/24597], Loss: 1.7457\n",
      "Epoch [7/100], Step [14200/24597], Loss: 1.5881\n",
      "Epoch [7/100], Step [14300/24597], Loss: 1.7591\n",
      "Epoch [7/100], Step [14400/24597], Loss: 1.6683\n",
      "Epoch [7/100], Step [14500/24597], Loss: 1.7016\n",
      "Epoch [7/100], Step [14600/24597], Loss: 1.7555\n",
      "Epoch [7/100], Step [14700/24597], Loss: 1.5899\n",
      "Epoch [7/100], Step [14800/24597], Loss: 1.8315\n",
      "Epoch [7/100], Step [14900/24597], Loss: 1.7828\n",
      "Epoch [7/100], Step [15000/24597], Loss: 1.5846\n",
      "Epoch [7/100], Step [15100/24597], Loss: 1.5114\n",
      "Epoch [7/100], Step [15200/24597], Loss: 1.6673\n",
      "Epoch [7/100], Step [15300/24597], Loss: 1.5520\n",
      "Epoch [7/100], Step [15400/24597], Loss: 1.4421\n",
      "Epoch [7/100], Step [15500/24597], Loss: 1.5256\n",
      "Epoch [7/100], Step [15600/24597], Loss: 1.4673\n",
      "Epoch [7/100], Step [15700/24597], Loss: 1.6241\n",
      "Epoch [7/100], Step [15800/24597], Loss: 1.8846\n",
      "Epoch [7/100], Step [15900/24597], Loss: 1.7307\n",
      "Epoch [7/100], Step [16000/24597], Loss: 1.6883\n",
      "Epoch [7/100], Step [16100/24597], Loss: 1.5674\n",
      "Epoch [7/100], Step [16200/24597], Loss: 1.7094\n",
      "Epoch [7/100], Step [16300/24597], Loss: 1.5933\n",
      "Epoch [7/100], Step [16400/24597], Loss: 1.6082\n",
      "Epoch [7/100], Step [16500/24597], Loss: 1.7975\n",
      "Epoch [7/100], Step [16600/24597], Loss: 1.6179\n",
      "Epoch [7/100], Step [16700/24597], Loss: 1.8219\n",
      "Epoch [7/100], Step [16800/24597], Loss: 1.6678\n",
      "Epoch [7/100], Step [16900/24597], Loss: 1.7347\n",
      "Epoch [7/100], Step [17000/24597], Loss: 1.7807\n",
      "Epoch [7/100], Step [17100/24597], Loss: 1.8523\n",
      "Epoch [7/100], Step [17200/24597], Loss: 1.4797\n",
      "Epoch [7/100], Step [17300/24597], Loss: 1.8396\n",
      "Epoch [7/100], Step [17400/24597], Loss: 1.5717\n",
      "Epoch [7/100], Step [17500/24597], Loss: 1.7601\n",
      "Epoch [7/100], Step [17600/24597], Loss: 1.7299\n",
      "Epoch [7/100], Step [17700/24597], Loss: 1.7653\n",
      "Epoch [7/100], Step [17800/24597], Loss: 1.6406\n",
      "Epoch [7/100], Step [17900/24597], Loss: 1.5057\n",
      "Epoch [7/100], Step [18000/24597], Loss: 1.7467\n",
      "Epoch [7/100], Step [18100/24597], Loss: 1.7244\n",
      "Epoch [7/100], Step [18200/24597], Loss: 1.6356\n",
      "Epoch [7/100], Step [18300/24597], Loss: 1.5150\n",
      "Epoch [7/100], Step [18400/24597], Loss: 1.6796\n",
      "Epoch [7/100], Step [18500/24597], Loss: 1.7822\n",
      "Epoch [7/100], Step [18600/24597], Loss: 1.7617\n",
      "Epoch [7/100], Step [18700/24597], Loss: 1.3894\n",
      "Epoch [7/100], Step [18800/24597], Loss: 1.6433\n",
      "Epoch [7/100], Step [18900/24597], Loss: 1.8028\n",
      "Epoch [7/100], Step [19000/24597], Loss: 1.7355\n",
      "Epoch [7/100], Step [19100/24597], Loss: 1.5407\n",
      "Epoch [7/100], Step [19200/24597], Loss: 1.5676\n",
      "Epoch [7/100], Step [19300/24597], Loss: 1.5474\n",
      "Epoch [7/100], Step [19400/24597], Loss: 1.7852\n",
      "Epoch [7/100], Step [19500/24597], Loss: 1.6929\n",
      "Epoch [7/100], Step [19600/24597], Loss: 1.5543\n",
      "Epoch [7/100], Step [19700/24597], Loss: 1.7479\n",
      "Epoch [7/100], Step [19800/24597], Loss: 1.4992\n",
      "Epoch [7/100], Step [19900/24597], Loss: 1.5815\n",
      "Epoch [7/100], Step [20000/24597], Loss: 1.5958\n",
      "Epoch [7/100], Step [20100/24597], Loss: 1.5328\n",
      "Epoch [7/100], Step [20200/24597], Loss: 1.8592\n",
      "Epoch [7/100], Step [20300/24597], Loss: 1.6238\n",
      "Epoch [7/100], Step [20400/24597], Loss: 1.7541\n",
      "Epoch [7/100], Step [20500/24597], Loss: 1.6943\n",
      "Epoch [7/100], Step [20600/24597], Loss: 1.6191\n",
      "Epoch [7/100], Step [20700/24597], Loss: 1.7140\n",
      "Epoch [7/100], Step [20800/24597], Loss: 1.5849\n",
      "Epoch [7/100], Step [20900/24597], Loss: 1.6263\n",
      "Epoch [7/100], Step [21000/24597], Loss: 1.4854\n",
      "Epoch [7/100], Step [21100/24597], Loss: 1.7303\n",
      "Epoch [7/100], Step [21200/24597], Loss: 1.6472\n",
      "Epoch [7/100], Step [21300/24597], Loss: 1.5475\n",
      "Epoch [7/100], Step [21400/24597], Loss: 1.7879\n",
      "Epoch [7/100], Step [21500/24597], Loss: 1.4879\n",
      "Epoch [7/100], Step [21600/24597], Loss: 1.6257\n",
      "Epoch [7/100], Step [21700/24597], Loss: 1.5669\n",
      "Epoch [7/100], Step [21800/24597], Loss: 1.6702\n",
      "Epoch [7/100], Step [21900/24597], Loss: 1.6039\n",
      "Epoch [7/100], Step [22000/24597], Loss: 1.6616\n",
      "Epoch [7/100], Step [22100/24597], Loss: 1.4986\n",
      "Epoch [7/100], Step [22200/24597], Loss: 1.6008\n",
      "Epoch [7/100], Step [22300/24597], Loss: 1.6123\n",
      "Epoch [7/100], Step [22400/24597], Loss: 1.6158\n",
      "Epoch [7/100], Step [22500/24597], Loss: 1.4698\n",
      "Epoch [7/100], Step [22600/24597], Loss: 1.7180\n",
      "Epoch [7/100], Step [22700/24597], Loss: 1.5963\n",
      "Epoch [7/100], Step [22800/24597], Loss: 1.8436\n",
      "Epoch [7/100], Step [22900/24597], Loss: 1.6746\n",
      "Epoch [7/100], Step [23000/24597], Loss: 1.6547\n",
      "Epoch [7/100], Step [23100/24597], Loss: 1.5995\n",
      "Epoch [7/100], Step [23200/24597], Loss: 1.5852\n",
      "Epoch [7/100], Step [23300/24597], Loss: 1.5216\n",
      "Epoch [7/100], Step [23400/24597], Loss: 1.7023\n",
      "Epoch [7/100], Step [23500/24597], Loss: 1.5535\n",
      "Epoch [7/100], Step [23600/24597], Loss: 1.7349\n",
      "Epoch [7/100], Step [23700/24597], Loss: 1.5616\n",
      "Epoch [7/100], Step [23800/24597], Loss: 1.5393\n",
      "Epoch [7/100], Step [23900/24597], Loss: 1.4703\n",
      "Epoch [7/100], Step [24000/24597], Loss: 1.6851\n",
      "Epoch [7/100], Step [24100/24597], Loss: 1.5989\n",
      "Epoch [7/100], Step [24200/24597], Loss: 1.5841\n",
      "Epoch [7/100], Step [24300/24597], Loss: 1.4874\n",
      "Epoch [7/100], Step [24400/24597], Loss: 1.6106\n",
      "Epoch [7/100], Step [24500/24597], Loss: 1.4884\n",
      "Epoch [8/100], Step [100/24597], Loss: 1.7699\n",
      "Epoch [8/100], Step [200/24597], Loss: 1.5260\n",
      "Epoch [8/100], Step [300/24597], Loss: 1.8595\n",
      "Epoch [8/100], Step [400/24597], Loss: 1.5603\n",
      "Epoch [8/100], Step [500/24597], Loss: 1.7459\n",
      "Epoch [8/100], Step [600/24597], Loss: 1.4830\n",
      "Epoch [8/100], Step [700/24597], Loss: 1.8231\n",
      "Epoch [8/100], Step [800/24597], Loss: 1.6711\n",
      "Epoch [8/100], Step [900/24597], Loss: 1.7127\n",
      "Epoch [8/100], Step [1000/24597], Loss: 1.6845\n",
      "Epoch [8/100], Step [1100/24597], Loss: 1.5320\n",
      "Epoch [8/100], Step [1200/24597], Loss: 1.6188\n",
      "Epoch [8/100], Step [1300/24597], Loss: 1.7857\n",
      "Epoch [8/100], Step [1400/24597], Loss: 1.5268\n",
      "Epoch [8/100], Step [1500/24597], Loss: 1.4773\n",
      "Epoch [8/100], Step [1600/24597], Loss: 1.5469\n",
      "Epoch [8/100], Step [1700/24597], Loss: 1.5473\n",
      "Epoch [8/100], Step [1800/24597], Loss: 1.5616\n",
      "Epoch [8/100], Step [1900/24597], Loss: 1.7591\n",
      "Epoch [8/100], Step [2000/24597], Loss: 1.6198\n",
      "Epoch [8/100], Step [2100/24597], Loss: 1.7169\n",
      "Epoch [8/100], Step [2200/24597], Loss: 1.4408\n",
      "Epoch [8/100], Step [2300/24597], Loss: 1.5487\n",
      "Epoch [8/100], Step [2400/24597], Loss: 1.8744\n",
      "Epoch [8/100], Step [2500/24597], Loss: 1.5029\n",
      "Epoch [8/100], Step [2600/24597], Loss: 1.5686\n",
      "Epoch [8/100], Step [2700/24597], Loss: 1.7037\n",
      "Epoch [8/100], Step [2800/24597], Loss: 1.4832\n",
      "Epoch [8/100], Step [2900/24597], Loss: 1.6434\n",
      "Epoch [8/100], Step [3000/24597], Loss: 1.9411\n",
      "Epoch [8/100], Step [3100/24597], Loss: 1.5271\n",
      "Epoch [8/100], Step [3200/24597], Loss: 1.6143\n",
      "Epoch [8/100], Step [3300/24597], Loss: 1.8655\n",
      "Epoch [8/100], Step [3400/24597], Loss: 1.5222\n",
      "Epoch [8/100], Step [3500/24597], Loss: 1.6678\n",
      "Epoch [8/100], Step [3600/24597], Loss: 1.6129\n",
      "Epoch [8/100], Step [3700/24597], Loss: 1.6439\n",
      "Epoch [8/100], Step [3800/24597], Loss: 1.6574\n",
      "Epoch [8/100], Step [3900/24597], Loss: 1.6077\n",
      "Epoch [8/100], Step [4000/24597], Loss: 1.4381\n",
      "Epoch [8/100], Step [4100/24597], Loss: 1.6197\n",
      "Epoch [8/100], Step [4200/24597], Loss: 1.8388\n",
      "Epoch [8/100], Step [4300/24597], Loss: 1.6535\n",
      "Epoch [8/100], Step [4400/24597], Loss: 1.7219\n",
      "Epoch [8/100], Step [4500/24597], Loss: 1.7498\n",
      "Epoch [8/100], Step [4600/24597], Loss: 1.5510\n",
      "Epoch [8/100], Step [4700/24597], Loss: 1.6602\n",
      "Epoch [8/100], Step [4800/24597], Loss: 1.5037\n",
      "Epoch [8/100], Step [4900/24597], Loss: 1.6052\n",
      "Epoch [8/100], Step [5000/24597], Loss: 1.5291\n",
      "Epoch [8/100], Step [5100/24597], Loss: 1.4381\n",
      "Epoch [8/100], Step [5200/24597], Loss: 1.5371\n",
      "Epoch [8/100], Step [5300/24597], Loss: 1.7104\n",
      "Epoch [8/100], Step [5400/24597], Loss: 1.8844\n",
      "Epoch [8/100], Step [5500/24597], Loss: 1.7018\n",
      "Epoch [8/100], Step [5600/24597], Loss: 1.5363\n",
      "Epoch [8/100], Step [5700/24597], Loss: 1.7276\n",
      "Epoch [8/100], Step [5800/24597], Loss: 1.5887\n",
      "Epoch [8/100], Step [5900/24597], Loss: 1.5545\n",
      "Epoch [8/100], Step [6000/24597], Loss: 1.6603\n",
      "Epoch [8/100], Step [6100/24597], Loss: 1.6971\n",
      "Epoch [8/100], Step [6200/24597], Loss: 1.7076\n",
      "Epoch [8/100], Step [6300/24597], Loss: 1.6993\n",
      "Epoch [8/100], Step [6400/24597], Loss: 1.9161\n",
      "Epoch [8/100], Step [6500/24597], Loss: 1.6560\n",
      "Epoch [8/100], Step [6600/24597], Loss: 1.7156\n",
      "Epoch [8/100], Step [6700/24597], Loss: 1.6023\n",
      "Epoch [8/100], Step [6800/24597], Loss: 1.6938\n",
      "Epoch [8/100], Step [6900/24597], Loss: 1.7043\n",
      "Epoch [8/100], Step [7000/24597], Loss: 1.6479\n",
      "Epoch [8/100], Step [7100/24597], Loss: 1.4352\n",
      "Epoch [8/100], Step [7200/24597], Loss: 1.6712\n",
      "Epoch [8/100], Step [7300/24597], Loss: 1.8348\n",
      "Epoch [8/100], Step [7400/24597], Loss: 1.3632\n",
      "Epoch [8/100], Step [7500/24597], Loss: 1.5510\n",
      "Epoch [8/100], Step [7600/24597], Loss: 1.6061\n",
      "Epoch [8/100], Step [7700/24597], Loss: 1.8629\n",
      "Epoch [8/100], Step [7800/24597], Loss: 1.5687\n",
      "Epoch [8/100], Step [7900/24597], Loss: 1.5994\n",
      "Epoch [8/100], Step [8000/24597], Loss: 1.4307\n",
      "Epoch [8/100], Step [8100/24597], Loss: 1.7424\n",
      "Epoch [8/100], Step [8200/24597], Loss: 1.8044\n",
      "Epoch [8/100], Step [8300/24597], Loss: 1.7606\n",
      "Epoch [8/100], Step [8400/24597], Loss: 1.3524\n",
      "Epoch [8/100], Step [8500/24597], Loss: 1.7199\n",
      "Epoch [8/100], Step [8600/24597], Loss: 1.5150\n",
      "Epoch [8/100], Step [8700/24597], Loss: 1.6016\n",
      "Epoch [8/100], Step [8800/24597], Loss: 1.4632\n",
      "Epoch [8/100], Step [8900/24597], Loss: 1.4340\n",
      "Epoch [8/100], Step [9000/24597], Loss: 1.5155\n",
      "Epoch [8/100], Step [9100/24597], Loss: 1.5980\n",
      "Epoch [8/100], Step [9200/24597], Loss: 1.6913\n",
      "Epoch [8/100], Step [9300/24597], Loss: 1.8156\n",
      "Epoch [8/100], Step [9400/24597], Loss: 2.0061\n",
      "Epoch [8/100], Step [9500/24597], Loss: 1.5598\n",
      "Epoch [8/100], Step [9600/24597], Loss: 1.8058\n",
      "Epoch [8/100], Step [9700/24597], Loss: 1.6623\n",
      "Epoch [8/100], Step [9800/24597], Loss: 1.5948\n",
      "Epoch [8/100], Step [9900/24597], Loss: 1.6827\n",
      "Epoch [8/100], Step [10000/24597], Loss: 1.6728\n",
      "Epoch [8/100], Step [10100/24597], Loss: 1.6354\n",
      "Epoch [8/100], Step [10200/24597], Loss: 1.6017\n",
      "Epoch [8/100], Step [10300/24597], Loss: 1.6088\n",
      "Epoch [8/100], Step [10400/24597], Loss: 1.5794\n",
      "Epoch [8/100], Step [10500/24597], Loss: 1.5033\n",
      "Epoch [8/100], Step [10600/24597], Loss: 1.7481\n",
      "Epoch [8/100], Step [10700/24597], Loss: 1.5070\n",
      "Epoch [8/100], Step [10800/24597], Loss: 1.5412\n",
      "Epoch [8/100], Step [10900/24597], Loss: 1.7309\n",
      "Epoch [8/100], Step [11000/24597], Loss: 1.7445\n",
      "Epoch [8/100], Step [11100/24597], Loss: 1.5257\n",
      "Epoch [8/100], Step [11200/24597], Loss: 1.6062\n",
      "Epoch [8/100], Step [11300/24597], Loss: 1.4212\n",
      "Epoch [8/100], Step [11400/24597], Loss: 1.6023\n",
      "Epoch [8/100], Step [11500/24597], Loss: 1.5572\n",
      "Epoch [8/100], Step [11600/24597], Loss: 1.6475\n",
      "Epoch [8/100], Step [11700/24597], Loss: 1.5863\n",
      "Epoch [8/100], Step [11800/24597], Loss: 1.5153\n",
      "Epoch [8/100], Step [11900/24597], Loss: 1.5610\n",
      "Epoch [8/100], Step [12000/24597], Loss: 1.6127\n",
      "Epoch [8/100], Step [12100/24597], Loss: 1.6747\n",
      "Epoch [8/100], Step [12200/24597], Loss: 1.6807\n",
      "Epoch [8/100], Step [12300/24597], Loss: 1.5780\n",
      "Epoch [8/100], Step [12400/24597], Loss: 1.8709\n",
      "Epoch [8/100], Step [12500/24597], Loss: 1.8521\n",
      "Epoch [8/100], Step [12600/24597], Loss: 1.6900\n",
      "Epoch [8/100], Step [12700/24597], Loss: 1.4263\n",
      "Epoch [8/100], Step [12800/24597], Loss: 1.5793\n",
      "Epoch [8/100], Step [12900/24597], Loss: 1.4134\n",
      "Epoch [8/100], Step [13000/24597], Loss: 1.7300\n",
      "Epoch [8/100], Step [13100/24597], Loss: 1.4618\n",
      "Epoch [8/100], Step [13200/24597], Loss: 1.8614\n",
      "Epoch [8/100], Step [13300/24597], Loss: 1.6220\n",
      "Epoch [8/100], Step [13400/24597], Loss: 1.5573\n",
      "Epoch [8/100], Step [13500/24597], Loss: 1.5765\n",
      "Epoch [8/100], Step [13600/24597], Loss: 1.8573\n",
      "Epoch [8/100], Step [13700/24597], Loss: 1.4969\n",
      "Epoch [8/100], Step [13800/24597], Loss: 1.8027\n",
      "Epoch [8/100], Step [13900/24597], Loss: 1.8392\n",
      "Epoch [8/100], Step [14000/24597], Loss: 1.5209\n",
      "Epoch [8/100], Step [14100/24597], Loss: 1.6337\n",
      "Epoch [8/100], Step [14200/24597], Loss: 1.6480\n",
      "Epoch [8/100], Step [14300/24597], Loss: 1.7976\n",
      "Epoch [8/100], Step [14400/24597], Loss: 1.4839\n",
      "Epoch [8/100], Step [14500/24597], Loss: 1.6760\n",
      "Epoch [8/100], Step [14600/24597], Loss: 1.5987\n",
      "Epoch [8/100], Step [14700/24597], Loss: 1.7056\n",
      "Epoch [8/100], Step [14800/24597], Loss: 1.7139\n",
      "Epoch [8/100], Step [14900/24597], Loss: 1.7509\n",
      "Epoch [8/100], Step [15000/24597], Loss: 1.8309\n",
      "Epoch [8/100], Step [15100/24597], Loss: 1.4002\n",
      "Epoch [8/100], Step [15200/24597], Loss: 1.6242\n",
      "Epoch [8/100], Step [15300/24597], Loss: 1.5636\n",
      "Epoch [8/100], Step [15400/24597], Loss: 1.9136\n",
      "Epoch [8/100], Step [15500/24597], Loss: 1.6024\n",
      "Epoch [8/100], Step [15600/24597], Loss: 1.8106\n",
      "Epoch [8/100], Step [15700/24597], Loss: 1.6333\n",
      "Epoch [8/100], Step [15800/24597], Loss: 1.5453\n",
      "Epoch [8/100], Step [15900/24597], Loss: 1.5962\n",
      "Epoch [8/100], Step [16000/24597], Loss: 1.6188\n",
      "Epoch [8/100], Step [16100/24597], Loss: 1.5540\n",
      "Epoch [8/100], Step [16200/24597], Loss: 1.6800\n",
      "Epoch [8/100], Step [16300/24597], Loss: 1.7003\n",
      "Epoch [8/100], Step [16400/24597], Loss: 1.5344\n",
      "Epoch [8/100], Step [16500/24597], Loss: 1.5770\n",
      "Epoch [8/100], Step [16600/24597], Loss: 1.6373\n",
      "Epoch [8/100], Step [16700/24597], Loss: 1.8546\n",
      "Epoch [8/100], Step [16800/24597], Loss: 1.9091\n",
      "Epoch [8/100], Step [16900/24597], Loss: 1.6484\n",
      "Epoch [8/100], Step [17000/24597], Loss: 1.4819\n",
      "Epoch [8/100], Step [17100/24597], Loss: 1.3815\n",
      "Epoch [8/100], Step [17200/24597], Loss: 1.6340\n",
      "Epoch [8/100], Step [17300/24597], Loss: 1.4114\n",
      "Epoch [8/100], Step [17400/24597], Loss: 1.5762\n",
      "Epoch [8/100], Step [17500/24597], Loss: 1.6953\n",
      "Epoch [8/100], Step [17600/24597], Loss: 1.5911\n",
      "Epoch [8/100], Step [17700/24597], Loss: 1.5230\n",
      "Epoch [8/100], Step [17800/24597], Loss: 1.5585\n",
      "Epoch [8/100], Step [17900/24597], Loss: 1.7725\n",
      "Epoch [8/100], Step [18000/24597], Loss: 1.6526\n",
      "Epoch [8/100], Step [18100/24597], Loss: 1.6803\n",
      "Epoch [8/100], Step [18200/24597], Loss: 1.7702\n",
      "Epoch [8/100], Step [18300/24597], Loss: 1.8267\n",
      "Epoch [8/100], Step [18400/24597], Loss: 1.6217\n",
      "Epoch [8/100], Step [18500/24597], Loss: 1.5297\n",
      "Epoch [8/100], Step [18600/24597], Loss: 1.7656\n",
      "Epoch [8/100], Step [18700/24597], Loss: 1.8097\n",
      "Epoch [8/100], Step [18800/24597], Loss: 1.5701\n",
      "Epoch [8/100], Step [18900/24597], Loss: 1.7498\n",
      "Epoch [8/100], Step [19000/24597], Loss: 1.4900\n",
      "Epoch [8/100], Step [19100/24597], Loss: 1.5031\n",
      "Epoch [8/100], Step [19200/24597], Loss: 1.5953\n",
      "Epoch [8/100], Step [19300/24597], Loss: 1.4392\n",
      "Epoch [8/100], Step [19400/24597], Loss: 1.5661\n",
      "Epoch [8/100], Step [19500/24597], Loss: 1.8546\n",
      "Epoch [8/100], Step [19600/24597], Loss: 1.5769\n",
      "Epoch [8/100], Step [19700/24597], Loss: 1.6649\n",
      "Epoch [8/100], Step [19800/24597], Loss: 1.6973\n",
      "Epoch [8/100], Step [19900/24597], Loss: 1.5621\n",
      "Epoch [8/100], Step [20000/24597], Loss: 1.5620\n",
      "Epoch [8/100], Step [20100/24597], Loss: 1.5739\n",
      "Epoch [8/100], Step [20200/24597], Loss: 1.6625\n",
      "Epoch [8/100], Step [20300/24597], Loss: 1.5119\n",
      "Epoch [8/100], Step [20400/24597], Loss: 1.6750\n",
      "Epoch [8/100], Step [20500/24597], Loss: 1.3818\n",
      "Epoch [8/100], Step [20600/24597], Loss: 1.5841\n",
      "Epoch [8/100], Step [20700/24597], Loss: 1.6853\n",
      "Epoch [8/100], Step [20800/24597], Loss: 1.4531\n",
      "Epoch [8/100], Step [20900/24597], Loss: 1.6871\n",
      "Epoch [8/100], Step [21000/24597], Loss: 1.8037\n",
      "Epoch [8/100], Step [21100/24597], Loss: 1.5356\n",
      "Epoch [8/100], Step [21200/24597], Loss: 1.4514\n",
      "Epoch [8/100], Step [21300/24597], Loss: 1.8225\n",
      "Epoch [8/100], Step [21400/24597], Loss: 1.7770\n",
      "Epoch [8/100], Step [21500/24597], Loss: 1.6152\n",
      "Epoch [8/100], Step [21600/24597], Loss: 1.5884\n",
      "Epoch [8/100], Step [21700/24597], Loss: 1.8582\n",
      "Epoch [8/100], Step [21800/24597], Loss: 1.5846\n",
      "Epoch [8/100], Step [21900/24597], Loss: 1.8541\n",
      "Epoch [8/100], Step [22000/24597], Loss: 1.6342\n",
      "Epoch [8/100], Step [22100/24597], Loss: 1.7487\n",
      "Epoch [8/100], Step [22200/24597], Loss: 1.6340\n",
      "Epoch [8/100], Step [22300/24597], Loss: 1.5523\n",
      "Epoch [8/100], Step [22400/24597], Loss: 1.9247\n",
      "Epoch [8/100], Step [22500/24597], Loss: 1.6496\n",
      "Epoch [8/100], Step [22600/24597], Loss: 1.8807\n",
      "Epoch [8/100], Step [22700/24597], Loss: 1.6239\n",
      "Epoch [8/100], Step [22800/24597], Loss: 1.7725\n",
      "Epoch [8/100], Step [22900/24597], Loss: 1.7948\n",
      "Epoch [8/100], Step [23000/24597], Loss: 1.4804\n",
      "Epoch [8/100], Step [23100/24597], Loss: 1.6152\n",
      "Epoch [8/100], Step [23200/24597], Loss: 1.7052\n",
      "Epoch [8/100], Step [23300/24597], Loss: 1.7271\n",
      "Epoch [8/100], Step [23400/24597], Loss: 1.5375\n",
      "Epoch [8/100], Step [23500/24597], Loss: 1.6455\n",
      "Epoch [8/100], Step [23600/24597], Loss: 1.6330\n",
      "Epoch [8/100], Step [23700/24597], Loss: 1.6282\n",
      "Epoch [8/100], Step [23800/24597], Loss: 1.6365\n",
      "Epoch [8/100], Step [23900/24597], Loss: 1.8034\n",
      "Epoch [8/100], Step [24000/24597], Loss: 1.5668\n",
      "Epoch [8/100], Step [24100/24597], Loss: 1.5770\n",
      "Epoch [8/100], Step [24200/24597], Loss: 1.5605\n",
      "Epoch [8/100], Step [24300/24597], Loss: 1.6098\n",
      "Epoch [8/100], Step [24400/24597], Loss: 1.4597\n",
      "Epoch [8/100], Step [24500/24597], Loss: 1.8175\n",
      "Epoch [9/100], Step [100/24597], Loss: 1.6558\n",
      "Epoch [9/100], Step [200/24597], Loss: 1.6189\n",
      "Epoch [9/100], Step [300/24597], Loss: 1.7727\n",
      "Epoch [9/100], Step [400/24597], Loss: 1.5736\n",
      "Epoch [9/100], Step [500/24597], Loss: 1.6651\n",
      "Epoch [9/100], Step [600/24597], Loss: 1.7194\n",
      "Epoch [9/100], Step [700/24597], Loss: 1.7324\n",
      "Epoch [9/100], Step [800/24597], Loss: 1.7268\n",
      "Epoch [9/100], Step [900/24597], Loss: 1.7398\n",
      "Epoch [9/100], Step [1000/24597], Loss: 1.5312\n",
      "Epoch [9/100], Step [1100/24597], Loss: 1.6475\n",
      "Epoch [9/100], Step [1200/24597], Loss: 1.4936\n",
      "Epoch [9/100], Step [1300/24597], Loss: 1.5562\n",
      "Epoch [9/100], Step [1400/24597], Loss: 1.8359\n",
      "Epoch [9/100], Step [1500/24597], Loss: 1.6976\n",
      "Epoch [9/100], Step [1600/24597], Loss: 2.0010\n",
      "Epoch [9/100], Step [1700/24597], Loss: 1.5757\n",
      "Epoch [9/100], Step [1800/24597], Loss: 1.4855\n",
      "Epoch [9/100], Step [1900/24597], Loss: 1.5244\n",
      "Epoch [9/100], Step [2000/24597], Loss: 1.5762\n",
      "Epoch [9/100], Step [2100/24597], Loss: 1.5518\n",
      "Epoch [9/100], Step [2200/24597], Loss: 1.5597\n",
      "Epoch [9/100], Step [2300/24597], Loss: 1.6982\n",
      "Epoch [9/100], Step [2400/24597], Loss: 1.6489\n",
      "Epoch [9/100], Step [2500/24597], Loss: 1.6399\n",
      "Epoch [9/100], Step [2600/24597], Loss: 1.6230\n",
      "Epoch [9/100], Step [2700/24597], Loss: 1.4918\n",
      "Epoch [9/100], Step [2800/24597], Loss: 1.6861\n",
      "Epoch [9/100], Step [2900/24597], Loss: 1.9183\n",
      "Epoch [9/100], Step [3000/24597], Loss: 1.5286\n",
      "Epoch [9/100], Step [3100/24597], Loss: 1.9355\n",
      "Epoch [9/100], Step [3200/24597], Loss: 1.6506\n",
      "Epoch [9/100], Step [3300/24597], Loss: 1.4290\n",
      "Epoch [9/100], Step [3400/24597], Loss: 1.6995\n",
      "Epoch [9/100], Step [3500/24597], Loss: 1.7710\n",
      "Epoch [9/100], Step [3600/24597], Loss: 1.5368\n",
      "Epoch [9/100], Step [3700/24597], Loss: 1.4967\n",
      "Epoch [9/100], Step [3800/24597], Loss: 1.5748\n",
      "Epoch [9/100], Step [3900/24597], Loss: 1.7981\n",
      "Epoch [9/100], Step [4000/24597], Loss: 1.6032\n",
      "Epoch [9/100], Step [4100/24597], Loss: 1.6050\n",
      "Epoch [9/100], Step [4200/24597], Loss: 1.6848\n",
      "Epoch [9/100], Step [4300/24597], Loss: 1.6518\n",
      "Epoch [9/100], Step [4400/24597], Loss: 1.9245\n",
      "Epoch [9/100], Step [4500/24597], Loss: 1.5006\n",
      "Epoch [9/100], Step [4600/24597], Loss: 1.5706\n",
      "Epoch [9/100], Step [4700/24597], Loss: 1.6284\n",
      "Epoch [9/100], Step [4800/24597], Loss: 1.4799\n",
      "Epoch [9/100], Step [4900/24597], Loss: 1.7831\n",
      "Epoch [9/100], Step [5000/24597], Loss: 1.6731\n",
      "Epoch [9/100], Step [5100/24597], Loss: 1.6275\n",
      "Epoch [9/100], Step [5200/24597], Loss: 1.6636\n",
      "Epoch [9/100], Step [5300/24597], Loss: 1.4553\n",
      "Epoch [9/100], Step [5400/24597], Loss: 1.5384\n",
      "Epoch [9/100], Step [5500/24597], Loss: 1.6386\n",
      "Epoch [9/100], Step [5600/24597], Loss: 1.6316\n",
      "Epoch [9/100], Step [5700/24597], Loss: 1.4319\n",
      "Epoch [9/100], Step [5800/24597], Loss: 1.4506\n",
      "Epoch [9/100], Step [5900/24597], Loss: 1.6638\n",
      "Epoch [9/100], Step [6000/24597], Loss: 1.7722\n",
      "Epoch [9/100], Step [6100/24597], Loss: 1.6481\n",
      "Epoch [9/100], Step [6200/24597], Loss: 1.5959\n",
      "Epoch [9/100], Step [6300/24597], Loss: 1.6933\n",
      "Epoch [9/100], Step [6400/24597], Loss: 1.7856\n",
      "Epoch [9/100], Step [6500/24597], Loss: 1.7779\n",
      "Epoch [9/100], Step [6600/24597], Loss: 1.4685\n",
      "Epoch [9/100], Step [6700/24597], Loss: 1.7745\n",
      "Epoch [9/100], Step [6800/24597], Loss: 1.6336\n",
      "Epoch [9/100], Step [6900/24597], Loss: 1.7272\n",
      "Epoch [9/100], Step [7000/24597], Loss: 1.4457\n",
      "Epoch [9/100], Step [7100/24597], Loss: 1.6659\n",
      "Epoch [9/100], Step [7200/24597], Loss: 1.7207\n",
      "Epoch [9/100], Step [7300/24597], Loss: 1.6878\n",
      "Epoch [9/100], Step [7400/24597], Loss: 1.8390\n",
      "Epoch [9/100], Step [7500/24597], Loss: 1.6349\n",
      "Epoch [9/100], Step [7600/24597], Loss: 1.5914\n",
      "Epoch [9/100], Step [7700/24597], Loss: 1.7948\n",
      "Epoch [9/100], Step [7800/24597], Loss: 1.4221\n",
      "Epoch [9/100], Step [7900/24597], Loss: 1.7611\n",
      "Epoch [9/100], Step [8000/24597], Loss: 1.5188\n",
      "Epoch [9/100], Step [8100/24597], Loss: 1.5126\n",
      "Epoch [9/100], Step [8200/24597], Loss: 1.6692\n",
      "Epoch [9/100], Step [8300/24597], Loss: 1.5804\n",
      "Epoch [9/100], Step [8400/24597], Loss: 1.5163\n",
      "Epoch [9/100], Step [8500/24597], Loss: 1.6865\n",
      "Epoch [9/100], Step [8600/24597], Loss: 1.5981\n",
      "Epoch [9/100], Step [8700/24597], Loss: 1.5981\n",
      "Epoch [9/100], Step [8800/24597], Loss: 1.7223\n",
      "Epoch [9/100], Step [8900/24597], Loss: 1.5822\n",
      "Epoch [9/100], Step [9000/24597], Loss: 1.5572\n",
      "Epoch [9/100], Step [9100/24597], Loss: 1.5931\n",
      "Epoch [9/100], Step [9200/24597], Loss: 1.8720\n",
      "Epoch [9/100], Step [9300/24597], Loss: 1.4798\n",
      "Epoch [9/100], Step [9400/24597], Loss: 1.8534\n",
      "Epoch [9/100], Step [9500/24597], Loss: 1.5826\n",
      "Epoch [9/100], Step [9600/24597], Loss: 1.4960\n",
      "Epoch [9/100], Step [9700/24597], Loss: 1.6343\n",
      "Epoch [9/100], Step [9800/24597], Loss: 1.7273\n",
      "Epoch [9/100], Step [9900/24597], Loss: 1.5668\n",
      "Epoch [9/100], Step [10000/24597], Loss: 1.5257\n",
      "Epoch [9/100], Step [10100/24597], Loss: 1.7195\n",
      "Epoch [9/100], Step [10200/24597], Loss: 1.5288\n",
      "Epoch [9/100], Step [10300/24597], Loss: 1.8923\n",
      "Epoch [9/100], Step [10400/24597], Loss: 1.5795\n",
      "Epoch [9/100], Step [10500/24597], Loss: 1.6630\n",
      "Epoch [9/100], Step [10600/24597], Loss: 1.8168\n",
      "Epoch [9/100], Step [10700/24597], Loss: 1.7212\n",
      "Epoch [9/100], Step [10800/24597], Loss: 1.6094\n",
      "Epoch [9/100], Step [10900/24597], Loss: 1.7086\n",
      "Epoch [9/100], Step [11000/24597], Loss: 1.6446\n",
      "Epoch [9/100], Step [11100/24597], Loss: 1.5136\n",
      "Epoch [9/100], Step [11200/24597], Loss: 1.5445\n",
      "Epoch [9/100], Step [11300/24597], Loss: 1.7816\n",
      "Epoch [9/100], Step [11400/24597], Loss: 1.7432\n",
      "Epoch [9/100], Step [11500/24597], Loss: 1.6484\n",
      "Epoch [9/100], Step [11600/24597], Loss: 1.5610\n",
      "Epoch [9/100], Step [11700/24597], Loss: 1.7311\n",
      "Epoch [9/100], Step [11800/24597], Loss: 1.4821\n",
      "Epoch [9/100], Step [11900/24597], Loss: 1.4967\n",
      "Epoch [9/100], Step [12000/24597], Loss: 1.7100\n",
      "Epoch [9/100], Step [12100/24597], Loss: 1.8434\n",
      "Epoch [9/100], Step [12200/24597], Loss: 1.6002\n",
      "Epoch [9/100], Step [12300/24597], Loss: 1.6309\n",
      "Epoch [9/100], Step [12400/24597], Loss: 1.6057\n",
      "Epoch [9/100], Step [12500/24597], Loss: 1.5392\n",
      "Epoch [9/100], Step [12600/24597], Loss: 1.6975\n",
      "Epoch [9/100], Step [12700/24597], Loss: 1.8962\n",
      "Epoch [9/100], Step [12800/24597], Loss: 1.6828\n",
      "Epoch [9/100], Step [12900/24597], Loss: 1.8610\n",
      "Epoch [9/100], Step [13000/24597], Loss: 1.6940\n",
      "Epoch [9/100], Step [13100/24597], Loss: 1.7377\n",
      "Epoch [9/100], Step [13200/24597], Loss: 1.6107\n",
      "Epoch [9/100], Step [13300/24597], Loss: 1.5700\n",
      "Epoch [9/100], Step [13400/24597], Loss: 1.6863\n",
      "Epoch [9/100], Step [13500/24597], Loss: 1.4359\n",
      "Epoch [9/100], Step [13600/24597], Loss: 1.3667\n",
      "Epoch [9/100], Step [13700/24597], Loss: 1.6468\n",
      "Epoch [9/100], Step [13800/24597], Loss: 1.6989\n",
      "Epoch [9/100], Step [13900/24597], Loss: 1.6327\n",
      "Epoch [9/100], Step [14000/24597], Loss: 2.0147\n",
      "Epoch [9/100], Step [14100/24597], Loss: 1.4543\n",
      "Epoch [9/100], Step [14200/24597], Loss: 1.7332\n",
      "Epoch [9/100], Step [14300/24597], Loss: 1.5860\n",
      "Epoch [9/100], Step [14400/24597], Loss: 1.3832\n",
      "Epoch [9/100], Step [14500/24597], Loss: 1.6749\n",
      "Epoch [9/100], Step [14600/24597], Loss: 1.5413\n",
      "Epoch [9/100], Step [14700/24597], Loss: 1.4210\n",
      "Epoch [9/100], Step [14800/24597], Loss: 1.8247\n",
      "Epoch [9/100], Step [14900/24597], Loss: 1.6607\n",
      "Epoch [9/100], Step [15000/24597], Loss: 1.5690\n",
      "Epoch [9/100], Step [15100/24597], Loss: 1.8765\n",
      "Epoch [9/100], Step [15200/24597], Loss: 1.5842\n",
      "Epoch [9/100], Step [15300/24597], Loss: 1.6697\n",
      "Epoch [9/100], Step [15400/24597], Loss: 1.6633\n",
      "Epoch [9/100], Step [15500/24597], Loss: 1.6914\n",
      "Epoch [9/100], Step [15600/24597], Loss: 1.7368\n",
      "Epoch [9/100], Step [15700/24597], Loss: 1.7038\n",
      "Epoch [9/100], Step [15800/24597], Loss: 1.5756\n",
      "Epoch [9/100], Step [15900/24597], Loss: 1.7898\n",
      "Epoch [9/100], Step [16000/24597], Loss: 1.5937\n",
      "Epoch [9/100], Step [16100/24597], Loss: 1.5482\n",
      "Epoch [9/100], Step [16200/24597], Loss: 1.5565\n",
      "Epoch [9/100], Step [16300/24597], Loss: 1.7313\n",
      "Epoch [9/100], Step [16400/24597], Loss: 1.6257\n",
      "Epoch [9/100], Step [16500/24597], Loss: 1.4267\n",
      "Epoch [9/100], Step [16600/24597], Loss: 1.6860\n",
      "Epoch [9/100], Step [16700/24597], Loss: 1.3484\n",
      "Epoch [9/100], Step [16800/24597], Loss: 1.7066\n",
      "Epoch [9/100], Step [16900/24597], Loss: 1.6748\n",
      "Epoch [9/100], Step [17000/24597], Loss: 1.5681\n",
      "Epoch [9/100], Step [17100/24597], Loss: 1.8896\n",
      "Epoch [9/100], Step [17200/24597], Loss: 1.5649\n",
      "Epoch [9/100], Step [17300/24597], Loss: 1.5431\n",
      "Epoch [9/100], Step [17400/24597], Loss: 1.5530\n",
      "Epoch [9/100], Step [17500/24597], Loss: 1.5675\n",
      "Epoch [9/100], Step [17600/24597], Loss: 1.4939\n",
      "Epoch [9/100], Step [17700/24597], Loss: 1.8722\n",
      "Epoch [9/100], Step [17800/24597], Loss: 1.4078\n",
      "Epoch [9/100], Step [17900/24597], Loss: 1.6266\n",
      "Epoch [9/100], Step [18000/24597], Loss: 1.4686\n",
      "Epoch [9/100], Step [18100/24597], Loss: 1.5441\n",
      "Epoch [9/100], Step [18200/24597], Loss: 1.5927\n",
      "Epoch [9/100], Step [18300/24597], Loss: 1.6621\n",
      "Epoch [9/100], Step [18400/24597], Loss: 1.7709\n",
      "Epoch [9/100], Step [18500/24597], Loss: 1.6740\n",
      "Epoch [9/100], Step [18600/24597], Loss: 1.6731\n",
      "Epoch [9/100], Step [18700/24597], Loss: 1.5163\n",
      "Epoch [9/100], Step [18800/24597], Loss: 1.6075\n",
      "Epoch [9/100], Step [18900/24597], Loss: 1.4212\n",
      "Epoch [9/100], Step [19000/24597], Loss: 1.6427\n",
      "Epoch [9/100], Step [19100/24597], Loss: 1.5729\n",
      "Epoch [9/100], Step [19200/24597], Loss: 1.7529\n",
      "Epoch [9/100], Step [19300/24597], Loss: 1.4897\n",
      "Epoch [9/100], Step [19400/24597], Loss: 1.6161\n",
      "Epoch [9/100], Step [19500/24597], Loss: 1.3099\n",
      "Epoch [9/100], Step [19600/24597], Loss: 1.5358\n",
      "Epoch [9/100], Step [19700/24597], Loss: 1.6220\n",
      "Epoch [9/100], Step [19800/24597], Loss: 1.7809\n",
      "Epoch [9/100], Step [19900/24597], Loss: 1.6821\n",
      "Epoch [9/100], Step [20000/24597], Loss: 1.6888\n",
      "Epoch [9/100], Step [20100/24597], Loss: 1.7369\n",
      "Epoch [9/100], Step [20200/24597], Loss: 1.5031\n",
      "Epoch [9/100], Step [20300/24597], Loss: 1.4730\n",
      "Epoch [9/100], Step [20400/24597], Loss: 1.7071\n",
      "Epoch [9/100], Step [20500/24597], Loss: 1.6049\n",
      "Epoch [9/100], Step [20600/24597], Loss: 1.7596\n",
      "Epoch [9/100], Step [20700/24597], Loss: 1.6484\n",
      "Epoch [9/100], Step [20800/24597], Loss: 1.5320\n",
      "Epoch [9/100], Step [20900/24597], Loss: 1.7666\n",
      "Epoch [9/100], Step [21000/24597], Loss: 1.7425\n",
      "Epoch [9/100], Step [21100/24597], Loss: 1.5407\n",
      "Epoch [9/100], Step [21200/24597], Loss: 1.4481\n",
      "Epoch [9/100], Step [21300/24597], Loss: 1.5842\n",
      "Epoch [9/100], Step [21400/24597], Loss: 1.6908\n",
      "Epoch [9/100], Step [21500/24597], Loss: 1.6228\n",
      "Epoch [9/100], Step [21600/24597], Loss: 1.6915\n",
      "Epoch [9/100], Step [21700/24597], Loss: 1.7017\n",
      "Epoch [9/100], Step [21800/24597], Loss: 1.5962\n",
      "Epoch [9/100], Step [21900/24597], Loss: 1.5062\n",
      "Epoch [9/100], Step [22000/24597], Loss: 1.6300\n",
      "Epoch [9/100], Step [22100/24597], Loss: 1.5168\n",
      "Epoch [9/100], Step [22200/24597], Loss: 1.6189\n",
      "Epoch [9/100], Step [22300/24597], Loss: 1.6418\n",
      "Epoch [9/100], Step [22400/24597], Loss: 1.7438\n",
      "Epoch [9/100], Step [22500/24597], Loss: 1.6590\n",
      "Epoch [9/100], Step [22600/24597], Loss: 1.6809\n",
      "Epoch [9/100], Step [22700/24597], Loss: 1.4015\n",
      "Epoch [9/100], Step [22800/24597], Loss: 1.7025\n",
      "Epoch [9/100], Step [22900/24597], Loss: 1.5598\n",
      "Epoch [9/100], Step [23000/24597], Loss: 1.7404\n",
      "Epoch [9/100], Step [23100/24597], Loss: 1.7324\n",
      "Epoch [9/100], Step [23200/24597], Loss: 1.6649\n",
      "Epoch [9/100], Step [23300/24597], Loss: 1.5448\n",
      "Epoch [9/100], Step [23400/24597], Loss: 1.8099\n",
      "Epoch [9/100], Step [23500/24597], Loss: 1.7000\n",
      "Epoch [9/100], Step [23600/24597], Loss: 1.6748\n",
      "Epoch [9/100], Step [23700/24597], Loss: 1.6692\n",
      "Epoch [9/100], Step [23800/24597], Loss: 1.7598\n",
      "Epoch [9/100], Step [23900/24597], Loss: 1.8098\n",
      "Epoch [9/100], Step [24000/24597], Loss: 1.7228\n",
      "Epoch [9/100], Step [24100/24597], Loss: 1.5756\n",
      "Epoch [9/100], Step [24200/24597], Loss: 1.6349\n",
      "Epoch [9/100], Step [24300/24597], Loss: 1.7021\n",
      "Epoch [9/100], Step [24400/24597], Loss: 1.5852\n",
      "Epoch [9/100], Step [24500/24597], Loss: 1.7244\n",
      "Epoch [10/100], Step [100/24597], Loss: 1.8718\n",
      "Epoch [10/100], Step [200/24597], Loss: 1.6124\n",
      "Epoch [10/100], Step [300/24597], Loss: 1.4684\n",
      "Epoch [10/100], Step [400/24597], Loss: 1.6475\n",
      "Epoch [10/100], Step [500/24597], Loss: 1.5451\n",
      "Epoch [10/100], Step [600/24597], Loss: 1.7053\n",
      "Epoch [10/100], Step [700/24597], Loss: 1.5353\n",
      "Epoch [10/100], Step [800/24597], Loss: 1.5895\n",
      "Epoch [10/100], Step [900/24597], Loss: 1.6850\n",
      "Epoch [10/100], Step [1000/24597], Loss: 1.6471\n",
      "Epoch [10/100], Step [1100/24597], Loss: 1.5019\n",
      "Epoch [10/100], Step [1200/24597], Loss: 1.8569\n",
      "Epoch [10/100], Step [1300/24597], Loss: 1.5993\n",
      "Epoch [10/100], Step [1400/24597], Loss: 1.7504\n",
      "Epoch [10/100], Step [1500/24597], Loss: 1.5681\n",
      "Epoch [10/100], Step [1600/24597], Loss: 1.5219\n",
      "Epoch [10/100], Step [1700/24597], Loss: 1.7007\n",
      "Epoch [10/100], Step [1800/24597], Loss: 1.6109\n",
      "Epoch [10/100], Step [1900/24597], Loss: 1.6563\n",
      "Epoch [10/100], Step [2000/24597], Loss: 1.6669\n",
      "Epoch [10/100], Step [2100/24597], Loss: 1.4467\n",
      "Epoch [10/100], Step [2200/24597], Loss: 1.7536\n",
      "Epoch [10/100], Step [2300/24597], Loss: 1.5112\n",
      "Epoch [10/100], Step [2400/24597], Loss: 1.4981\n",
      "Epoch [10/100], Step [2500/24597], Loss: 1.4883\n",
      "Epoch [10/100], Step [2600/24597], Loss: 1.7095\n",
      "Epoch [10/100], Step [2700/24597], Loss: 1.8230\n",
      "Epoch [10/100], Step [2800/24597], Loss: 1.6071\n",
      "Epoch [10/100], Step [2900/24597], Loss: 1.6527\n",
      "Epoch [10/100], Step [3000/24597], Loss: 1.6266\n",
      "Epoch [10/100], Step [3100/24597], Loss: 1.5252\n",
      "Epoch [10/100], Step [3200/24597], Loss: 1.5992\n",
      "Epoch [10/100], Step [3300/24597], Loss: 1.7261\n",
      "Epoch [10/100], Step [3400/24597], Loss: 1.9234\n",
      "Epoch [10/100], Step [3500/24597], Loss: 1.4246\n",
      "Epoch [10/100], Step [3600/24597], Loss: 1.6825\n",
      "Epoch [10/100], Step [3700/24597], Loss: 1.6071\n",
      "Epoch [10/100], Step [3800/24597], Loss: 1.8562\n",
      "Epoch [10/100], Step [3900/24597], Loss: 1.6431\n",
      "Epoch [10/100], Step [4000/24597], Loss: 1.7703\n",
      "Epoch [10/100], Step [4100/24597], Loss: 1.6398\n",
      "Epoch [10/100], Step [4200/24597], Loss: 1.4714\n",
      "Epoch [10/100], Step [4300/24597], Loss: 1.8219\n",
      "Epoch [10/100], Step [4400/24597], Loss: 1.5388\n",
      "Epoch [10/100], Step [4500/24597], Loss: 1.8021\n",
      "Epoch [10/100], Step [4600/24597], Loss: 1.4836\n",
      "Epoch [10/100], Step [4700/24597], Loss: 1.8174\n",
      "Epoch [10/100], Step [4800/24597], Loss: 1.7197\n",
      "Epoch [10/100], Step [4900/24597], Loss: 1.7437\n",
      "Epoch [10/100], Step [5000/24597], Loss: 1.7059\n",
      "Epoch [10/100], Step [5100/24597], Loss: 1.5333\n",
      "Epoch [10/100], Step [5200/24597], Loss: 1.4870\n",
      "Epoch [10/100], Step [5300/24597], Loss: 1.6680\n",
      "Epoch [10/100], Step [5400/24597], Loss: 1.7511\n",
      "Epoch [10/100], Step [5500/24597], Loss: 1.5168\n",
      "Epoch [10/100], Step [5600/24597], Loss: 1.8007\n",
      "Epoch [10/100], Step [5700/24597], Loss: 1.5917\n",
      "Epoch [10/100], Step [5800/24597], Loss: 1.7226\n",
      "Epoch [10/100], Step [5900/24597], Loss: 1.5525\n",
      "Epoch [10/100], Step [6000/24597], Loss: 1.7192\n",
      "Epoch [10/100], Step [6100/24597], Loss: 1.7239\n",
      "Epoch [10/100], Step [6200/24597], Loss: 1.6431\n",
      "Epoch [10/100], Step [6300/24597], Loss: 1.7098\n",
      "Epoch [10/100], Step [6400/24597], Loss: 1.6470\n",
      "Epoch [10/100], Step [6500/24597], Loss: 1.9133\n",
      "Epoch [10/100], Step [6600/24597], Loss: 1.8368\n",
      "Epoch [10/100], Step [6700/24597], Loss: 1.8277\n",
      "Epoch [10/100], Step [6800/24597], Loss: 1.8670\n",
      "Epoch [10/100], Step [6900/24597], Loss: 1.3719\n",
      "Epoch [10/100], Step [7000/24597], Loss: 1.6488\n",
      "Epoch [10/100], Step [7100/24597], Loss: 1.5229\n",
      "Epoch [10/100], Step [7200/24597], Loss: 1.6053\n",
      "Epoch [10/100], Step [7300/24597], Loss: 1.6810\n",
      "Epoch [10/100], Step [7400/24597], Loss: 1.5872\n",
      "Epoch [10/100], Step [7500/24597], Loss: 1.6656\n",
      "Epoch [10/100], Step [7600/24597], Loss: 1.4581\n",
      "Epoch [10/100], Step [7700/24597], Loss: 1.7873\n",
      "Epoch [10/100], Step [7800/24597], Loss: 1.5373\n",
      "Epoch [10/100], Step [7900/24597], Loss: 1.8739\n",
      "Epoch [10/100], Step [8000/24597], Loss: 1.6880\n",
      "Epoch [10/100], Step [8100/24597], Loss: 1.4668\n",
      "Epoch [10/100], Step [8200/24597], Loss: 1.6702\n",
      "Epoch [10/100], Step [8300/24597], Loss: 1.5653\n",
      "Epoch [10/100], Step [8400/24597], Loss: 1.5614\n",
      "Epoch [10/100], Step [8500/24597], Loss: 1.5822\n",
      "Epoch [10/100], Step [8600/24597], Loss: 1.4659\n",
      "Epoch [10/100], Step [8700/24597], Loss: 1.5765\n",
      "Epoch [10/100], Step [8800/24597], Loss: 1.6380\n",
      "Epoch [10/100], Step [8900/24597], Loss: 1.8363\n",
      "Epoch [10/100], Step [9000/24597], Loss: 1.5774\n",
      "Epoch [10/100], Step [9100/24597], Loss: 1.7639\n",
      "Epoch [10/100], Step [9200/24597], Loss: 1.7070\n",
      "Epoch [10/100], Step [9300/24597], Loss: 1.6031\n",
      "Epoch [10/100], Step [9400/24597], Loss: 1.9385\n",
      "Epoch [10/100], Step [9500/24597], Loss: 1.6455\n",
      "Epoch [10/100], Step [9600/24597], Loss: 1.6205\n",
      "Epoch [10/100], Step [9700/24597], Loss: 1.6561\n",
      "Epoch [10/100], Step [9800/24597], Loss: 1.5415\n",
      "Epoch [10/100], Step [9900/24597], Loss: 1.7742\n",
      "Epoch [10/100], Step [10000/24597], Loss: 1.4778\n",
      "Epoch [10/100], Step [10100/24597], Loss: 1.4784\n",
      "Epoch [10/100], Step [10200/24597], Loss: 1.6540\n",
      "Epoch [10/100], Step [10300/24597], Loss: 1.6783\n",
      "Epoch [10/100], Step [10400/24597], Loss: 1.7378\n",
      "Epoch [10/100], Step [10500/24597], Loss: 1.5803\n",
      "Epoch [10/100], Step [10600/24597], Loss: 1.8275\n",
      "Epoch [10/100], Step [10700/24597], Loss: 1.4663\n",
      "Epoch [10/100], Step [10800/24597], Loss: 1.7844\n",
      "Epoch [10/100], Step [10900/24597], Loss: 1.7186\n",
      "Epoch [10/100], Step [11000/24597], Loss: 1.4867\n",
      "Epoch [10/100], Step [11100/24597], Loss: 1.6155\n",
      "Epoch [10/100], Step [11200/24597], Loss: 1.7919\n",
      "Epoch [10/100], Step [11300/24597], Loss: 1.6115\n",
      "Epoch [10/100], Step [11400/24597], Loss: 1.7172\n",
      "Epoch [10/100], Step [11500/24597], Loss: 1.8849\n",
      "Epoch [10/100], Step [11600/24597], Loss: 1.5072\n",
      "Epoch [10/100], Step [11700/24597], Loss: 1.5021\n",
      "Epoch [10/100], Step [11800/24597], Loss: 1.4048\n",
      "Epoch [10/100], Step [11900/24597], Loss: 1.5780\n",
      "Epoch [10/100], Step [12000/24597], Loss: 1.4258\n",
      "Epoch [10/100], Step [12100/24597], Loss: 1.6890\n",
      "Epoch [10/100], Step [12200/24597], Loss: 1.5278\n",
      "Epoch [10/100], Step [12300/24597], Loss: 1.6768\n",
      "Epoch [10/100], Step [12400/24597], Loss: 1.4451\n",
      "Epoch [10/100], Step [12500/24597], Loss: 1.5291\n",
      "Epoch [10/100], Step [12600/24597], Loss: 1.7936\n",
      "Epoch [10/100], Step [12700/24597], Loss: 1.8251\n",
      "Epoch [10/100], Step [12800/24597], Loss: 1.8722\n",
      "Epoch [10/100], Step [12900/24597], Loss: 1.6501\n",
      "Epoch [10/100], Step [13000/24597], Loss: 1.3039\n",
      "Epoch [10/100], Step [13100/24597], Loss: 1.6414\n",
      "Epoch [10/100], Step [13200/24597], Loss: 1.6817\n",
      "Epoch [10/100], Step [13300/24597], Loss: 1.6326\n",
      "Epoch [10/100], Step [13400/24597], Loss: 1.4954\n",
      "Epoch [10/100], Step [13500/24597], Loss: 1.6875\n",
      "Epoch [10/100], Step [13600/24597], Loss: 1.3997\n",
      "Epoch [10/100], Step [13700/24597], Loss: 1.8258\n",
      "Epoch [10/100], Step [13800/24597], Loss: 1.5213\n",
      "Epoch [10/100], Step [13900/24597], Loss: 1.5865\n",
      "Epoch [10/100], Step [14000/24597], Loss: 1.6445\n",
      "Epoch [10/100], Step [14100/24597], Loss: 1.6431\n",
      "Epoch [10/100], Step [14200/24597], Loss: 1.7544\n",
      "Epoch [10/100], Step [14300/24597], Loss: 1.5591\n",
      "Epoch [10/100], Step [14400/24597], Loss: 1.5826\n",
      "Epoch [10/100], Step [14500/24597], Loss: 1.4535\n",
      "Epoch [10/100], Step [14600/24597], Loss: 1.6969\n",
      "Epoch [10/100], Step [14700/24597], Loss: 1.7369\n",
      "Epoch [10/100], Step [14800/24597], Loss: 1.5255\n",
      "Epoch [10/100], Step [14900/24597], Loss: 1.5070\n",
      "Epoch [10/100], Step [15000/24597], Loss: 1.5152\n",
      "Epoch [10/100], Step [15100/24597], Loss: 1.4129\n",
      "Epoch [10/100], Step [15200/24597], Loss: 1.5081\n",
      "Epoch [10/100], Step [15300/24597], Loss: 1.5430\n",
      "Epoch [10/100], Step [15400/24597], Loss: 1.6911\n",
      "Epoch [10/100], Step [15500/24597], Loss: 1.5339\n",
      "Epoch [10/100], Step [15600/24597], Loss: 1.5023\n",
      "Epoch [10/100], Step [15700/24597], Loss: 1.5201\n",
      "Epoch [10/100], Step [15800/24597], Loss: 1.6081\n",
      "Epoch [10/100], Step [15900/24597], Loss: 1.6557\n",
      "Epoch [10/100], Step [16000/24597], Loss: 2.0118\n",
      "Epoch [10/100], Step [16100/24597], Loss: 1.6877\n",
      "Epoch [10/100], Step [16200/24597], Loss: 1.7042\n",
      "Epoch [10/100], Step [16300/24597], Loss: 1.4660\n",
      "Epoch [10/100], Step [16400/24597], Loss: 1.7278\n",
      "Epoch [10/100], Step [16500/24597], Loss: 1.5692\n",
      "Epoch [10/100], Step [16600/24597], Loss: 1.5287\n",
      "Epoch [10/100], Step [16700/24597], Loss: 1.4975\n",
      "Epoch [10/100], Step [16800/24597], Loss: 1.6397\n",
      "Epoch [10/100], Step [16900/24597], Loss: 1.5305\n",
      "Epoch [10/100], Step [17000/24597], Loss: 1.6681\n",
      "Epoch [10/100], Step [17100/24597], Loss: 1.5509\n",
      "Epoch [10/100], Step [17200/24597], Loss: 1.4286\n",
      "Epoch [10/100], Step [17300/24597], Loss: 1.5941\n",
      "Epoch [10/100], Step [17400/24597], Loss: 1.6282\n",
      "Epoch [10/100], Step [17500/24597], Loss: 1.5704\n",
      "Epoch [10/100], Step [17600/24597], Loss: 1.7747\n",
      "Epoch [10/100], Step [17700/24597], Loss: 1.6081\n",
      "Epoch [10/100], Step [17800/24597], Loss: 1.6930\n",
      "Epoch [10/100], Step [17900/24597], Loss: 1.3840\n",
      "Epoch [10/100], Step [18000/24597], Loss: 1.7407\n",
      "Epoch [10/100], Step [18100/24597], Loss: 1.6935\n",
      "Epoch [10/100], Step [18200/24597], Loss: 1.5429\n",
      "Epoch [10/100], Step [18300/24597], Loss: 1.6492\n",
      "Epoch [10/100], Step [18400/24597], Loss: 1.6929\n",
      "Epoch [10/100], Step [18500/24597], Loss: 1.6349\n",
      "Epoch [10/100], Step [18600/24597], Loss: 1.4783\n",
      "Epoch [10/100], Step [18700/24597], Loss: 1.4104\n",
      "Epoch [10/100], Step [18800/24597], Loss: 1.6342\n",
      "Epoch [10/100], Step [18900/24597], Loss: 1.6205\n",
      "Epoch [10/100], Step [19000/24597], Loss: 1.7508\n",
      "Epoch [10/100], Step [19100/24597], Loss: 1.5367\n",
      "Epoch [10/100], Step [19200/24597], Loss: 1.7614\n",
      "Epoch [10/100], Step [19300/24597], Loss: 1.5827\n",
      "Epoch [10/100], Step [19400/24597], Loss: 1.4938\n",
      "Epoch [10/100], Step [19500/24597], Loss: 1.3631\n",
      "Epoch [10/100], Step [19600/24597], Loss: 1.5721\n",
      "Epoch [10/100], Step [19700/24597], Loss: 1.5592\n",
      "Epoch [10/100], Step [19800/24597], Loss: 1.5703\n",
      "Epoch [10/100], Step [19900/24597], Loss: 1.5202\n",
      "Epoch [10/100], Step [20000/24597], Loss: 1.6219\n",
      "Epoch [10/100], Step [20100/24597], Loss: 1.5162\n",
      "Epoch [10/100], Step [20200/24597], Loss: 1.5503\n",
      "Epoch [10/100], Step [20300/24597], Loss: 1.5403\n",
      "Epoch [10/100], Step [20400/24597], Loss: 1.4384\n",
      "Epoch [10/100], Step [20500/24597], Loss: 1.8205\n",
      "Epoch [10/100], Step [20600/24597], Loss: 1.5342\n",
      "Epoch [10/100], Step [20700/24597], Loss: 1.7087\n",
      "Epoch [10/100], Step [20800/24597], Loss: 1.6632\n",
      "Epoch [10/100], Step [20900/24597], Loss: 1.4898\n",
      "Epoch [10/100], Step [21000/24597], Loss: 1.7649\n",
      "Epoch [10/100], Step [21100/24597], Loss: 1.6509\n",
      "Epoch [10/100], Step [21200/24597], Loss: 1.7610\n",
      "Epoch [10/100], Step [21300/24597], Loss: 1.9566\n",
      "Epoch [10/100], Step [21400/24597], Loss: 1.6523\n",
      "Epoch [10/100], Step [21500/24597], Loss: 1.8199\n",
      "Epoch [10/100], Step [21600/24597], Loss: 1.5751\n",
      "Epoch [10/100], Step [21700/24597], Loss: 1.5212\n",
      "Epoch [10/100], Step [21800/24597], Loss: 1.5256\n",
      "Epoch [10/100], Step [21900/24597], Loss: 1.6291\n",
      "Epoch [10/100], Step [22000/24597], Loss: 1.5704\n",
      "Epoch [10/100], Step [22100/24597], Loss: 1.6128\n",
      "Epoch [10/100], Step [22200/24597], Loss: 1.7209\n",
      "Epoch [10/100], Step [22300/24597], Loss: 1.6943\n",
      "Epoch [10/100], Step [22400/24597], Loss: 1.7132\n",
      "Epoch [10/100], Step [22500/24597], Loss: 1.6674\n",
      "Epoch [10/100], Step [22600/24597], Loss: 1.6251\n",
      "Epoch [10/100], Step [22700/24597], Loss: 1.5442\n",
      "Epoch [10/100], Step [22800/24597], Loss: 1.6657\n",
      "Epoch [10/100], Step [22900/24597], Loss: 1.7000\n",
      "Epoch [10/100], Step [23000/24597], Loss: 1.5151\n",
      "Epoch [10/100], Step [23100/24597], Loss: 1.6961\n",
      "Epoch [10/100], Step [23200/24597], Loss: 1.8102\n",
      "Epoch [10/100], Step [23300/24597], Loss: 1.4953\n",
      "Epoch [10/100], Step [23400/24597], Loss: 1.6758\n",
      "Epoch [10/100], Step [23500/24597], Loss: 1.6589\n",
      "Epoch [10/100], Step [23600/24597], Loss: 1.6776\n",
      "Epoch [10/100], Step [23700/24597], Loss: 1.7310\n",
      "Epoch [10/100], Step [23800/24597], Loss: 1.4752\n",
      "Epoch [10/100], Step [23900/24597], Loss: 1.6604\n",
      "Epoch [10/100], Step [24000/24597], Loss: 1.7933\n",
      "Epoch [10/100], Step [24100/24597], Loss: 1.6285\n",
      "Epoch [10/100], Step [24200/24597], Loss: 1.7690\n",
      "Epoch [10/100], Step [24300/24597], Loss: 2.0312\n",
      "Epoch [10/100], Step [24400/24597], Loss: 1.7783\n",
      "Epoch [10/100], Step [24500/24597], Loss: 1.5115\n",
      "Epoch [11/100], Step [100/24597], Loss: 1.6143\n",
      "Epoch [11/100], Step [200/24597], Loss: 1.5984\n",
      "Epoch [11/100], Step [300/24597], Loss: 1.5770\n",
      "Epoch [11/100], Step [400/24597], Loss: 1.7592\n",
      "Epoch [11/100], Step [500/24597], Loss: 1.7583\n",
      "Epoch [11/100], Step [600/24597], Loss: 1.7814\n",
      "Epoch [11/100], Step [700/24597], Loss: 1.7057\n",
      "Epoch [11/100], Step [800/24597], Loss: 1.6392\n",
      "Epoch [11/100], Step [900/24597], Loss: 1.8771\n",
      "Epoch [11/100], Step [1000/24597], Loss: 1.6240\n",
      "Epoch [11/100], Step [1100/24597], Loss: 1.6698\n",
      "Epoch [11/100], Step [1200/24597], Loss: 1.6119\n",
      "Epoch [11/100], Step [1300/24597], Loss: 1.7661\n",
      "Epoch [11/100], Step [1400/24597], Loss: 1.5270\n",
      "Epoch [11/100], Step [1500/24597], Loss: 1.5555\n",
      "Epoch [11/100], Step [1600/24597], Loss: 1.5064\n",
      "Epoch [11/100], Step [1700/24597], Loss: 1.6180\n",
      "Epoch [11/100], Step [1800/24597], Loss: 1.4628\n",
      "Epoch [11/100], Step [1900/24597], Loss: 1.6144\n",
      "Epoch [11/100], Step [2000/24597], Loss: 1.3439\n",
      "Epoch [11/100], Step [2100/24597], Loss: 1.4297\n",
      "Epoch [11/100], Step [2200/24597], Loss: 1.4368\n",
      "Epoch [11/100], Step [2300/24597], Loss: 1.7643\n",
      "Epoch [11/100], Step [2400/24597], Loss: 1.6868\n",
      "Epoch [11/100], Step [2500/24597], Loss: 1.5387\n",
      "Epoch [11/100], Step [2600/24597], Loss: 1.5693\n",
      "Epoch [11/100], Step [2700/24597], Loss: 1.5670\n",
      "Epoch [11/100], Step [2800/24597], Loss: 1.5795\n",
      "Epoch [11/100], Step [2900/24597], Loss: 1.5852\n",
      "Epoch [11/100], Step [3000/24597], Loss: 1.8544\n",
      "Epoch [11/100], Step [3100/24597], Loss: 1.5165\n",
      "Epoch [11/100], Step [3200/24597], Loss: 1.7131\n",
      "Epoch [11/100], Step [3300/24597], Loss: 1.4412\n",
      "Epoch [11/100], Step [3400/24597], Loss: 1.6609\n",
      "Epoch [11/100], Step [3500/24597], Loss: 1.7271\n",
      "Epoch [11/100], Step [3600/24597], Loss: 1.4588\n",
      "Epoch [11/100], Step [3700/24597], Loss: 1.6366\n",
      "Epoch [11/100], Step [3800/24597], Loss: 1.6069\n",
      "Epoch [11/100], Step [3900/24597], Loss: 1.5250\n",
      "Epoch [11/100], Step [4000/24597], Loss: 1.7285\n",
      "Epoch [11/100], Step [4100/24597], Loss: 1.4999\n",
      "Epoch [11/100], Step [4200/24597], Loss: 1.6963\n",
      "Epoch [11/100], Step [4300/24597], Loss: 1.6608\n",
      "Epoch [11/100], Step [4400/24597], Loss: 1.5263\n",
      "Epoch [11/100], Step [4500/24597], Loss: 1.7404\n",
      "Epoch [11/100], Step [4600/24597], Loss: 1.5412\n",
      "Epoch [11/100], Step [4700/24597], Loss: 1.6695\n",
      "Epoch [11/100], Step [4800/24597], Loss: 1.5739\n",
      "Epoch [11/100], Step [4900/24597], Loss: 1.5124\n",
      "Epoch [11/100], Step [5000/24597], Loss: 1.4246\n",
      "Epoch [11/100], Step [5100/24597], Loss: 1.6098\n",
      "Epoch [11/100], Step [5200/24597], Loss: 1.7353\n",
      "Epoch [11/100], Step [5300/24597], Loss: 1.5217\n",
      "Epoch [11/100], Step [5400/24597], Loss: 1.3679\n",
      "Epoch [11/100], Step [5500/24597], Loss: 1.5562\n",
      "Epoch [11/100], Step [5600/24597], Loss: 1.7146\n",
      "Epoch [11/100], Step [5700/24597], Loss: 1.5957\n",
      "Epoch [11/100], Step [5800/24597], Loss: 1.6975\n",
      "Epoch [11/100], Step [5900/24597], Loss: 1.5941\n",
      "Epoch [11/100], Step [6000/24597], Loss: 1.4748\n",
      "Epoch [11/100], Step [6100/24597], Loss: 1.6711\n",
      "Epoch [11/100], Step [6200/24597], Loss: 1.7811\n",
      "Epoch [11/100], Step [6300/24597], Loss: 1.6215\n",
      "Epoch [11/100], Step [6400/24597], Loss: 1.7113\n",
      "Epoch [11/100], Step [6500/24597], Loss: 1.8754\n",
      "Epoch [11/100], Step [6600/24597], Loss: 1.7216\n",
      "Epoch [11/100], Step [6700/24597], Loss: 1.7121\n",
      "Epoch [11/100], Step [6800/24597], Loss: 1.5976\n",
      "Epoch [11/100], Step [6900/24597], Loss: 1.4528\n",
      "Epoch [11/100], Step [7000/24597], Loss: 1.7363\n",
      "Epoch [11/100], Step [7100/24597], Loss: 1.5402\n",
      "Epoch [11/100], Step [7200/24597], Loss: 1.5849\n",
      "Epoch [11/100], Step [7300/24597], Loss: 1.5096\n",
      "Epoch [11/100], Step [7400/24597], Loss: 1.5512\n",
      "Epoch [11/100], Step [7500/24597], Loss: 1.6209\n",
      "Epoch [11/100], Step [7600/24597], Loss: 1.8588\n",
      "Epoch [11/100], Step [7700/24597], Loss: 1.7493\n",
      "Epoch [11/100], Step [7800/24597], Loss: 1.5299\n",
      "Epoch [11/100], Step [7900/24597], Loss: 1.7773\n",
      "Epoch [11/100], Step [8000/24597], Loss: 1.5815\n",
      "Epoch [11/100], Step [8100/24597], Loss: 1.5298\n",
      "Epoch [11/100], Step [8200/24597], Loss: 1.5871\n",
      "Epoch [11/100], Step [8300/24597], Loss: 1.6389\n",
      "Epoch [11/100], Step [8400/24597], Loss: 1.6562\n",
      "Epoch [11/100], Step [8500/24597], Loss: 1.5571\n",
      "Epoch [11/100], Step [8600/24597], Loss: 1.5275\n",
      "Epoch [11/100], Step [8700/24597], Loss: 1.6629\n",
      "Epoch [11/100], Step [8800/24597], Loss: 1.6121\n",
      "Epoch [11/100], Step [8900/24597], Loss: 1.6054\n",
      "Epoch [11/100], Step [9000/24597], Loss: 1.5104\n",
      "Epoch [11/100], Step [9100/24597], Loss: 1.4423\n",
      "Epoch [11/100], Step [9200/24597], Loss: 1.6949\n",
      "Epoch [11/100], Step [9300/24597], Loss: 1.7078\n",
      "Epoch [11/100], Step [9400/24597], Loss: 1.4873\n",
      "Epoch [11/100], Step [9500/24597], Loss: 1.7233\n",
      "Epoch [11/100], Step [9600/24597], Loss: 1.6231\n",
      "Epoch [11/100], Step [9700/24597], Loss: 1.5331\n",
      "Epoch [11/100], Step [9800/24597], Loss: 1.6735\n",
      "Epoch [11/100], Step [9900/24597], Loss: 1.6137\n",
      "Epoch [11/100], Step [10000/24597], Loss: 1.7158\n",
      "Epoch [11/100], Step [10100/24597], Loss: 1.6431\n",
      "Epoch [11/100], Step [10200/24597], Loss: 1.6360\n",
      "Epoch [11/100], Step [10300/24597], Loss: 1.6047\n",
      "Epoch [11/100], Step [10400/24597], Loss: 1.6737\n",
      "Epoch [11/100], Step [10500/24597], Loss: 1.5348\n",
      "Epoch [11/100], Step [10600/24597], Loss: 1.6580\n",
      "Epoch [11/100], Step [10700/24597], Loss: 1.6761\n",
      "Epoch [11/100], Step [10800/24597], Loss: 1.5667\n",
      "Epoch [11/100], Step [10900/24597], Loss: 1.8756\n",
      "Epoch [11/100], Step [11000/24597], Loss: 1.5284\n",
      "Epoch [11/100], Step [11100/24597], Loss: 1.8145\n",
      "Epoch [11/100], Step [11200/24597], Loss: 1.6114\n",
      "Epoch [11/100], Step [11300/24597], Loss: 1.8945\n",
      "Epoch [11/100], Step [11400/24597], Loss: 1.5322\n",
      "Epoch [11/100], Step [11500/24597], Loss: 1.6377\n",
      "Epoch [11/100], Step [11600/24597], Loss: 1.3736\n",
      "Epoch [11/100], Step [11700/24597], Loss: 1.5302\n",
      "Epoch [11/100], Step [11800/24597], Loss: 1.7168\n",
      "Epoch [11/100], Step [11900/24597], Loss: 1.5600\n",
      "Epoch [11/100], Step [12000/24597], Loss: 1.3831\n",
      "Epoch [11/100], Step [12100/24597], Loss: 1.8862\n",
      "Epoch [11/100], Step [12200/24597], Loss: 1.7264\n",
      "Epoch [11/100], Step [12300/24597], Loss: 1.6432\n",
      "Epoch [11/100], Step [12400/24597], Loss: 1.6305\n",
      "Epoch [11/100], Step [12500/24597], Loss: 1.7996\n",
      "Epoch [11/100], Step [12600/24597], Loss: 1.6091\n",
      "Epoch [11/100], Step [12700/24597], Loss: 1.5732\n",
      "Epoch [11/100], Step [12800/24597], Loss: 1.4038\n",
      "Epoch [11/100], Step [12900/24597], Loss: 1.4847\n",
      "Epoch [11/100], Step [13000/24597], Loss: 1.5385\n",
      "Epoch [11/100], Step [13100/24597], Loss: 1.4593\n",
      "Epoch [11/100], Step [13200/24597], Loss: 1.6172\n",
      "Epoch [11/100], Step [13300/24597], Loss: 1.5649\n",
      "Epoch [11/100], Step [13400/24597], Loss: 1.6745\n",
      "Epoch [11/100], Step [13500/24597], Loss: 1.6413\n",
      "Epoch [11/100], Step [13600/24597], Loss: 1.6535\n",
      "Epoch [11/100], Step [13700/24597], Loss: 1.4278\n",
      "Epoch [11/100], Step [13800/24597], Loss: 1.5849\n",
      "Epoch [11/100], Step [13900/24597], Loss: 1.6335\n",
      "Epoch [11/100], Step [14000/24597], Loss: 1.5356\n",
      "Epoch [11/100], Step [14100/24597], Loss: 1.7754\n",
      "Epoch [11/100], Step [14200/24597], Loss: 1.8039\n",
      "Epoch [11/100], Step [14300/24597], Loss: 1.8023\n",
      "Epoch [11/100], Step [14400/24597], Loss: 1.5999\n",
      "Epoch [11/100], Step [14500/24597], Loss: 1.6139\n",
      "Epoch [11/100], Step [14600/24597], Loss: 1.6681\n",
      "Epoch [11/100], Step [14700/24597], Loss: 1.5443\n",
      "Epoch [11/100], Step [14800/24597], Loss: 1.7448\n",
      "Epoch [11/100], Step [14900/24597], Loss: 1.5265\n",
      "Epoch [11/100], Step [15000/24597], Loss: 1.5827\n",
      "Epoch [11/100], Step [15100/24597], Loss: 1.7810\n",
      "Epoch [11/100], Step [15200/24597], Loss: 1.4294\n",
      "Epoch [11/100], Step [15300/24597], Loss: 1.8202\n",
      "Epoch [11/100], Step [15400/24597], Loss: 1.6470\n",
      "Epoch [11/100], Step [15500/24597], Loss: 1.5538\n",
      "Epoch [11/100], Step [15600/24597], Loss: 1.7672\n",
      "Epoch [11/100], Step [15700/24597], Loss: 1.6593\n",
      "Epoch [11/100], Step [15800/24597], Loss: 1.6203\n",
      "Epoch [11/100], Step [15900/24597], Loss: 1.6631\n",
      "Epoch [11/100], Step [16000/24597], Loss: 1.6669\n",
      "Epoch [11/100], Step [16100/24597], Loss: 1.5549\n",
      "Epoch [11/100], Step [16200/24597], Loss: 1.6722\n",
      "Epoch [11/100], Step [16300/24597], Loss: 1.5152\n",
      "Epoch [11/100], Step [16400/24597], Loss: 1.5986\n",
      "Epoch [11/100], Step [16500/24597], Loss: 1.5887\n",
      "Epoch [11/100], Step [16600/24597], Loss: 1.5377\n",
      "Epoch [11/100], Step [16700/24597], Loss: 1.6803\n",
      "Epoch [11/100], Step [16800/24597], Loss: 1.5940\n",
      "Epoch [11/100], Step [16900/24597], Loss: 1.5335\n",
      "Epoch [11/100], Step [17000/24597], Loss: 1.4277\n",
      "Epoch [11/100], Step [17100/24597], Loss: 1.6866\n",
      "Epoch [11/100], Step [17200/24597], Loss: 1.8491\n",
      "Epoch [11/100], Step [17300/24597], Loss: 1.4855\n",
      "Epoch [11/100], Step [17400/24597], Loss: 1.7804\n",
      "Epoch [11/100], Step [17500/24597], Loss: 1.4908\n",
      "Epoch [11/100], Step [17600/24597], Loss: 1.5072\n",
      "Epoch [11/100], Step [17700/24597], Loss: 1.5548\n",
      "Epoch [11/100], Step [17800/24597], Loss: 1.4640\n",
      "Epoch [11/100], Step [17900/24597], Loss: 1.8104\n",
      "Epoch [11/100], Step [18000/24597], Loss: 1.7250\n",
      "Epoch [11/100], Step [18100/24597], Loss: 1.5942\n",
      "Epoch [11/100], Step [18200/24597], Loss: 1.6496\n",
      "Epoch [11/100], Step [18300/24597], Loss: 1.6822\n",
      "Epoch [11/100], Step [18400/24597], Loss: 1.6278\n",
      "Epoch [11/100], Step [18500/24597], Loss: 1.5269\n",
      "Epoch [11/100], Step [18600/24597], Loss: 1.4799\n",
      "Epoch [11/100], Step [18700/24597], Loss: 1.6333\n",
      "Epoch [11/100], Step [18800/24597], Loss: 1.6242\n",
      "Epoch [11/100], Step [18900/24597], Loss: 1.4725\n",
      "Epoch [11/100], Step [19000/24597], Loss: 1.7672\n",
      "Epoch [11/100], Step [19100/24597], Loss: 1.6217\n",
      "Epoch [11/100], Step [19200/24597], Loss: 1.7005\n",
      "Epoch [11/100], Step [19300/24597], Loss: 1.4286\n",
      "Epoch [11/100], Step [19400/24597], Loss: 1.7409\n",
      "Epoch [11/100], Step [19500/24597], Loss: 1.8565\n",
      "Epoch [11/100], Step [19600/24597], Loss: 1.5806\n",
      "Epoch [11/100], Step [19700/24597], Loss: 1.4028\n",
      "Epoch [11/100], Step [19800/24597], Loss: 1.6318\n",
      "Epoch [11/100], Step [19900/24597], Loss: 1.7733\n",
      "Epoch [11/100], Step [20000/24597], Loss: 1.7498\n",
      "Epoch [11/100], Step [20100/24597], Loss: 1.7777\n",
      "Epoch [11/100], Step [20200/24597], Loss: 1.7280\n",
      "Epoch [11/100], Step [20300/24597], Loss: 1.5872\n",
      "Epoch [11/100], Step [20400/24597], Loss: 1.5007\n",
      "Epoch [11/100], Step [20500/24597], Loss: 1.5905\n",
      "Epoch [11/100], Step [20600/24597], Loss: 1.8593\n",
      "Epoch [11/100], Step [20700/24597], Loss: 1.4879\n",
      "Epoch [11/100], Step [20800/24597], Loss: 1.7789\n",
      "Epoch [11/100], Step [20900/24597], Loss: 1.6531\n",
      "Epoch [11/100], Step [21000/24597], Loss: 1.7186\n",
      "Epoch [11/100], Step [21100/24597], Loss: 1.6461\n",
      "Epoch [11/100], Step [21200/24597], Loss: 1.5619\n",
      "Epoch [11/100], Step [21300/24597], Loss: 1.4964\n",
      "Epoch [11/100], Step [21400/24597], Loss: 1.6256\n",
      "Epoch [11/100], Step [21500/24597], Loss: 1.5918\n",
      "Epoch [11/100], Step [21600/24597], Loss: 1.5955\n",
      "Epoch [11/100], Step [21700/24597], Loss: 1.5985\n",
      "Epoch [11/100], Step [21800/24597], Loss: 1.6529\n",
      "Epoch [11/100], Step [21900/24597], Loss: 1.5189\n",
      "Epoch [11/100], Step [22000/24597], Loss: 1.6256\n",
      "Epoch [11/100], Step [22100/24597], Loss: 1.5387\n",
      "Epoch [11/100], Step [22200/24597], Loss: 1.5248\n",
      "Epoch [11/100], Step [22300/24597], Loss: 1.3819\n",
      "Epoch [11/100], Step [22400/24597], Loss: 1.6821\n",
      "Epoch [11/100], Step [22500/24597], Loss: 1.5365\n",
      "Epoch [11/100], Step [22600/24597], Loss: 1.5135\n",
      "Epoch [11/100], Step [22700/24597], Loss: 1.4637\n",
      "Epoch [11/100], Step [22800/24597], Loss: 1.5369\n",
      "Epoch [11/100], Step [22900/24597], Loss: 1.8769\n",
      "Epoch [11/100], Step [23000/24597], Loss: 1.9281\n",
      "Epoch [11/100], Step [23100/24597], Loss: 1.6812\n",
      "Epoch [11/100], Step [23200/24597], Loss: 1.6018\n",
      "Epoch [11/100], Step [23300/24597], Loss: 1.7089\n",
      "Epoch [11/100], Step [23400/24597], Loss: 1.4662\n",
      "Epoch [11/100], Step [23500/24597], Loss: 1.5884\n",
      "Epoch [11/100], Step [23600/24597], Loss: 1.6422\n",
      "Epoch [11/100], Step [23700/24597], Loss: 1.4953\n",
      "Epoch [11/100], Step [23800/24597], Loss: 1.8555\n",
      "Epoch [11/100], Step [23900/24597], Loss: 1.4942\n",
      "Epoch [11/100], Step [24000/24597], Loss: 1.6350\n",
      "Epoch [11/100], Step [24100/24597], Loss: 1.6086\n",
      "Epoch [11/100], Step [24200/24597], Loss: 1.7252\n",
      "Epoch [11/100], Step [24300/24597], Loss: 1.7006\n",
      "Epoch [11/100], Step [24400/24597], Loss: 1.5939\n",
      "Epoch [11/100], Step [24500/24597], Loss: 1.5137\n",
      "Epoch [12/100], Step [100/24597], Loss: 1.7590\n",
      "Epoch [12/100], Step [200/24597], Loss: 1.4881\n",
      "Epoch [12/100], Step [300/24597], Loss: 1.6743\n",
      "Epoch [12/100], Step [400/24597], Loss: 1.5429\n",
      "Epoch [12/100], Step [500/24597], Loss: 1.5450\n",
      "Epoch [12/100], Step [600/24597], Loss: 1.7249\n",
      "Epoch [12/100], Step [700/24597], Loss: 1.5393\n",
      "Epoch [12/100], Step [800/24597], Loss: 1.7088\n",
      "Epoch [12/100], Step [900/24597], Loss: 1.7389\n",
      "Epoch [12/100], Step [1000/24597], Loss: 1.6916\n",
      "Epoch [12/100], Step [1100/24597], Loss: 1.7746\n",
      "Epoch [12/100], Step [1200/24597], Loss: 1.7803\n",
      "Epoch [12/100], Step [1300/24597], Loss: 1.5624\n",
      "Epoch [12/100], Step [1400/24597], Loss: 1.3975\n",
      "Epoch [12/100], Step [1500/24597], Loss: 1.5434\n",
      "Epoch [12/100], Step [1600/24597], Loss: 1.4434\n",
      "Epoch [12/100], Step [1700/24597], Loss: 1.4418\n",
      "Epoch [12/100], Step [1800/24597], Loss: 1.3852\n",
      "Epoch [12/100], Step [1900/24597], Loss: 1.5271\n",
      "Epoch [12/100], Step [2000/24597], Loss: 1.4256\n",
      "Epoch [12/100], Step [2100/24597], Loss: 1.5958\n",
      "Epoch [12/100], Step [2200/24597], Loss: 1.3598\n",
      "Epoch [12/100], Step [2300/24597], Loss: 1.7322\n",
      "Epoch [12/100], Step [2400/24597], Loss: 1.5119\n",
      "Epoch [12/100], Step [2500/24597], Loss: 1.4534\n",
      "Epoch [12/100], Step [2600/24597], Loss: 1.4465\n",
      "Epoch [12/100], Step [2700/24597], Loss: 1.7992\n",
      "Epoch [12/100], Step [2800/24597], Loss: 1.5473\n",
      "Epoch [12/100], Step [2900/24597], Loss: 1.5026\n",
      "Epoch [12/100], Step [3000/24597], Loss: 1.7398\n",
      "Epoch [12/100], Step [3100/24597], Loss: 1.7530\n",
      "Epoch [12/100], Step [3200/24597], Loss: 1.6612\n",
      "Epoch [12/100], Step [3300/24597], Loss: 1.7142\n",
      "Epoch [12/100], Step [3400/24597], Loss: 1.6732\n",
      "Epoch [12/100], Step [3500/24597], Loss: 1.5096\n",
      "Epoch [12/100], Step [3600/24597], Loss: 1.6854\n",
      "Epoch [12/100], Step [3700/24597], Loss: 1.4657\n",
      "Epoch [12/100], Step [3800/24597], Loss: 1.5879\n",
      "Epoch [12/100], Step [3900/24597], Loss: 1.6396\n",
      "Epoch [12/100], Step [4000/24597], Loss: 1.6803\n",
      "Epoch [12/100], Step [4100/24597], Loss: 1.6441\n",
      "Epoch [12/100], Step [4200/24597], Loss: 1.4316\n",
      "Epoch [12/100], Step [4300/24597], Loss: 1.5044\n",
      "Epoch [12/100], Step [4400/24597], Loss: 1.5413\n",
      "Epoch [12/100], Step [4500/24597], Loss: 1.7013\n",
      "Epoch [12/100], Step [4600/24597], Loss: 1.5896\n",
      "Epoch [12/100], Step [4700/24597], Loss: 1.6453\n",
      "Epoch [12/100], Step [4800/24597], Loss: 1.9104\n",
      "Epoch [12/100], Step [4900/24597], Loss: 1.6005\n",
      "Epoch [12/100], Step [5000/24597], Loss: 1.4491\n",
      "Epoch [12/100], Step [5100/24597], Loss: 1.7985\n",
      "Epoch [12/100], Step [5200/24597], Loss: 1.6794\n",
      "Epoch [12/100], Step [5300/24597], Loss: 1.5425\n",
      "Epoch [12/100], Step [5400/24597], Loss: 1.6352\n",
      "Epoch [12/100], Step [5500/24597], Loss: 1.4737\n",
      "Epoch [12/100], Step [5600/24597], Loss: 1.6268\n",
      "Epoch [12/100], Step [5700/24597], Loss: 1.5081\n",
      "Epoch [12/100], Step [5800/24597], Loss: 1.7912\n",
      "Epoch [12/100], Step [5900/24597], Loss: 1.6953\n",
      "Epoch [12/100], Step [6000/24597], Loss: 1.7599\n",
      "Epoch [12/100], Step [6100/24597], Loss: 1.6112\n",
      "Epoch [12/100], Step [6200/24597], Loss: 1.7966\n",
      "Epoch [12/100], Step [6300/24597], Loss: 1.3965\n",
      "Epoch [12/100], Step [6400/24597], Loss: 1.6679\n",
      "Epoch [12/100], Step [6500/24597], Loss: 1.7661\n",
      "Epoch [12/100], Step [6600/24597], Loss: 1.5454\n",
      "Epoch [12/100], Step [6700/24597], Loss: 1.6494\n",
      "Epoch [12/100], Step [6800/24597], Loss: 1.5696\n",
      "Epoch [12/100], Step [6900/24597], Loss: 1.8578\n",
      "Epoch [12/100], Step [7000/24597], Loss: 1.5632\n",
      "Epoch [12/100], Step [7100/24597], Loss: 1.7535\n",
      "Epoch [12/100], Step [7200/24597], Loss: 1.5367\n",
      "Epoch [12/100], Step [7300/24597], Loss: 1.5984\n",
      "Epoch [12/100], Step [7400/24597], Loss: 1.6503\n",
      "Epoch [12/100], Step [7500/24597], Loss: 1.6883\n",
      "Epoch [12/100], Step [7600/24597], Loss: 1.8154\n",
      "Epoch [12/100], Step [7700/24597], Loss: 1.7006\n",
      "Epoch [12/100], Step [7800/24597], Loss: 1.6017\n",
      "Epoch [12/100], Step [7900/24597], Loss: 1.5849\n",
      "Epoch [12/100], Step [8000/24597], Loss: 1.5076\n",
      "Epoch [12/100], Step [8100/24597], Loss: 1.5035\n",
      "Epoch [12/100], Step [8200/24597], Loss: 1.6489\n",
      "Epoch [12/100], Step [8300/24597], Loss: 1.7555\n",
      "Epoch [12/100], Step [8400/24597], Loss: 1.7945\n",
      "Epoch [12/100], Step [8500/24597], Loss: 1.6643\n",
      "Epoch [12/100], Step [8600/24597], Loss: 1.7231\n",
      "Epoch [12/100], Step [8700/24597], Loss: 1.5269\n",
      "Epoch [12/100], Step [8800/24597], Loss: 1.6892\n",
      "Epoch [12/100], Step [8900/24597], Loss: 1.6698\n",
      "Epoch [12/100], Step [9000/24597], Loss: 1.5637\n",
      "Epoch [12/100], Step [9100/24597], Loss: 1.4995\n",
      "Epoch [12/100], Step [9200/24597], Loss: 1.6801\n",
      "Epoch [12/100], Step [9300/24597], Loss: 1.5874\n",
      "Epoch [12/100], Step [9400/24597], Loss: 1.6916\n",
      "Epoch [12/100], Step [9500/24597], Loss: 1.4945\n",
      "Epoch [12/100], Step [9600/24597], Loss: 1.9511\n",
      "Epoch [12/100], Step [9700/24597], Loss: 1.6658\n",
      "Epoch [12/100], Step [9800/24597], Loss: 1.7202\n",
      "Epoch [12/100], Step [9900/24597], Loss: 1.5728\n",
      "Epoch [12/100], Step [10000/24597], Loss: 1.5736\n",
      "Epoch [12/100], Step [10100/24597], Loss: 1.7820\n",
      "Epoch [12/100], Step [10200/24597], Loss: 1.6518\n",
      "Epoch [12/100], Step [10300/24597], Loss: 1.6695\n",
      "Epoch [12/100], Step [10400/24597], Loss: 1.5838\n",
      "Epoch [12/100], Step [10500/24597], Loss: 1.5010\n",
      "Epoch [12/100], Step [10600/24597], Loss: 1.7303\n",
      "Epoch [12/100], Step [10700/24597], Loss: 1.7329\n",
      "Epoch [12/100], Step [10800/24597], Loss: 1.7988\n",
      "Epoch [12/100], Step [10900/24597], Loss: 1.4639\n",
      "Epoch [12/100], Step [11000/24597], Loss: 1.7843\n",
      "Epoch [12/100], Step [11100/24597], Loss: 1.7699\n",
      "Epoch [12/100], Step [11200/24597], Loss: 1.9242\n",
      "Epoch [12/100], Step [11300/24597], Loss: 1.5955\n",
      "Epoch [12/100], Step [11400/24597], Loss: 1.4610\n",
      "Epoch [12/100], Step [11500/24597], Loss: 1.6800\n",
      "Epoch [12/100], Step [11600/24597], Loss: 1.5682\n",
      "Epoch [12/100], Step [11700/24597], Loss: 1.4306\n",
      "Epoch [12/100], Step [11800/24597], Loss: 1.5135\n",
      "Epoch [12/100], Step [11900/24597], Loss: 1.7096\n",
      "Epoch [12/100], Step [12000/24597], Loss: 1.7152\n",
      "Epoch [12/100], Step [12100/24597], Loss: 1.6924\n",
      "Epoch [12/100], Step [12200/24597], Loss: 1.5065\n",
      "Epoch [12/100], Step [12300/24597], Loss: 1.5081\n",
      "Epoch [12/100], Step [12400/24597], Loss: 1.4778\n",
      "Epoch [12/100], Step [12500/24597], Loss: 1.5448\n",
      "Epoch [12/100], Step [12600/24597], Loss: 1.5349\n",
      "Epoch [12/100], Step [12700/24597], Loss: 1.7360\n",
      "Epoch [12/100], Step [12800/24597], Loss: 1.4695\n",
      "Epoch [12/100], Step [12900/24597], Loss: 1.7668\n",
      "Epoch [12/100], Step [13000/24597], Loss: 1.6132\n",
      "Epoch [12/100], Step [13100/24597], Loss: 1.6394\n",
      "Epoch [12/100], Step [13200/24597], Loss: 1.6828\n",
      "Epoch [12/100], Step [13300/24597], Loss: 1.5600\n",
      "Epoch [12/100], Step [13400/24597], Loss: 1.6027\n",
      "Epoch [12/100], Step [13500/24597], Loss: 1.4356\n",
      "Epoch [12/100], Step [13600/24597], Loss: 1.5040\n",
      "Epoch [12/100], Step [13700/24597], Loss: 1.6085\n",
      "Epoch [12/100], Step [13800/24597], Loss: 1.6986\n",
      "Epoch [12/100], Step [13900/24597], Loss: 1.6368\n",
      "Epoch [12/100], Step [14000/24597], Loss: 1.7935\n",
      "Epoch [12/100], Step [14100/24597], Loss: 1.5936\n",
      "Epoch [12/100], Step [14200/24597], Loss: 1.5203\n",
      "Epoch [12/100], Step [14300/24597], Loss: 1.8598\n",
      "Epoch [12/100], Step [14400/24597], Loss: 1.7029\n",
      "Epoch [12/100], Step [14500/24597], Loss: 1.7505\n",
      "Epoch [12/100], Step [14600/24597], Loss: 1.6844\n",
      "Epoch [12/100], Step [14700/24597], Loss: 1.7341\n",
      "Epoch [12/100], Step [14800/24597], Loss: 1.6147\n",
      "Epoch [12/100], Step [14900/24597], Loss: 1.6248\n",
      "Epoch [12/100], Step [15000/24597], Loss: 1.6030\n",
      "Epoch [12/100], Step [15100/24597], Loss: 1.5676\n",
      "Epoch [12/100], Step [15200/24597], Loss: 1.6879\n",
      "Epoch [12/100], Step [15300/24597], Loss: 1.5661\n",
      "Epoch [12/100], Step [15400/24597], Loss: 1.6698\n",
      "Epoch [12/100], Step [15500/24597], Loss: 1.5690\n",
      "Epoch [12/100], Step [15600/24597], Loss: 1.6522\n",
      "Epoch [12/100], Step [15700/24597], Loss: 1.7155\n",
      "Epoch [12/100], Step [15800/24597], Loss: 1.6148\n",
      "Epoch [12/100], Step [15900/24597], Loss: 1.4526\n",
      "Epoch [12/100], Step [16000/24597], Loss: 1.5077\n",
      "Epoch [12/100], Step [16100/24597], Loss: 1.7360\n",
      "Epoch [12/100], Step [16200/24597], Loss: 1.8082\n",
      "Epoch [12/100], Step [16300/24597], Loss: 1.7168\n",
      "Epoch [12/100], Step [16400/24597], Loss: 1.5823\n",
      "Epoch [12/100], Step [16500/24597], Loss: 1.3363\n",
      "Epoch [12/100], Step [16600/24597], Loss: 1.5976\n",
      "Epoch [12/100], Step [16700/24597], Loss: 1.6843\n",
      "Epoch [12/100], Step [16800/24597], Loss: 1.5186\n",
      "Epoch [12/100], Step [16900/24597], Loss: 1.6506\n",
      "Epoch [12/100], Step [17000/24597], Loss: 1.6289\n",
      "Epoch [12/100], Step [17100/24597], Loss: 1.5162\n",
      "Epoch [12/100], Step [17200/24597], Loss: 1.6589\n",
      "Epoch [12/100], Step [17300/24597], Loss: 1.7372\n",
      "Epoch [12/100], Step [17400/24597], Loss: 1.8420\n",
      "Epoch [12/100], Step [17500/24597], Loss: 1.7561\n",
      "Epoch [12/100], Step [17600/24597], Loss: 1.6374\n",
      "Epoch [12/100], Step [17700/24597], Loss: 1.7242\n",
      "Epoch [12/100], Step [17800/24597], Loss: 1.7710\n",
      "Epoch [12/100], Step [17900/24597], Loss: 1.5759\n",
      "Epoch [12/100], Step [18000/24597], Loss: 1.6890\n",
      "Epoch [12/100], Step [18100/24597], Loss: 1.5261\n",
      "Epoch [12/100], Step [18200/24597], Loss: 1.7150\n",
      "Epoch [12/100], Step [18300/24597], Loss: 1.7396\n",
      "Epoch [12/100], Step [18400/24597], Loss: 1.6725\n",
      "Epoch [12/100], Step [18500/24597], Loss: 1.5736\n",
      "Epoch [12/100], Step [18600/24597], Loss: 1.5323\n",
      "Epoch [12/100], Step [18700/24597], Loss: 1.5440\n",
      "Epoch [12/100], Step [18800/24597], Loss: 1.5957\n",
      "Epoch [12/100], Step [18900/24597], Loss: 1.6844\n",
      "Epoch [12/100], Step [19000/24597], Loss: 1.3797\n",
      "Epoch [12/100], Step [19100/24597], Loss: 1.6051\n",
      "Epoch [12/100], Step [19200/24597], Loss: 1.5488\n",
      "Epoch [12/100], Step [19300/24597], Loss: 1.6286\n",
      "Epoch [12/100], Step [19400/24597], Loss: 1.6610\n",
      "Epoch [12/100], Step [19500/24597], Loss: 1.7706\n",
      "Epoch [12/100], Step [19600/24597], Loss: 1.6661\n",
      "Epoch [12/100], Step [19700/24597], Loss: 1.6147\n",
      "Epoch [12/100], Step [19800/24597], Loss: 1.4599\n",
      "Epoch [12/100], Step [19900/24597], Loss: 1.5333\n",
      "Epoch [12/100], Step [20000/24597], Loss: 1.6278\n",
      "Epoch [12/100], Step [20100/24597], Loss: 1.5744\n",
      "Epoch [12/100], Step [20200/24597], Loss: 1.6113\n",
      "Epoch [12/100], Step [20300/24597], Loss: 1.5893\n",
      "Epoch [12/100], Step [20400/24597], Loss: 1.7407\n",
      "Epoch [12/100], Step [20500/24597], Loss: 1.7024\n",
      "Epoch [12/100], Step [20600/24597], Loss: 1.4617\n",
      "Epoch [12/100], Step [20700/24597], Loss: 1.4373\n",
      "Epoch [12/100], Step [20800/24597], Loss: 1.8426\n",
      "Epoch [12/100], Step [20900/24597], Loss: 1.7207\n",
      "Epoch [12/100], Step [21000/24597], Loss: 1.4495\n",
      "Epoch [12/100], Step [21100/24597], Loss: 1.6458\n",
      "Epoch [12/100], Step [21200/24597], Loss: 1.7160\n",
      "Epoch [12/100], Step [21300/24597], Loss: 1.6031\n",
      "Epoch [12/100], Step [21400/24597], Loss: 1.5658\n",
      "Epoch [12/100], Step [21500/24597], Loss: 1.5597\n",
      "Epoch [12/100], Step [21600/24597], Loss: 1.5941\n",
      "Epoch [12/100], Step [21700/24597], Loss: 1.6520\n",
      "Epoch [12/100], Step [21800/24597], Loss: 1.5613\n",
      "Epoch [12/100], Step [21900/24597], Loss: 1.4656\n",
      "Epoch [12/100], Step [22000/24597], Loss: 1.4926\n",
      "Epoch [12/100], Step [22100/24597], Loss: 1.6978\n",
      "Epoch [12/100], Step [22200/24597], Loss: 1.6217\n",
      "Epoch [12/100], Step [22300/24597], Loss: 1.5966\n",
      "Epoch [12/100], Step [22400/24597], Loss: 1.4401\n",
      "Epoch [12/100], Step [22500/24597], Loss: 1.4410\n",
      "Epoch [12/100], Step [22600/24597], Loss: 1.6713\n",
      "Epoch [12/100], Step [22700/24597], Loss: 1.8169\n",
      "Epoch [12/100], Step [22800/24597], Loss: 1.5610\n",
      "Epoch [12/100], Step [22900/24597], Loss: 1.7947\n",
      "Epoch [12/100], Step [23000/24597], Loss: 1.7721\n",
      "Epoch [12/100], Step [23100/24597], Loss: 1.7251\n",
      "Epoch [12/100], Step [23200/24597], Loss: 1.6827\n",
      "Epoch [12/100], Step [23300/24597], Loss: 1.7215\n",
      "Epoch [12/100], Step [23400/24597], Loss: 1.7017\n",
      "Epoch [12/100], Step [23500/24597], Loss: 1.6118\n",
      "Epoch [12/100], Step [23600/24597], Loss: 1.6030\n",
      "Epoch [12/100], Step [23700/24597], Loss: 1.5414\n",
      "Epoch [12/100], Step [23800/24597], Loss: 1.6182\n",
      "Epoch [12/100], Step [23900/24597], Loss: 1.6352\n",
      "Epoch [12/100], Step [24000/24597], Loss: 1.9032\n",
      "Epoch [12/100], Step [24100/24597], Loss: 1.4704\n",
      "Epoch [12/100], Step [24200/24597], Loss: 1.5436\n",
      "Epoch [12/100], Step [24300/24597], Loss: 1.6570\n",
      "Epoch [12/100], Step [24400/24597], Loss: 1.8736\n",
      "Epoch [12/100], Step [24500/24597], Loss: 1.6943\n",
      "Epoch [13/100], Step [100/24597], Loss: 1.5955\n",
      "Epoch [13/100], Step [200/24597], Loss: 1.7498\n",
      "Epoch [13/100], Step [300/24597], Loss: 1.7280\n",
      "Epoch [13/100], Step [400/24597], Loss: 1.5922\n",
      "Epoch [13/100], Step [500/24597], Loss: 1.7099\n",
      "Epoch [13/100], Step [600/24597], Loss: 1.6122\n",
      "Epoch [13/100], Step [700/24597], Loss: 1.6629\n",
      "Epoch [13/100], Step [800/24597], Loss: 1.6607\n",
      "Epoch [13/100], Step [900/24597], Loss: 1.7870\n",
      "Epoch [13/100], Step [1000/24597], Loss: 1.7145\n",
      "Epoch [13/100], Step [1100/24597], Loss: 1.6298\n",
      "Epoch [13/100], Step [1200/24597], Loss: 1.5316\n",
      "Epoch [13/100], Step [1300/24597], Loss: 1.5155\n",
      "Epoch [13/100], Step [1400/24597], Loss: 1.3053\n",
      "Epoch [13/100], Step [1500/24597], Loss: 1.5611\n",
      "Epoch [13/100], Step [1600/24597], Loss: 1.5601\n",
      "Epoch [13/100], Step [1700/24597], Loss: 1.5214\n",
      "Epoch [13/100], Step [1800/24597], Loss: 1.5254\n",
      "Epoch [13/100], Step [1900/24597], Loss: 1.7735\n",
      "Epoch [13/100], Step [2000/24597], Loss: 1.8086\n",
      "Epoch [13/100], Step [2100/24597], Loss: 1.7883\n",
      "Epoch [13/100], Step [2200/24597], Loss: 1.6019\n",
      "Epoch [13/100], Step [2300/24597], Loss: 1.5428\n",
      "Epoch [13/100], Step [2400/24597], Loss: 1.7077\n",
      "Epoch [13/100], Step [2500/24597], Loss: 1.6515\n",
      "Epoch [13/100], Step [2600/24597], Loss: 1.6974\n",
      "Epoch [13/100], Step [2700/24597], Loss: 1.6474\n",
      "Epoch [13/100], Step [2800/24597], Loss: 1.6119\n",
      "Epoch [13/100], Step [2900/24597], Loss: 1.5493\n",
      "Epoch [13/100], Step [3000/24597], Loss: 1.3764\n",
      "Epoch [13/100], Step [3100/24597], Loss: 1.6371\n",
      "Epoch [13/100], Step [3200/24597], Loss: 1.6858\n",
      "Epoch [13/100], Step [3300/24597], Loss: 1.8004\n",
      "Epoch [13/100], Step [3400/24597], Loss: 1.6505\n",
      "Epoch [13/100], Step [3500/24597], Loss: 1.6071\n",
      "Epoch [13/100], Step [3600/24597], Loss: 1.4597\n",
      "Epoch [13/100], Step [3700/24597], Loss: 1.6423\n",
      "Epoch [13/100], Step [3800/24597], Loss: 1.5063\n",
      "Epoch [13/100], Step [3900/24597], Loss: 1.6739\n",
      "Epoch [13/100], Step [4000/24597], Loss: 1.5497\n",
      "Epoch [13/100], Step [4100/24597], Loss: 1.5386\n",
      "Epoch [13/100], Step [4200/24597], Loss: 1.7083\n",
      "Epoch [13/100], Step [4300/24597], Loss: 1.3731\n",
      "Epoch [13/100], Step [4400/24597], Loss: 1.6624\n",
      "Epoch [13/100], Step [4500/24597], Loss: 1.7388\n",
      "Epoch [13/100], Step [4600/24597], Loss: 1.5492\n",
      "Epoch [13/100], Step [4700/24597], Loss: 1.6462\n",
      "Epoch [13/100], Step [4800/24597], Loss: 1.5293\n",
      "Epoch [13/100], Step [4900/24597], Loss: 1.6420\n",
      "Epoch [13/100], Step [5000/24597], Loss: 1.8454\n",
      "Epoch [13/100], Step [5100/24597], Loss: 1.4318\n",
      "Epoch [13/100], Step [5200/24597], Loss: 1.6202\n",
      "Epoch [13/100], Step [5300/24597], Loss: 1.6426\n",
      "Epoch [13/100], Step [5400/24597], Loss: 1.5886\n",
      "Epoch [13/100], Step [5500/24597], Loss: 1.4686\n",
      "Epoch [13/100], Step [5600/24597], Loss: 1.8181\n",
      "Epoch [13/100], Step [5700/24597], Loss: 1.6140\n",
      "Epoch [13/100], Step [5800/24597], Loss: 1.6064\n",
      "Epoch [13/100], Step [5900/24597], Loss: 1.6529\n",
      "Epoch [13/100], Step [6000/24597], Loss: 1.5220\n",
      "Epoch [13/100], Step [6100/24597], Loss: 1.7402\n",
      "Epoch [13/100], Step [6200/24597], Loss: 1.7470\n",
      "Epoch [13/100], Step [6300/24597], Loss: 1.5357\n",
      "Epoch [13/100], Step [6400/24597], Loss: 1.6594\n",
      "Epoch [13/100], Step [6500/24597], Loss: 1.8535\n",
      "Epoch [13/100], Step [6600/24597], Loss: 1.4909\n",
      "Epoch [13/100], Step [6700/24597], Loss: 1.7323\n",
      "Epoch [13/100], Step [6800/24597], Loss: 1.5461\n",
      "Epoch [13/100], Step [6900/24597], Loss: 1.8101\n",
      "Epoch [13/100], Step [7000/24597], Loss: 1.4987\n",
      "Epoch [13/100], Step [7100/24597], Loss: 1.7467\n",
      "Epoch [13/100], Step [7200/24597], Loss: 1.7089\n",
      "Epoch [13/100], Step [7300/24597], Loss: 1.5089\n",
      "Epoch [13/100], Step [7400/24597], Loss: 1.4347\n",
      "Epoch [13/100], Step [7500/24597], Loss: 1.7247\n",
      "Epoch [13/100], Step [7600/24597], Loss: 1.7336\n",
      "Epoch [13/100], Step [7700/24597], Loss: 1.8627\n",
      "Epoch [13/100], Step [7800/24597], Loss: 1.4037\n",
      "Epoch [13/100], Step [7900/24597], Loss: 1.5203\n",
      "Epoch [13/100], Step [8000/24597], Loss: 1.5842\n",
      "Epoch [13/100], Step [8100/24597], Loss: 1.4547\n",
      "Epoch [13/100], Step [8200/24597], Loss: 1.6427\n",
      "Epoch [13/100], Step [8300/24597], Loss: 1.7354\n",
      "Epoch [13/100], Step [8400/24597], Loss: 1.4828\n",
      "Epoch [13/100], Step [8500/24597], Loss: 1.6823\n",
      "Epoch [13/100], Step [8600/24597], Loss: 1.5206\n",
      "Epoch [13/100], Step [8700/24597], Loss: 1.6787\n",
      "Epoch [13/100], Step [8800/24597], Loss: 1.6482\n",
      "Epoch [13/100], Step [8900/24597], Loss: 1.7748\n",
      "Epoch [13/100], Step [9000/24597], Loss: 1.6210\n",
      "Epoch [13/100], Step [9100/24597], Loss: 1.4342\n",
      "Epoch [13/100], Step [9200/24597], Loss: 1.6717\n",
      "Epoch [13/100], Step [9300/24597], Loss: 1.5262\n",
      "Epoch [13/100], Step [9400/24597], Loss: 1.7659\n",
      "Epoch [13/100], Step [9500/24597], Loss: 1.7034\n",
      "Epoch [13/100], Step [9600/24597], Loss: 1.7395\n",
      "Epoch [13/100], Step [9700/24597], Loss: 1.7243\n",
      "Epoch [13/100], Step [9800/24597], Loss: 1.6192\n",
      "Epoch [13/100], Step [9900/24597], Loss: 1.4870\n",
      "Epoch [13/100], Step [10000/24597], Loss: 1.8680\n",
      "Epoch [13/100], Step [10100/24597], Loss: 1.7480\n",
      "Epoch [13/100], Step [10200/24597], Loss: 1.6120\n",
      "Epoch [13/100], Step [10300/24597], Loss: 1.6586\n",
      "Epoch [13/100], Step [10400/24597], Loss: 1.6289\n",
      "Epoch [13/100], Step [10500/24597], Loss: 1.5919\n",
      "Epoch [13/100], Step [10600/24597], Loss: 1.5442\n",
      "Epoch [13/100], Step [10700/24597], Loss: 1.5961\n",
      "Epoch [13/100], Step [10800/24597], Loss: 1.5135\n",
      "Epoch [13/100], Step [10900/24597], Loss: 1.6453\n",
      "Epoch [13/100], Step [11000/24597], Loss: 1.5382\n",
      "Epoch [13/100], Step [11100/24597], Loss: 1.7403\n",
      "Epoch [13/100], Step [11200/24597], Loss: 1.6050\n",
      "Epoch [13/100], Step [11300/24597], Loss: 1.7650\n",
      "Epoch [13/100], Step [11400/24597], Loss: 1.7083\n",
      "Epoch [13/100], Step [11500/24597], Loss: 1.6096\n",
      "Epoch [13/100], Step [11600/24597], Loss: 1.8342\n",
      "Epoch [13/100], Step [11700/24597], Loss: 1.6481\n",
      "Epoch [13/100], Step [11800/24597], Loss: 1.5834\n",
      "Epoch [13/100], Step [11900/24597], Loss: 1.5232\n",
      "Epoch [13/100], Step [12000/24597], Loss: 1.4862\n",
      "Epoch [13/100], Step [12100/24597], Loss: 1.5983\n",
      "Epoch [13/100], Step [12200/24597], Loss: 1.7062\n",
      "Epoch [13/100], Step [12300/24597], Loss: 1.5184\n",
      "Epoch [13/100], Step [12400/24597], Loss: 1.4514\n",
      "Epoch [13/100], Step [12500/24597], Loss: 1.8744\n",
      "Epoch [13/100], Step [12600/24597], Loss: 1.5241\n",
      "Epoch [13/100], Step [12700/24597], Loss: 1.7058\n",
      "Epoch [13/100], Step [12800/24597], Loss: 1.5317\n",
      "Epoch [13/100], Step [12900/24597], Loss: 2.0410\n",
      "Epoch [13/100], Step [13000/24597], Loss: 1.6987\n",
      "Epoch [13/100], Step [13100/24597], Loss: 1.8109\n",
      "Epoch [13/100], Step [13200/24597], Loss: 1.8054\n",
      "Epoch [13/100], Step [13300/24597], Loss: 1.5639\n",
      "Epoch [13/100], Step [13400/24597], Loss: 1.5565\n",
      "Epoch [13/100], Step [13500/24597], Loss: 1.8443\n",
      "Epoch [13/100], Step [13600/24597], Loss: 1.4775\n",
      "Epoch [13/100], Step [13700/24597], Loss: 1.5817\n",
      "Epoch [13/100], Step [13800/24597], Loss: 1.5781\n",
      "Epoch [13/100], Step [13900/24597], Loss: 1.6434\n",
      "Epoch [13/100], Step [14000/24597], Loss: 1.7734\n",
      "Epoch [13/100], Step [14100/24597], Loss: 1.6410\n",
      "Epoch [13/100], Step [14200/24597], Loss: 1.8137\n",
      "Epoch [13/100], Step [14300/24597], Loss: 1.7163\n",
      "Epoch [13/100], Step [14400/24597], Loss: 1.5386\n",
      "Epoch [13/100], Step [14500/24597], Loss: 1.7438\n",
      "Epoch [13/100], Step [14600/24597], Loss: 1.6742\n",
      "Epoch [13/100], Step [14700/24597], Loss: 1.7958\n",
      "Epoch [13/100], Step [14800/24597], Loss: 1.6536\n",
      "Epoch [13/100], Step [14900/24597], Loss: 1.6184\n",
      "Epoch [13/100], Step [15000/24597], Loss: 1.6991\n",
      "Epoch [13/100], Step [15100/24597], Loss: 1.7080\n",
      "Epoch [13/100], Step [15200/24597], Loss: 1.3843\n",
      "Epoch [13/100], Step [15300/24597], Loss: 1.7775\n",
      "Epoch [13/100], Step [15400/24597], Loss: 1.8414\n",
      "Epoch [13/100], Step [15500/24597], Loss: 1.7837\n",
      "Epoch [13/100], Step [15600/24597], Loss: 1.5281\n",
      "Epoch [13/100], Step [15700/24597], Loss: 1.5678\n",
      "Epoch [13/100], Step [15800/24597], Loss: 1.6801\n",
      "Epoch [13/100], Step [15900/24597], Loss: 1.7098\n",
      "Epoch [13/100], Step [16000/24597], Loss: 1.7084\n",
      "Epoch [13/100], Step [16100/24597], Loss: 1.4776\n",
      "Epoch [13/100], Step [16200/24597], Loss: 1.7361\n",
      "Epoch [13/100], Step [16300/24597], Loss: 1.7027\n",
      "Epoch [13/100], Step [16400/24597], Loss: 1.5429\n",
      "Epoch [13/100], Step [16500/24597], Loss: 1.6209\n",
      "Epoch [13/100], Step [16600/24597], Loss: 1.5751\n",
      "Epoch [13/100], Step [16700/24597], Loss: 1.5435\n",
      "Epoch [13/100], Step [16800/24597], Loss: 1.6984\n",
      "Epoch [13/100], Step [16900/24597], Loss: 1.5661\n",
      "Epoch [13/100], Step [17000/24597], Loss: 1.3833\n",
      "Epoch [13/100], Step [17100/24597], Loss: 1.7270\n",
      "Epoch [13/100], Step [17200/24597], Loss: 1.5510\n",
      "Epoch [13/100], Step [17300/24597], Loss: 1.5456\n",
      "Epoch [13/100], Step [17400/24597], Loss: 1.6234\n",
      "Epoch [13/100], Step [17500/24597], Loss: 1.5133\n",
      "Epoch [13/100], Step [17600/24597], Loss: 1.8132\n",
      "Epoch [13/100], Step [17700/24597], Loss: 1.8277\n",
      "Epoch [13/100], Step [17800/24597], Loss: 1.5115\n",
      "Epoch [13/100], Step [17900/24597], Loss: 1.6000\n",
      "Epoch [13/100], Step [18000/24597], Loss: 1.7598\n",
      "Epoch [13/100], Step [18100/24597], Loss: 1.7116\n",
      "Epoch [13/100], Step [18200/24597], Loss: 1.4999\n",
      "Epoch [13/100], Step [18300/24597], Loss: 1.7236\n",
      "Epoch [13/100], Step [18400/24597], Loss: 1.6323\n",
      "Epoch [13/100], Step [18500/24597], Loss: 1.7500\n",
      "Epoch [13/100], Step [18600/24597], Loss: 1.6256\n",
      "Epoch [13/100], Step [18700/24597], Loss: 1.6137\n",
      "Epoch [13/100], Step [18800/24597], Loss: 1.4460\n",
      "Epoch [13/100], Step [18900/24597], Loss: 1.5244\n",
      "Epoch [13/100], Step [19000/24597], Loss: 1.7497\n",
      "Epoch [13/100], Step [19100/24597], Loss: 1.7262\n",
      "Epoch [13/100], Step [19200/24597], Loss: 1.4990\n",
      "Epoch [13/100], Step [19300/24597], Loss: 1.4572\n",
      "Epoch [13/100], Step [19400/24597], Loss: 1.5851\n",
      "Epoch [13/100], Step [19500/24597], Loss: 1.4293\n",
      "Epoch [13/100], Step [19600/24597], Loss: 1.6398\n",
      "Epoch [13/100], Step [19700/24597], Loss: 1.6302\n",
      "Epoch [13/100], Step [19800/24597], Loss: 1.7054\n",
      "Epoch [13/100], Step [19900/24597], Loss: 1.5419\n",
      "Epoch [13/100], Step [20000/24597], Loss: 1.8578\n",
      "Epoch [13/100], Step [20100/24597], Loss: 1.7005\n",
      "Epoch [13/100], Step [20200/24597], Loss: 1.5257\n",
      "Epoch [13/100], Step [20300/24597], Loss: 1.4995\n",
      "Epoch [13/100], Step [20400/24597], Loss: 1.5257\n",
      "Epoch [13/100], Step [20500/24597], Loss: 1.5676\n",
      "Epoch [13/100], Step [20600/24597], Loss: 1.6271\n",
      "Epoch [13/100], Step [20700/24597], Loss: 1.5883\n",
      "Epoch [13/100], Step [20800/24597], Loss: 1.7677\n",
      "Epoch [13/100], Step [20900/24597], Loss: 1.7744\n",
      "Epoch [13/100], Step [21000/24597], Loss: 1.6918\n",
      "Epoch [13/100], Step [21100/24597], Loss: 1.6081\n",
      "Epoch [13/100], Step [21200/24597], Loss: 1.4746\n",
      "Epoch [13/100], Step [21300/24597], Loss: 1.7611\n",
      "Epoch [13/100], Step [21400/24597], Loss: 1.4784\n",
      "Epoch [13/100], Step [21500/24597], Loss: 1.4833\n",
      "Epoch [13/100], Step [21600/24597], Loss: 1.5225\n",
      "Epoch [13/100], Step [21700/24597], Loss: 1.5240\n",
      "Epoch [13/100], Step [21800/24597], Loss: 1.5340\n",
      "Epoch [13/100], Step [21900/24597], Loss: 1.6984\n",
      "Epoch [13/100], Step [22000/24597], Loss: 1.5113\n",
      "Epoch [13/100], Step [22100/24597], Loss: 1.6500\n",
      "Epoch [13/100], Step [22200/24597], Loss: 1.6330\n",
      "Epoch [13/100], Step [22300/24597], Loss: 1.7086\n",
      "Epoch [13/100], Step [22400/24597], Loss: 1.3350\n",
      "Epoch [13/100], Step [22500/24597], Loss: 1.7278\n",
      "Epoch [13/100], Step [22600/24597], Loss: 1.5158\n",
      "Epoch [13/100], Step [22700/24597], Loss: 1.7687\n",
      "Epoch [13/100], Step [22800/24597], Loss: 1.5895\n",
      "Epoch [13/100], Step [22900/24597], Loss: 1.5196\n",
      "Epoch [13/100], Step [23000/24597], Loss: 1.7220\n",
      "Epoch [13/100], Step [23100/24597], Loss: 1.6855\n",
      "Epoch [13/100], Step [23200/24597], Loss: 1.4862\n",
      "Epoch [13/100], Step [23300/24597], Loss: 1.4940\n",
      "Epoch [13/100], Step [23400/24597], Loss: 1.5074\n",
      "Epoch [13/100], Step [23500/24597], Loss: 1.6674\n",
      "Epoch [13/100], Step [23600/24597], Loss: 1.5004\n",
      "Epoch [13/100], Step [23700/24597], Loss: 1.8206\n",
      "Epoch [13/100], Step [23800/24597], Loss: 1.7618\n",
      "Epoch [13/100], Step [23900/24597], Loss: 1.5711\n",
      "Epoch [13/100], Step [24000/24597], Loss: 1.6708\n",
      "Epoch [13/100], Step [24100/24597], Loss: 1.6998\n",
      "Epoch [13/100], Step [24200/24597], Loss: 1.6265\n",
      "Epoch [13/100], Step [24300/24597], Loss: 1.5222\n",
      "Epoch [13/100], Step [24400/24597], Loss: 1.6276\n",
      "Epoch [13/100], Step [24500/24597], Loss: 1.6544\n",
      "Epoch [14/100], Step [100/24597], Loss: 1.3139\n",
      "Epoch [14/100], Step [200/24597], Loss: 1.6420\n",
      "Epoch [14/100], Step [300/24597], Loss: 1.7620\n",
      "Epoch [14/100], Step [400/24597], Loss: 1.6388\n",
      "Epoch [14/100], Step [500/24597], Loss: 1.6975\n",
      "Epoch [14/100], Step [600/24597], Loss: 1.5756\n",
      "Epoch [14/100], Step [700/24597], Loss: 1.6071\n",
      "Epoch [14/100], Step [800/24597], Loss: 1.4488\n",
      "Epoch [14/100], Step [900/24597], Loss: 1.7088\n",
      "Epoch [14/100], Step [1000/24597], Loss: 1.5745\n",
      "Epoch [14/100], Step [1100/24597], Loss: 1.6055\n",
      "Epoch [14/100], Step [1200/24597], Loss: 1.5362\n",
      "Epoch [14/100], Step [1300/24597], Loss: 1.6119\n",
      "Epoch [14/100], Step [1400/24597], Loss: 1.6418\n",
      "Epoch [14/100], Step [1500/24597], Loss: 1.6703\n",
      "Epoch [14/100], Step [1600/24597], Loss: 1.4308\n",
      "Epoch [14/100], Step [1700/24597], Loss: 1.6296\n",
      "Epoch [14/100], Step [1800/24597], Loss: 1.6414\n",
      "Epoch [14/100], Step [1900/24597], Loss: 1.6868\n",
      "Epoch [14/100], Step [2000/24597], Loss: 1.5250\n",
      "Epoch [14/100], Step [2100/24597], Loss: 1.4700\n",
      "Epoch [14/100], Step [2200/24597], Loss: 1.5889\n",
      "Epoch [14/100], Step [2300/24597], Loss: 1.6274\n",
      "Epoch [14/100], Step [2400/24597], Loss: 1.8140\n",
      "Epoch [14/100], Step [2500/24597], Loss: 1.6680\n",
      "Epoch [14/100], Step [2600/24597], Loss: 1.6330\n",
      "Epoch [14/100], Step [2700/24597], Loss: 1.7567\n",
      "Epoch [14/100], Step [2800/24597], Loss: 1.5894\n",
      "Epoch [14/100], Step [2900/24597], Loss: 1.4611\n",
      "Epoch [14/100], Step [3000/24597], Loss: 1.5446\n",
      "Epoch [14/100], Step [3100/24597], Loss: 1.6329\n",
      "Epoch [14/100], Step [3200/24597], Loss: 1.5182\n",
      "Epoch [14/100], Step [3300/24597], Loss: 1.4585\n",
      "Epoch [14/100], Step [3400/24597], Loss: 1.2664\n",
      "Epoch [14/100], Step [3500/24597], Loss: 1.5934\n",
      "Epoch [14/100], Step [3600/24597], Loss: 1.5405\n",
      "Epoch [14/100], Step [3700/24597], Loss: 1.5703\n",
      "Epoch [14/100], Step [3800/24597], Loss: 1.4627\n",
      "Epoch [14/100], Step [3900/24597], Loss: 1.6790\n",
      "Epoch [14/100], Step [4000/24597], Loss: 1.6811\n",
      "Epoch [14/100], Step [4100/24597], Loss: 1.5773\n",
      "Epoch [14/100], Step [4200/24597], Loss: 1.6167\n",
      "Epoch [14/100], Step [4300/24597], Loss: 1.6640\n",
      "Epoch [14/100], Step [4400/24597], Loss: 1.6898\n",
      "Epoch [14/100], Step [4500/24597], Loss: 1.6520\n",
      "Epoch [14/100], Step [4600/24597], Loss: 1.7114\n",
      "Epoch [14/100], Step [4700/24597], Loss: 1.6762\n",
      "Epoch [14/100], Step [4800/24597], Loss: 1.6919\n",
      "Epoch [14/100], Step [4900/24597], Loss: 1.5647\n",
      "Epoch [14/100], Step [5000/24597], Loss: 1.6043\n",
      "Epoch [14/100], Step [5100/24597], Loss: 1.7934\n",
      "Epoch [14/100], Step [5200/24597], Loss: 1.5437\n",
      "Epoch [14/100], Step [5300/24597], Loss: 1.5962\n",
      "Epoch [14/100], Step [5400/24597], Loss: 1.6262\n",
      "Epoch [14/100], Step [5500/24597], Loss: 1.6122\n",
      "Epoch [14/100], Step [5600/24597], Loss: 1.5933\n",
      "Epoch [14/100], Step [5700/24597], Loss: 1.5504\n",
      "Epoch [14/100], Step [5800/24597], Loss: 1.8112\n",
      "Epoch [14/100], Step [5900/24597], Loss: 1.5456\n",
      "Epoch [14/100], Step [6000/24597], Loss: 1.9189\n",
      "Epoch [14/100], Step [6100/24597], Loss: 1.5484\n",
      "Epoch [14/100], Step [6200/24597], Loss: 1.6121\n",
      "Epoch [14/100], Step [6300/24597], Loss: 1.6543\n",
      "Epoch [14/100], Step [6400/24597], Loss: 1.5358\n",
      "Epoch [14/100], Step [6500/24597], Loss: 1.3805\n",
      "Epoch [14/100], Step [6600/24597], Loss: 1.7118\n",
      "Epoch [14/100], Step [6700/24597], Loss: 1.5679\n",
      "Epoch [14/100], Step [6800/24597], Loss: 1.6765\n",
      "Epoch [14/100], Step [6900/24597], Loss: 1.8635\n",
      "Epoch [14/100], Step [7000/24597], Loss: 1.9250\n",
      "Epoch [14/100], Step [7100/24597], Loss: 1.7689\n",
      "Epoch [14/100], Step [7200/24597], Loss: 1.7193\n",
      "Epoch [14/100], Step [7300/24597], Loss: 1.5580\n",
      "Epoch [14/100], Step [7400/24597], Loss: 1.3134\n",
      "Epoch [14/100], Step [7500/24597], Loss: 1.3565\n",
      "Epoch [14/100], Step [7600/24597], Loss: 1.7263\n",
      "Epoch [14/100], Step [7700/24597], Loss: 1.6655\n",
      "Epoch [14/100], Step [7800/24597], Loss: 1.6820\n",
      "Epoch [14/100], Step [7900/24597], Loss: 1.6433\n",
      "Epoch [14/100], Step [8000/24597], Loss: 1.5289\n",
      "Epoch [14/100], Step [8100/24597], Loss: 1.5544\n",
      "Epoch [14/100], Step [8200/24597], Loss: 1.6043\n",
      "Epoch [14/100], Step [8300/24597], Loss: 1.5856\n",
      "Epoch [14/100], Step [8400/24597], Loss: 1.5680\n",
      "Epoch [14/100], Step [8500/24597], Loss: 1.4302\n",
      "Epoch [14/100], Step [8600/24597], Loss: 1.4936\n",
      "Epoch [14/100], Step [8700/24597], Loss: 1.5126\n",
      "Epoch [14/100], Step [8800/24597], Loss: 1.6465\n",
      "Epoch [14/100], Step [8900/24597], Loss: 1.4965\n",
      "Epoch [14/100], Step [9000/24597], Loss: 1.4112\n",
      "Epoch [14/100], Step [9100/24597], Loss: 1.6564\n",
      "Epoch [14/100], Step [9200/24597], Loss: 1.8452\n",
      "Epoch [14/100], Step [9300/24597], Loss: 1.5009\n",
      "Epoch [14/100], Step [9400/24597], Loss: 1.3514\n",
      "Epoch [14/100], Step [9500/24597], Loss: 1.6721\n",
      "Epoch [14/100], Step [9600/24597], Loss: 1.4742\n",
      "Epoch [14/100], Step [9700/24597], Loss: 1.4136\n",
      "Epoch [14/100], Step [9800/24597], Loss: 1.6171\n",
      "Epoch [14/100], Step [9900/24597], Loss: 1.5168\n",
      "Epoch [14/100], Step [10000/24597], Loss: 1.6873\n",
      "Epoch [14/100], Step [10100/24597], Loss: 1.7156\n",
      "Epoch [14/100], Step [10200/24597], Loss: 1.7774\n",
      "Epoch [14/100], Step [10300/24597], Loss: 1.6010\n",
      "Epoch [14/100], Step [10400/24597], Loss: 1.5073\n",
      "Epoch [14/100], Step [10500/24597], Loss: 1.7986\n",
      "Epoch [14/100], Step [10600/24597], Loss: 1.6452\n",
      "Epoch [14/100], Step [10700/24597], Loss: 1.5919\n",
      "Epoch [14/100], Step [10800/24597], Loss: 1.6155\n",
      "Epoch [14/100], Step [10900/24597], Loss: 1.4933\n",
      "Epoch [14/100], Step [11000/24597], Loss: 1.5874\n",
      "Epoch [14/100], Step [11100/24597], Loss: 1.6339\n",
      "Epoch [14/100], Step [11200/24597], Loss: 1.4209\n",
      "Epoch [14/100], Step [11300/24597], Loss: 1.7410\n",
      "Epoch [14/100], Step [11400/24597], Loss: 1.4964\n",
      "Epoch [14/100], Step [11500/24597], Loss: 1.4247\n",
      "Epoch [14/100], Step [11600/24597], Loss: 1.4252\n",
      "Epoch [14/100], Step [11700/24597], Loss: 1.5286\n",
      "Epoch [14/100], Step [11800/24597], Loss: 1.6632\n",
      "Epoch [14/100], Step [11900/24597], Loss: 1.5944\n",
      "Epoch [14/100], Step [12000/24597], Loss: 1.6712\n",
      "Epoch [14/100], Step [12100/24597], Loss: 1.6425\n",
      "Epoch [14/100], Step [12200/24597], Loss: 1.4611\n",
      "Epoch [14/100], Step [12300/24597], Loss: 1.3462\n",
      "Epoch [14/100], Step [12400/24597], Loss: 1.4853\n",
      "Epoch [14/100], Step [12500/24597], Loss: 1.6646\n",
      "Epoch [14/100], Step [12600/24597], Loss: 1.6029\n",
      "Epoch [14/100], Step [12700/24597], Loss: 1.6287\n",
      "Epoch [14/100], Step [12800/24597], Loss: 1.7359\n",
      "Epoch [14/100], Step [12900/24597], Loss: 1.5336\n",
      "Epoch [14/100], Step [13000/24597], Loss: 1.4899\n",
      "Epoch [14/100], Step [13100/24597], Loss: 1.6985\n",
      "Epoch [14/100], Step [13200/24597], Loss: 1.4730\n",
      "Epoch [14/100], Step [13300/24597], Loss: 1.5588\n",
      "Epoch [14/100], Step [13400/24597], Loss: 1.5602\n",
      "Epoch [14/100], Step [13500/24597], Loss: 1.7139\n",
      "Epoch [14/100], Step [13600/24597], Loss: 1.4183\n",
      "Epoch [14/100], Step [13700/24597], Loss: 1.5172\n",
      "Epoch [14/100], Step [13800/24597], Loss: 1.7059\n",
      "Epoch [14/100], Step [13900/24597], Loss: 1.5337\n",
      "Epoch [14/100], Step [14000/24597], Loss: 1.5087\n",
      "Epoch [14/100], Step [14100/24597], Loss: 1.6427\n",
      "Epoch [14/100], Step [14200/24597], Loss: 1.6647\n",
      "Epoch [14/100], Step [14300/24597], Loss: 1.7450\n",
      "Epoch [14/100], Step [14400/24597], Loss: 1.4292\n",
      "Epoch [14/100], Step [14500/24597], Loss: 1.7117\n",
      "Epoch [14/100], Step [14600/24597], Loss: 1.5680\n",
      "Epoch [14/100], Step [14700/24597], Loss: 1.4603\n",
      "Epoch [14/100], Step [14800/24597], Loss: 1.7068\n",
      "Epoch [14/100], Step [14900/24597], Loss: 1.6185\n",
      "Epoch [14/100], Step [15000/24597], Loss: 1.6792\n",
      "Epoch [14/100], Step [15100/24597], Loss: 1.6068\n",
      "Epoch [14/100], Step [15200/24597], Loss: 1.6922\n",
      "Epoch [14/100], Step [15300/24597], Loss: 1.4338\n",
      "Epoch [14/100], Step [15400/24597], Loss: 1.7223\n",
      "Epoch [14/100], Step [15500/24597], Loss: 1.6706\n",
      "Epoch [14/100], Step [15600/24597], Loss: 1.6841\n",
      "Epoch [14/100], Step [15700/24597], Loss: 1.7145\n",
      "Epoch [14/100], Step [15800/24597], Loss: 1.4637\n",
      "Epoch [14/100], Step [15900/24597], Loss: 1.5254\n",
      "Epoch [14/100], Step [16000/24597], Loss: 1.4754\n",
      "Epoch [14/100], Step [16100/24597], Loss: 1.6122\n",
      "Epoch [14/100], Step [16200/24597], Loss: 1.6729\n",
      "Epoch [14/100], Step [16300/24597], Loss: 1.4373\n",
      "Epoch [14/100], Step [16400/24597], Loss: 1.8883\n",
      "Epoch [14/100], Step [16500/24597], Loss: 1.6384\n",
      "Epoch [14/100], Step [16600/24597], Loss: 1.8753\n",
      "Epoch [14/100], Step [16700/24597], Loss: 1.7592\n",
      "Epoch [14/100], Step [16800/24597], Loss: 1.4887\n",
      "Epoch [14/100], Step [16900/24597], Loss: 1.4543\n",
      "Epoch [14/100], Step [17000/24597], Loss: 1.6817\n",
      "Epoch [14/100], Step [17100/24597], Loss: 1.6702\n",
      "Epoch [14/100], Step [17200/24597], Loss: 1.7282\n",
      "Epoch [14/100], Step [17300/24597], Loss: 1.5334\n",
      "Epoch [14/100], Step [17400/24597], Loss: 1.7901\n",
      "Epoch [14/100], Step [17500/24597], Loss: 1.6737\n",
      "Epoch [14/100], Step [17600/24597], Loss: 1.6274\n",
      "Epoch [14/100], Step [17700/24597], Loss: 1.5703\n",
      "Epoch [14/100], Step [17800/24597], Loss: 1.7438\n",
      "Epoch [14/100], Step [17900/24597], Loss: 1.8812\n",
      "Epoch [14/100], Step [18000/24597], Loss: 1.6441\n",
      "Epoch [14/100], Step [18100/24597], Loss: 1.7262\n",
      "Epoch [14/100], Step [18200/24597], Loss: 1.7306\n",
      "Epoch [14/100], Step [18300/24597], Loss: 1.7942\n",
      "Epoch [14/100], Step [18400/24597], Loss: 1.7320\n",
      "Epoch [14/100], Step [18500/24597], Loss: 1.7086\n",
      "Epoch [14/100], Step [18600/24597], Loss: 1.7619\n",
      "Epoch [14/100], Step [18700/24597], Loss: 1.4586\n",
      "Epoch [14/100], Step [18800/24597], Loss: 1.5609\n",
      "Epoch [14/100], Step [18900/24597], Loss: 1.7529\n",
      "Epoch [14/100], Step [19000/24597], Loss: 1.7190\n",
      "Epoch [14/100], Step [19100/24597], Loss: 1.4865\n",
      "Epoch [14/100], Step [19200/24597], Loss: 1.5233\n",
      "Epoch [14/100], Step [19300/24597], Loss: 1.4344\n",
      "Epoch [14/100], Step [19400/24597], Loss: 1.6052\n",
      "Epoch [14/100], Step [19500/24597], Loss: 1.5877\n",
      "Epoch [14/100], Step [19600/24597], Loss: 1.8974\n",
      "Epoch [14/100], Step [19700/24597], Loss: 1.6139\n",
      "Epoch [14/100], Step [19800/24597], Loss: 1.4839\n",
      "Epoch [14/100], Step [19900/24597], Loss: 1.4418\n",
      "Epoch [14/100], Step [20000/24597], Loss: 1.6066\n",
      "Epoch [14/100], Step [20100/24597], Loss: 1.6637\n",
      "Epoch [14/100], Step [20200/24597], Loss: 1.5878\n",
      "Epoch [14/100], Step [20300/24597], Loss: 1.5733\n",
      "Epoch [14/100], Step [20400/24597], Loss: 1.6230\n",
      "Epoch [14/100], Step [20500/24597], Loss: 1.5209\n",
      "Epoch [14/100], Step [20600/24597], Loss: 1.4587\n",
      "Epoch [14/100], Step [20700/24597], Loss: 1.7256\n",
      "Epoch [14/100], Step [20800/24597], Loss: 1.7050\n",
      "Epoch [14/100], Step [20900/24597], Loss: 1.6356\n",
      "Epoch [14/100], Step [21000/24597], Loss: 1.9721\n",
      "Epoch [14/100], Step [21100/24597], Loss: 1.4667\n",
      "Epoch [14/100], Step [21200/24597], Loss: 1.3868\n",
      "Epoch [14/100], Step [21300/24597], Loss: 1.3749\n",
      "Epoch [14/100], Step [21400/24597], Loss: 1.6320\n",
      "Epoch [14/100], Step [21500/24597], Loss: 1.7444\n",
      "Epoch [14/100], Step [21600/24597], Loss: 1.7038\n",
      "Epoch [14/100], Step [21700/24597], Loss: 1.5265\n",
      "Epoch [14/100], Step [21800/24597], Loss: 1.5922\n",
      "Epoch [14/100], Step [21900/24597], Loss: 1.7235\n",
      "Epoch [14/100], Step [22000/24597], Loss: 1.3765\n",
      "Epoch [14/100], Step [22100/24597], Loss: 1.4527\n",
      "Epoch [14/100], Step [22200/24597], Loss: 1.8015\n",
      "Epoch [14/100], Step [22300/24597], Loss: 1.4707\n",
      "Epoch [14/100], Step [22400/24597], Loss: 1.6351\n",
      "Epoch [14/100], Step [22500/24597], Loss: 1.4404\n",
      "Epoch [14/100], Step [22600/24597], Loss: 1.5437\n",
      "Epoch [14/100], Step [22700/24597], Loss: 1.4900\n",
      "Epoch [14/100], Step [22800/24597], Loss: 1.5991\n",
      "Epoch [14/100], Step [22900/24597], Loss: 1.6468\n",
      "Epoch [14/100], Step [23000/24597], Loss: 1.7714\n",
      "Epoch [14/100], Step [23100/24597], Loss: 1.6947\n",
      "Epoch [14/100], Step [23200/24597], Loss: 1.8001\n",
      "Epoch [14/100], Step [23300/24597], Loss: 1.5780\n",
      "Epoch [14/100], Step [23400/24597], Loss: 1.5900\n",
      "Epoch [14/100], Step [23500/24597], Loss: 1.5614\n",
      "Epoch [14/100], Step [23600/24597], Loss: 1.5702\n",
      "Epoch [14/100], Step [23700/24597], Loss: 1.4361\n",
      "Epoch [14/100], Step [23800/24597], Loss: 1.7847\n",
      "Epoch [14/100], Step [23900/24597], Loss: 1.8358\n",
      "Epoch [14/100], Step [24000/24597], Loss: 1.6770\n",
      "Epoch [14/100], Step [24100/24597], Loss: 1.5591\n",
      "Epoch [14/100], Step [24200/24597], Loss: 1.6143\n",
      "Epoch [14/100], Step [24300/24597], Loss: 1.4116\n",
      "Epoch [14/100], Step [24400/24597], Loss: 1.8764\n",
      "Epoch [14/100], Step [24500/24597], Loss: 1.6211\n",
      "Epoch [15/100], Step [100/24597], Loss: 1.6960\n",
      "Epoch [15/100], Step [200/24597], Loss: 1.5639\n",
      "Epoch [15/100], Step [300/24597], Loss: 1.4451\n",
      "Epoch [15/100], Step [400/24597], Loss: 1.4445\n",
      "Epoch [15/100], Step [500/24597], Loss: 1.6960\n",
      "Epoch [15/100], Step [600/24597], Loss: 1.5202\n",
      "Epoch [15/100], Step [700/24597], Loss: 1.6244\n",
      "Epoch [15/100], Step [800/24597], Loss: 1.6441\n",
      "Epoch [15/100], Step [900/24597], Loss: 1.6304\n",
      "Epoch [15/100], Step [1000/24597], Loss: 1.6883\n",
      "Epoch [15/100], Step [1100/24597], Loss: 1.5670\n",
      "Epoch [15/100], Step [1200/24597], Loss: 1.5060\n",
      "Epoch [15/100], Step [1300/24597], Loss: 1.7808\n",
      "Epoch [15/100], Step [1400/24597], Loss: 1.6708\n",
      "Epoch [15/100], Step [1500/24597], Loss: 1.6883\n",
      "Epoch [15/100], Step [1600/24597], Loss: 1.7317\n",
      "Epoch [15/100], Step [1700/24597], Loss: 1.8135\n",
      "Epoch [15/100], Step [1800/24597], Loss: 1.4143\n",
      "Epoch [15/100], Step [1900/24597], Loss: 1.6339\n",
      "Epoch [15/100], Step [2000/24597], Loss: 1.6611\n",
      "Epoch [15/100], Step [2100/24597], Loss: 1.5353\n",
      "Epoch [15/100], Step [2200/24597], Loss: 1.7035\n",
      "Epoch [15/100], Step [2300/24597], Loss: 1.5370\n",
      "Epoch [15/100], Step [2400/24597], Loss: 1.6967\n",
      "Epoch [15/100], Step [2500/24597], Loss: 1.8162\n",
      "Epoch [15/100], Step [2600/24597], Loss: 1.5367\n",
      "Epoch [15/100], Step [2700/24597], Loss: 1.6246\n",
      "Epoch [15/100], Step [2800/24597], Loss: 1.7961\n",
      "Epoch [15/100], Step [2900/24597], Loss: 1.6897\n",
      "Epoch [15/100], Step [3000/24597], Loss: 1.4306\n",
      "Epoch [15/100], Step [3100/24597], Loss: 1.6920\n",
      "Epoch [15/100], Step [3200/24597], Loss: 1.6607\n",
      "Epoch [15/100], Step [3300/24597], Loss: 1.5959\n",
      "Epoch [15/100], Step [3400/24597], Loss: 2.0192\n",
      "Epoch [15/100], Step [3500/24597], Loss: 1.5963\n",
      "Epoch [15/100], Step [3600/24597], Loss: 1.6556\n",
      "Epoch [15/100], Step [3700/24597], Loss: 1.4386\n",
      "Epoch [15/100], Step [3800/24597], Loss: 1.7226\n",
      "Epoch [15/100], Step [3900/24597], Loss: 1.5875\n",
      "Epoch [15/100], Step [4000/24597], Loss: 1.7334\n",
      "Epoch [15/100], Step [4100/24597], Loss: 1.7228\n",
      "Epoch [15/100], Step [4200/24597], Loss: 1.6409\n",
      "Epoch [15/100], Step [4300/24597], Loss: 1.2367\n",
      "Epoch [15/100], Step [4400/24597], Loss: 1.6352\n",
      "Epoch [15/100], Step [4500/24597], Loss: 1.6501\n",
      "Epoch [15/100], Step [4600/24597], Loss: 1.6859\n",
      "Epoch [15/100], Step [4700/24597], Loss: 1.5801\n",
      "Epoch [15/100], Step [4800/24597], Loss: 1.7173\n",
      "Epoch [15/100], Step [4900/24597], Loss: 1.7089\n",
      "Epoch [15/100], Step [5000/24597], Loss: 1.6430\n",
      "Epoch [15/100], Step [5100/24597], Loss: 1.3881\n",
      "Epoch [15/100], Step [5200/24597], Loss: 1.5795\n",
      "Epoch [15/100], Step [5300/24597], Loss: 1.5426\n",
      "Epoch [15/100], Step [5400/24597], Loss: 1.5656\n",
      "Epoch [15/100], Step [5500/24597], Loss: 1.7363\n",
      "Epoch [15/100], Step [5600/24597], Loss: 1.7245\n",
      "Epoch [15/100], Step [5700/24597], Loss: 1.6217\n",
      "Epoch [15/100], Step [5800/24597], Loss: 1.5810\n",
      "Epoch [15/100], Step [5900/24597], Loss: 1.8036\n",
      "Epoch [15/100], Step [6000/24597], Loss: 1.7555\n",
      "Epoch [15/100], Step [6100/24597], Loss: 1.6416\n",
      "Epoch [15/100], Step [6200/24597], Loss: 1.7236\n",
      "Epoch [15/100], Step [6300/24597], Loss: 1.6662\n",
      "Epoch [15/100], Step [6400/24597], Loss: 1.5798\n",
      "Epoch [15/100], Step [6500/24597], Loss: 1.4920\n",
      "Epoch [15/100], Step [6600/24597], Loss: 1.3216\n",
      "Epoch [15/100], Step [6700/24597], Loss: 1.6973\n",
      "Epoch [15/100], Step [6800/24597], Loss: 1.5369\n",
      "Epoch [15/100], Step [6900/24597], Loss: 1.7156\n",
      "Epoch [15/100], Step [7000/24597], Loss: 1.6154\n",
      "Epoch [15/100], Step [7100/24597], Loss: 1.5351\n",
      "Epoch [15/100], Step [7200/24597], Loss: 1.8739\n",
      "Epoch [15/100], Step [7300/24597], Loss: 1.5011\n",
      "Epoch [15/100], Step [7400/24597], Loss: 1.6927\n",
      "Epoch [15/100], Step [7500/24597], Loss: 1.6383\n",
      "Epoch [15/100], Step [7600/24597], Loss: 1.4814\n",
      "Epoch [15/100], Step [7700/24597], Loss: 1.5810\n",
      "Epoch [15/100], Step [7800/24597], Loss: 1.6774\n",
      "Epoch [15/100], Step [7900/24597], Loss: 1.7366\n",
      "Epoch [15/100], Step [8000/24597], Loss: 1.5853\n",
      "Epoch [15/100], Step [8100/24597], Loss: 1.4804\n",
      "Epoch [15/100], Step [8200/24597], Loss: 1.6361\n",
      "Epoch [15/100], Step [8300/24597], Loss: 1.6762\n",
      "Epoch [15/100], Step [8400/24597], Loss: 1.7975\n",
      "Epoch [15/100], Step [8500/24597], Loss: 1.8376\n",
      "Epoch [15/100], Step [8600/24597], Loss: 1.5837\n",
      "Epoch [15/100], Step [8700/24597], Loss: 1.6008\n",
      "Epoch [15/100], Step [8800/24597], Loss: 1.5998\n",
      "Epoch [15/100], Step [8900/24597], Loss: 1.6036\n",
      "Epoch [15/100], Step [9000/24597], Loss: 1.6032\n",
      "Epoch [15/100], Step [9100/24597], Loss: 1.6642\n",
      "Epoch [15/100], Step [9200/24597], Loss: 1.7021\n",
      "Epoch [15/100], Step [9300/24597], Loss: 1.4675\n",
      "Epoch [15/100], Step [9400/24597], Loss: 1.7520\n",
      "Epoch [15/100], Step [9500/24597], Loss: 1.5838\n",
      "Epoch [15/100], Step [9600/24597], Loss: 1.7300\n",
      "Epoch [15/100], Step [9700/24597], Loss: 1.3695\n",
      "Epoch [15/100], Step [9800/24597], Loss: 1.6564\n",
      "Epoch [15/100], Step [9900/24597], Loss: 1.5953\n",
      "Epoch [15/100], Step [10000/24597], Loss: 1.5544\n",
      "Epoch [15/100], Step [10100/24597], Loss: 1.5817\n",
      "Epoch [15/100], Step [10200/24597], Loss: 1.4855\n",
      "Epoch [15/100], Step [10300/24597], Loss: 1.4543\n",
      "Epoch [15/100], Step [10400/24597], Loss: 1.4838\n",
      "Epoch [15/100], Step [10500/24597], Loss: 1.6608\n",
      "Epoch [15/100], Step [10600/24597], Loss: 1.6296\n",
      "Epoch [15/100], Step [10700/24597], Loss: 1.8399\n",
      "Epoch [15/100], Step [10800/24597], Loss: 1.9260\n",
      "Epoch [15/100], Step [10900/24597], Loss: 1.7616\n",
      "Epoch [15/100], Step [11000/24597], Loss: 1.6126\n",
      "Epoch [15/100], Step [11100/24597], Loss: 1.7016\n",
      "Epoch [15/100], Step [11200/24597], Loss: 1.7646\n",
      "Epoch [15/100], Step [11300/24597], Loss: 1.5013\n",
      "Epoch [15/100], Step [11400/24597], Loss: 1.5827\n",
      "Epoch [15/100], Step [11500/24597], Loss: 1.6792\n",
      "Epoch [15/100], Step [11600/24597], Loss: 1.6021\n",
      "Epoch [15/100], Step [11700/24597], Loss: 1.5255\n",
      "Epoch [15/100], Step [11800/24597], Loss: 1.8137\n",
      "Epoch [15/100], Step [11900/24597], Loss: 1.7215\n",
      "Epoch [15/100], Step [12000/24597], Loss: 1.8586\n",
      "Epoch [15/100], Step [12100/24597], Loss: 1.6240\n",
      "Epoch [15/100], Step [12200/24597], Loss: 1.6126\n",
      "Epoch [15/100], Step [12300/24597], Loss: 1.8145\n",
      "Epoch [15/100], Step [12400/24597], Loss: 1.5756\n",
      "Epoch [15/100], Step [12500/24597], Loss: 1.6278\n",
      "Epoch [15/100], Step [12600/24597], Loss: 1.5670\n",
      "Epoch [15/100], Step [12700/24597], Loss: 1.8366\n",
      "Epoch [15/100], Step [12800/24597], Loss: 1.5249\n",
      "Epoch [15/100], Step [12900/24597], Loss: 1.7455\n",
      "Epoch [15/100], Step [13000/24597], Loss: 1.6014\n",
      "Epoch [15/100], Step [13100/24597], Loss: 1.5759\n",
      "Epoch [15/100], Step [13200/24597], Loss: 1.5484\n",
      "Epoch [15/100], Step [13300/24597], Loss: 1.6344\n",
      "Epoch [15/100], Step [13400/24597], Loss: 1.6376\n",
      "Epoch [15/100], Step [13500/24597], Loss: 1.6065\n",
      "Epoch [15/100], Step [13600/24597], Loss: 1.6262\n",
      "Epoch [15/100], Step [13700/24597], Loss: 1.4900\n",
      "Epoch [15/100], Step [13800/24597], Loss: 1.5968\n",
      "Epoch [15/100], Step [13900/24597], Loss: 1.5890\n",
      "Epoch [15/100], Step [14000/24597], Loss: 1.7466\n",
      "Epoch [15/100], Step [14100/24597], Loss: 1.5484\n",
      "Epoch [15/100], Step [14200/24597], Loss: 1.6811\n",
      "Epoch [15/100], Step [14300/24597], Loss: 1.4770\n",
      "Epoch [15/100], Step [14400/24597], Loss: 1.6918\n",
      "Epoch [15/100], Step [14500/24597], Loss: 1.6388\n",
      "Epoch [15/100], Step [14600/24597], Loss: 1.6830\n",
      "Epoch [15/100], Step [14700/24597], Loss: 1.7537\n",
      "Epoch [15/100], Step [14800/24597], Loss: 1.6439\n",
      "Epoch [15/100], Step [14900/24597], Loss: 1.4445\n",
      "Epoch [15/100], Step [15000/24597], Loss: 1.6862\n",
      "Epoch [15/100], Step [15100/24597], Loss: 1.9388\n",
      "Epoch [15/100], Step [15200/24597], Loss: 1.7974\n",
      "Epoch [15/100], Step [15300/24597], Loss: 1.6210\n",
      "Epoch [15/100], Step [15400/24597], Loss: 1.6327\n",
      "Epoch [15/100], Step [15500/24597], Loss: 1.6093\n",
      "Epoch [15/100], Step [15600/24597], Loss: 1.8001\n",
      "Epoch [15/100], Step [15700/24597], Loss: 1.6590\n",
      "Epoch [15/100], Step [15800/24597], Loss: 1.5519\n",
      "Epoch [15/100], Step [15900/24597], Loss: 1.6382\n",
      "Epoch [15/100], Step [16000/24597], Loss: 1.6030\n",
      "Epoch [15/100], Step [16100/24597], Loss: 1.4350\n",
      "Epoch [15/100], Step [16200/24597], Loss: 1.5946\n",
      "Epoch [15/100], Step [16300/24597], Loss: 1.6449\n",
      "Epoch [15/100], Step [16400/24597], Loss: 1.8407\n",
      "Epoch [15/100], Step [16500/24597], Loss: 1.4334\n",
      "Epoch [15/100], Step [16600/24597], Loss: 1.8409\n",
      "Epoch [15/100], Step [16700/24597], Loss: 1.9543\n",
      "Epoch [15/100], Step [16800/24597], Loss: 1.5624\n",
      "Epoch [15/100], Step [16900/24597], Loss: 1.6868\n",
      "Epoch [15/100], Step [17000/24597], Loss: 1.4255\n",
      "Epoch [15/100], Step [17100/24597], Loss: 1.6372\n",
      "Epoch [15/100], Step [17200/24597], Loss: 1.5883\n",
      "Epoch [15/100], Step [17300/24597], Loss: 1.5944\n",
      "Epoch [15/100], Step [17400/24597], Loss: 1.5631\n",
      "Epoch [15/100], Step [17500/24597], Loss: 1.7271\n",
      "Epoch [15/100], Step [17600/24597], Loss: 1.3593\n",
      "Epoch [15/100], Step [17700/24597], Loss: 1.5302\n",
      "Epoch [15/100], Step [17800/24597], Loss: 1.5508\n",
      "Epoch [15/100], Step [17900/24597], Loss: 1.6452\n",
      "Epoch [15/100], Step [18000/24597], Loss: 1.4375\n",
      "Epoch [15/100], Step [18100/24597], Loss: 1.7403\n",
      "Epoch [15/100], Step [18200/24597], Loss: 1.4815\n",
      "Epoch [15/100], Step [18300/24597], Loss: 1.7402\n",
      "Epoch [15/100], Step [18400/24597], Loss: 1.5348\n",
      "Epoch [15/100], Step [18500/24597], Loss: 1.5717\n",
      "Epoch [15/100], Step [18600/24597], Loss: 1.6582\n",
      "Epoch [15/100], Step [18700/24597], Loss: 1.6653\n",
      "Epoch [15/100], Step [18800/24597], Loss: 1.5817\n",
      "Epoch [15/100], Step [18900/24597], Loss: 1.5983\n",
      "Epoch [15/100], Step [19000/24597], Loss: 1.5830\n",
      "Epoch [15/100], Step [19100/24597], Loss: 1.5657\n",
      "Epoch [15/100], Step [19200/24597], Loss: 1.4546\n",
      "Epoch [15/100], Step [19300/24597], Loss: 1.5381\n",
      "Epoch [15/100], Step [19400/24597], Loss: 1.8291\n",
      "Epoch [15/100], Step [19500/24597], Loss: 1.4473\n",
      "Epoch [15/100], Step [19600/24597], Loss: 1.5000\n",
      "Epoch [15/100], Step [19700/24597], Loss: 1.7882\n",
      "Epoch [15/100], Step [19800/24597], Loss: 1.7357\n",
      "Epoch [15/100], Step [19900/24597], Loss: 1.7463\n",
      "Epoch [15/100], Step [20000/24597], Loss: 1.7354\n",
      "Epoch [15/100], Step [20100/24597], Loss: 1.5195\n",
      "Epoch [15/100], Step [20200/24597], Loss: 1.7345\n",
      "Epoch [15/100], Step [20300/24597], Loss: 1.7280\n",
      "Epoch [15/100], Step [20400/24597], Loss: 1.7788\n",
      "Epoch [15/100], Step [20500/24597], Loss: 1.4881\n",
      "Epoch [15/100], Step [20600/24597], Loss: 1.6577\n",
      "Epoch [15/100], Step [20700/24597], Loss: 1.6809\n",
      "Epoch [15/100], Step [20800/24597], Loss: 1.6788\n",
      "Epoch [15/100], Step [20900/24597], Loss: 1.6939\n",
      "Epoch [15/100], Step [21000/24597], Loss: 1.5912\n",
      "Epoch [15/100], Step [21100/24597], Loss: 1.4877\n",
      "Epoch [15/100], Step [21200/24597], Loss: 1.5794\n",
      "Epoch [15/100], Step [21300/24597], Loss: 1.5610\n",
      "Epoch [15/100], Step [21400/24597], Loss: 1.6111\n",
      "Epoch [15/100], Step [21500/24597], Loss: 1.6443\n",
      "Epoch [15/100], Step [21600/24597], Loss: 1.8288\n",
      "Epoch [15/100], Step [21700/24597], Loss: 1.7000\n",
      "Epoch [15/100], Step [21800/24597], Loss: 1.3597\n",
      "Epoch [15/100], Step [21900/24597], Loss: 1.9984\n",
      "Epoch [15/100], Step [22000/24597], Loss: 1.6357\n",
      "Epoch [15/100], Step [22100/24597], Loss: 1.6649\n",
      "Epoch [15/100], Step [22200/24597], Loss: 1.4302\n",
      "Epoch [15/100], Step [22300/24597], Loss: 1.7384\n",
      "Epoch [15/100], Step [22400/24597], Loss: 1.7060\n",
      "Epoch [15/100], Step [22500/24597], Loss: 1.5347\n",
      "Epoch [15/100], Step [22600/24597], Loss: 1.7054\n",
      "Epoch [15/100], Step [22700/24597], Loss: 1.9097\n",
      "Epoch [15/100], Step [22800/24597], Loss: 1.5816\n",
      "Epoch [15/100], Step [22900/24597], Loss: 1.8254\n",
      "Epoch [15/100], Step [23000/24597], Loss: 1.3274\n",
      "Epoch [15/100], Step [23100/24597], Loss: 1.5840\n",
      "Epoch [15/100], Step [23200/24597], Loss: 1.6036\n",
      "Epoch [15/100], Step [23300/24597], Loss: 1.7207\n",
      "Epoch [15/100], Step [23400/24597], Loss: 1.5812\n",
      "Epoch [15/100], Step [23500/24597], Loss: 1.5440\n",
      "Epoch [15/100], Step [23600/24597], Loss: 1.6349\n",
      "Epoch [15/100], Step [23700/24597], Loss: 1.8780\n",
      "Epoch [15/100], Step [23800/24597], Loss: 1.7138\n",
      "Epoch [15/100], Step [23900/24597], Loss: 1.5547\n",
      "Epoch [15/100], Step [24000/24597], Loss: 1.9124\n",
      "Epoch [15/100], Step [24100/24597], Loss: 1.6230\n",
      "Epoch [15/100], Step [24200/24597], Loss: 1.5723\n",
      "Epoch [15/100], Step [24300/24597], Loss: 1.4933\n",
      "Epoch [15/100], Step [24400/24597], Loss: 1.7794\n",
      "Epoch [15/100], Step [24500/24597], Loss: 1.6400\n",
      "Epoch [16/100], Step [100/24597], Loss: 1.7682\n",
      "Epoch [16/100], Step [200/24597], Loss: 1.6093\n",
      "Epoch [16/100], Step [300/24597], Loss: 1.3922\n",
      "Epoch [16/100], Step [400/24597], Loss: 1.5684\n",
      "Epoch [16/100], Step [500/24597], Loss: 1.7024\n",
      "Epoch [16/100], Step [600/24597], Loss: 1.6173\n",
      "Epoch [16/100], Step [700/24597], Loss: 1.6443\n",
      "Epoch [16/100], Step [800/24597], Loss: 1.6239\n",
      "Epoch [16/100], Step [900/24597], Loss: 1.5346\n",
      "Epoch [16/100], Step [1000/24597], Loss: 1.6908\n",
      "Epoch [16/100], Step [1100/24597], Loss: 1.4283\n",
      "Epoch [16/100], Step [1200/24597], Loss: 1.5562\n",
      "Epoch [16/100], Step [1300/24597], Loss: 1.4768\n",
      "Epoch [16/100], Step [1400/24597], Loss: 1.3912\n",
      "Epoch [16/100], Step [1500/24597], Loss: 1.4646\n",
      "Epoch [16/100], Step [1600/24597], Loss: 1.6819\n",
      "Epoch [16/100], Step [1700/24597], Loss: 1.7802\n",
      "Epoch [16/100], Step [1800/24597], Loss: 1.4796\n",
      "Epoch [16/100], Step [1900/24597], Loss: 1.6362\n",
      "Epoch [16/100], Step [2000/24597], Loss: 1.5025\n",
      "Epoch [16/100], Step [2100/24597], Loss: 1.6000\n",
      "Epoch [16/100], Step [2200/24597], Loss: 1.6242\n",
      "Epoch [16/100], Step [2300/24597], Loss: 1.6309\n",
      "Epoch [16/100], Step [2400/24597], Loss: 1.3422\n",
      "Epoch [16/100], Step [2500/24597], Loss: 1.6930\n",
      "Epoch [16/100], Step [2600/24597], Loss: 1.6092\n",
      "Epoch [16/100], Step [2700/24597], Loss: 1.7160\n",
      "Epoch [16/100], Step [2800/24597], Loss: 1.5193\n",
      "Epoch [16/100], Step [2900/24597], Loss: 1.6874\n",
      "Epoch [16/100], Step [3000/24597], Loss: 1.7619\n",
      "Epoch [16/100], Step [3100/24597], Loss: 1.4503\n",
      "Epoch [16/100], Step [3200/24597], Loss: 1.6396\n",
      "Epoch [16/100], Step [3300/24597], Loss: 1.5162\n",
      "Epoch [16/100], Step [3400/24597], Loss: 1.5233\n",
      "Epoch [16/100], Step [3500/24597], Loss: 1.7931\n",
      "Epoch [16/100], Step [3600/24597], Loss: 1.7009\n",
      "Epoch [16/100], Step [3700/24597], Loss: 1.6480\n",
      "Epoch [16/100], Step [3800/24597], Loss: 1.5190\n",
      "Epoch [16/100], Step [3900/24597], Loss: 1.8001\n",
      "Epoch [16/100], Step [4000/24597], Loss: 1.5657\n",
      "Epoch [16/100], Step [4100/24597], Loss: 1.6935\n",
      "Epoch [16/100], Step [4200/24597], Loss: 1.7100\n",
      "Epoch [16/100], Step [4300/24597], Loss: 1.6149\n",
      "Epoch [16/100], Step [4400/24597], Loss: 1.5953\n",
      "Epoch [16/100], Step [4500/24597], Loss: 1.4390\n",
      "Epoch [16/100], Step [4600/24597], Loss: 1.6501\n",
      "Epoch [16/100], Step [4700/24597], Loss: 1.5087\n",
      "Epoch [16/100], Step [4800/24597], Loss: 1.5117\n",
      "Epoch [16/100], Step [4900/24597], Loss: 1.6281\n",
      "Epoch [16/100], Step [5000/24597], Loss: 1.3685\n",
      "Epoch [16/100], Step [5100/24597], Loss: 1.6551\n",
      "Epoch [16/100], Step [5200/24597], Loss: 1.5571\n",
      "Epoch [16/100], Step [5300/24597], Loss: 1.5422\n",
      "Epoch [16/100], Step [5400/24597], Loss: 1.4301\n",
      "Epoch [16/100], Step [5500/24597], Loss: 1.5984\n",
      "Epoch [16/100], Step [5600/24597], Loss: 1.5740\n",
      "Epoch [16/100], Step [5700/24597], Loss: 1.4582\n",
      "Epoch [16/100], Step [5800/24597], Loss: 1.6308\n",
      "Epoch [16/100], Step [5900/24597], Loss: 1.6387\n",
      "Epoch [16/100], Step [6000/24597], Loss: 1.4439\n",
      "Epoch [16/100], Step [6100/24597], Loss: 1.5274\n",
      "Epoch [16/100], Step [6200/24597], Loss: 1.7431\n",
      "Epoch [16/100], Step [6300/24597], Loss: 1.4779\n",
      "Epoch [16/100], Step [6400/24597], Loss: 1.6523\n",
      "Epoch [16/100], Step [6500/24597], Loss: 1.7395\n",
      "Epoch [16/100], Step [6600/24597], Loss: 1.6244\n",
      "Epoch [16/100], Step [6700/24597], Loss: 1.5201\n",
      "Epoch [16/100], Step [6800/24597], Loss: 1.4581\n",
      "Epoch [16/100], Step [6900/24597], Loss: 1.4379\n",
      "Epoch [16/100], Step [7000/24597], Loss: 1.6078\n",
      "Epoch [16/100], Step [7100/24597], Loss: 1.8024\n",
      "Epoch [16/100], Step [7200/24597], Loss: 1.6616\n",
      "Epoch [16/100], Step [7300/24597], Loss: 1.4824\n",
      "Epoch [16/100], Step [7400/24597], Loss: 1.5960\n",
      "Epoch [16/100], Step [7500/24597], Loss: 1.5548\n",
      "Epoch [16/100], Step [7600/24597], Loss: 1.7413\n",
      "Epoch [16/100], Step [7700/24597], Loss: 1.5076\n",
      "Epoch [16/100], Step [7800/24597], Loss: 1.3520\n",
      "Epoch [16/100], Step [7900/24597], Loss: 1.7712\n",
      "Epoch [16/100], Step [8000/24597], Loss: 1.4227\n",
      "Epoch [16/100], Step [8100/24597], Loss: 1.6228\n",
      "Epoch [16/100], Step [8200/24597], Loss: 1.6772\n",
      "Epoch [16/100], Step [8300/24597], Loss: 1.6566\n",
      "Epoch [16/100], Step [8400/24597], Loss: 1.5308\n",
      "Epoch [16/100], Step [8500/24597], Loss: 1.4862\n",
      "Epoch [16/100], Step [8600/24597], Loss: 1.7027\n",
      "Epoch [16/100], Step [8700/24597], Loss: 1.5868\n",
      "Epoch [16/100], Step [8800/24597], Loss: 1.6669\n",
      "Epoch [16/100], Step [8900/24597], Loss: 1.5591\n",
      "Epoch [16/100], Step [9000/24597], Loss: 1.5994\n",
      "Epoch [16/100], Step [9100/24597], Loss: 1.3250\n",
      "Epoch [16/100], Step [9200/24597], Loss: 1.6202\n",
      "Epoch [16/100], Step [9300/24597], Loss: 1.7682\n",
      "Epoch [16/100], Step [9400/24597], Loss: 1.6841\n",
      "Epoch [16/100], Step [9500/24597], Loss: 1.7281\n",
      "Epoch [16/100], Step [9600/24597], Loss: 1.6265\n",
      "Epoch [16/100], Step [9700/24597], Loss: 1.5592\n",
      "Epoch [16/100], Step [9800/24597], Loss: 1.4648\n",
      "Epoch [16/100], Step [9900/24597], Loss: 1.5953\n",
      "Epoch [16/100], Step [10000/24597], Loss: 1.4696\n",
      "Epoch [16/100], Step [10100/24597], Loss: 1.5513\n",
      "Epoch [16/100], Step [10200/24597], Loss: 1.5765\n",
      "Epoch [16/100], Step [10300/24597], Loss: 1.7215\n",
      "Epoch [16/100], Step [10400/24597], Loss: 1.6742\n",
      "Epoch [16/100], Step [10500/24597], Loss: 1.5742\n",
      "Epoch [16/100], Step [10600/24597], Loss: 1.7893\n",
      "Epoch [16/100], Step [10700/24597], Loss: 1.4014\n",
      "Epoch [16/100], Step [10800/24597], Loss: 1.6048\n",
      "Epoch [16/100], Step [10900/24597], Loss: 1.3740\n",
      "Epoch [16/100], Step [11000/24597], Loss: 1.5524\n",
      "Epoch [16/100], Step [11100/24597], Loss: 1.5614\n",
      "Epoch [16/100], Step [11200/24597], Loss: 1.3176\n",
      "Epoch [16/100], Step [11300/24597], Loss: 1.8439\n",
      "Epoch [16/100], Step [11400/24597], Loss: 1.6863\n",
      "Epoch [16/100], Step [11500/24597], Loss: 1.4572\n",
      "Epoch [16/100], Step [11600/24597], Loss: 1.5297\n",
      "Epoch [16/100], Step [11700/24597], Loss: 1.4152\n",
      "Epoch [16/100], Step [11800/24597], Loss: 1.6195\n",
      "Epoch [16/100], Step [11900/24597], Loss: 1.5718\n",
      "Epoch [16/100], Step [12000/24597], Loss: 1.6151\n",
      "Epoch [16/100], Step [12100/24597], Loss: 1.5368\n",
      "Epoch [16/100], Step [12200/24597], Loss: 1.6289\n",
      "Epoch [16/100], Step [12300/24597], Loss: 1.6641\n",
      "Epoch [16/100], Step [12400/24597], Loss: 1.6133\n",
      "Epoch [16/100], Step [12500/24597], Loss: 1.4886\n",
      "Epoch [16/100], Step [12600/24597], Loss: 1.6634\n",
      "Epoch [16/100], Step [12700/24597], Loss: 1.6281\n",
      "Epoch [16/100], Step [12800/24597], Loss: 1.4626\n",
      "Epoch [16/100], Step [12900/24597], Loss: 1.6780\n",
      "Epoch [16/100], Step [13000/24597], Loss: 1.5742\n",
      "Epoch [16/100], Step [13100/24597], Loss: 1.6934\n",
      "Epoch [16/100], Step [13200/24597], Loss: 1.5961\n",
      "Epoch [16/100], Step [13300/24597], Loss: 1.8151\n",
      "Epoch [16/100], Step [13400/24597], Loss: 1.5073\n",
      "Epoch [16/100], Step [13500/24597], Loss: 1.6039\n",
      "Epoch [16/100], Step [13600/24597], Loss: 1.6267\n",
      "Epoch [16/100], Step [13700/24597], Loss: 1.6024\n",
      "Epoch [16/100], Step [13800/24597], Loss: 1.4476\n",
      "Epoch [16/100], Step [13900/24597], Loss: 1.7374\n",
      "Epoch [16/100], Step [14000/24597], Loss: 1.7512\n",
      "Epoch [16/100], Step [14100/24597], Loss: 1.5480\n",
      "Epoch [16/100], Step [14200/24597], Loss: 1.5925\n",
      "Epoch [16/100], Step [14300/24597], Loss: 1.8549\n",
      "Epoch [16/100], Step [14400/24597], Loss: 1.6353\n",
      "Epoch [16/100], Step [14500/24597], Loss: 1.8903\n",
      "Epoch [16/100], Step [14600/24597], Loss: 1.6128\n",
      "Epoch [16/100], Step [14700/24597], Loss: 1.5401\n",
      "Epoch [16/100], Step [14800/24597], Loss: 1.9468\n",
      "Epoch [16/100], Step [14900/24597], Loss: 1.8374\n",
      "Epoch [16/100], Step [15000/24597], Loss: 1.6720\n",
      "Epoch [16/100], Step [15100/24597], Loss: 1.4980\n",
      "Epoch [16/100], Step [15200/24597], Loss: 1.5394\n",
      "Epoch [16/100], Step [15300/24597], Loss: 1.4014\n",
      "Epoch [16/100], Step [15400/24597], Loss: 1.6402\n",
      "Epoch [16/100], Step [15500/24597], Loss: 1.5833\n",
      "Epoch [16/100], Step [15600/24597], Loss: 1.4310\n",
      "Epoch [16/100], Step [15700/24597], Loss: 1.4964\n",
      "Epoch [16/100], Step [15800/24597], Loss: 1.8774\n",
      "Epoch [16/100], Step [15900/24597], Loss: 1.5161\n",
      "Epoch [16/100], Step [16000/24597], Loss: 1.5885\n",
      "Epoch [16/100], Step [16100/24597], Loss: 1.3900\n",
      "Epoch [16/100], Step [16200/24597], Loss: 1.6357\n",
      "Epoch [16/100], Step [16300/24597], Loss: 1.8760\n",
      "Epoch [16/100], Step [16400/24597], Loss: 1.6130\n",
      "Epoch [16/100], Step [16500/24597], Loss: 1.7770\n",
      "Epoch [16/100], Step [16600/24597], Loss: 1.5572\n",
      "Epoch [16/100], Step [16700/24597], Loss: 1.7086\n",
      "Epoch [16/100], Step [16800/24597], Loss: 1.6425\n",
      "Epoch [16/100], Step [16900/24597], Loss: 1.5617\n",
      "Epoch [16/100], Step [17000/24597], Loss: 1.4159\n",
      "Epoch [16/100], Step [17100/24597], Loss: 1.6464\n",
      "Epoch [16/100], Step [17200/24597], Loss: 1.7496\n",
      "Epoch [16/100], Step [17300/24597], Loss: 1.4911\n",
      "Epoch [16/100], Step [17400/24597], Loss: 1.5600\n",
      "Epoch [16/100], Step [17500/24597], Loss: 1.7058\n",
      "Epoch [16/100], Step [17600/24597], Loss: 1.8346\n",
      "Epoch [16/100], Step [17700/24597], Loss: 1.5611\n",
      "Epoch [16/100], Step [17800/24597], Loss: 1.5426\n",
      "Epoch [16/100], Step [17900/24597], Loss: 1.6088\n",
      "Epoch [16/100], Step [18000/24597], Loss: 1.7346\n",
      "Epoch [16/100], Step [18100/24597], Loss: 1.5890\n",
      "Epoch [16/100], Step [18200/24597], Loss: 1.7753\n",
      "Epoch [16/100], Step [18300/24597], Loss: 1.7290\n",
      "Epoch [16/100], Step [18400/24597], Loss: 1.5878\n",
      "Epoch [16/100], Step [18500/24597], Loss: 1.7674\n",
      "Epoch [16/100], Step [18600/24597], Loss: 1.4828\n",
      "Epoch [16/100], Step [18700/24597], Loss: 1.5916\n",
      "Epoch [16/100], Step [18800/24597], Loss: 1.5947\n",
      "Epoch [16/100], Step [18900/24597], Loss: 1.5485\n",
      "Epoch [16/100], Step [19000/24597], Loss: 1.5152\n",
      "Epoch [16/100], Step [19100/24597], Loss: 1.6102\n",
      "Epoch [16/100], Step [19200/24597], Loss: 1.6039\n",
      "Epoch [16/100], Step [19300/24597], Loss: 1.6685\n",
      "Epoch [16/100], Step [19400/24597], Loss: 1.6060\n",
      "Epoch [16/100], Step [19500/24597], Loss: 1.7423\n",
      "Epoch [16/100], Step [19600/24597], Loss: 1.7229\n",
      "Epoch [16/100], Step [19700/24597], Loss: 1.4843\n",
      "Epoch [16/100], Step [19800/24597], Loss: 1.6757\n",
      "Epoch [16/100], Step [19900/24597], Loss: 1.5880\n",
      "Epoch [16/100], Step [20000/24597], Loss: 1.6771\n",
      "Epoch [16/100], Step [20100/24597], Loss: 1.4535\n",
      "Epoch [16/100], Step [20200/24597], Loss: 1.8391\n",
      "Epoch [16/100], Step [20300/24597], Loss: 1.6155\n",
      "Epoch [16/100], Step [20400/24597], Loss: 1.7385\n",
      "Epoch [16/100], Step [20500/24597], Loss: 1.5653\n",
      "Epoch [16/100], Step [20600/24597], Loss: 1.5392\n",
      "Epoch [16/100], Step [20700/24597], Loss: 1.6301\n",
      "Epoch [16/100], Step [20800/24597], Loss: 1.4786\n",
      "Epoch [16/100], Step [20900/24597], Loss: 1.5542\n",
      "Epoch [16/100], Step [21000/24597], Loss: 1.6303\n",
      "Epoch [16/100], Step [21100/24597], Loss: 1.6299\n",
      "Epoch [16/100], Step [21200/24597], Loss: 1.5457\n",
      "Epoch [16/100], Step [21300/24597], Loss: 1.5920\n",
      "Epoch [16/100], Step [21400/24597], Loss: 1.6111\n",
      "Epoch [16/100], Step [21500/24597], Loss: 1.5497\n",
      "Epoch [16/100], Step [21600/24597], Loss: 1.7466\n",
      "Epoch [16/100], Step [21700/24597], Loss: 1.7561\n",
      "Epoch [16/100], Step [21800/24597], Loss: 1.4234\n",
      "Epoch [16/100], Step [21900/24597], Loss: 1.6554\n",
      "Epoch [16/100], Step [22000/24597], Loss: 1.6689\n",
      "Epoch [16/100], Step [22100/24597], Loss: 1.4847\n",
      "Epoch [16/100], Step [22200/24597], Loss: 1.6653\n",
      "Epoch [16/100], Step [22300/24597], Loss: 1.7017\n",
      "Epoch [16/100], Step [22400/24597], Loss: 1.5964\n",
      "Epoch [16/100], Step [22500/24597], Loss: 1.3547\n",
      "Epoch [16/100], Step [22600/24597], Loss: 1.5085\n",
      "Epoch [16/100], Step [22700/24597], Loss: 1.6585\n",
      "Epoch [16/100], Step [22800/24597], Loss: 1.6699\n",
      "Epoch [16/100], Step [22900/24597], Loss: 1.3586\n",
      "Epoch [16/100], Step [23000/24597], Loss: 1.7208\n",
      "Epoch [16/100], Step [23100/24597], Loss: 1.7873\n",
      "Epoch [16/100], Step [23200/24597], Loss: 1.6269\n",
      "Epoch [16/100], Step [23300/24597], Loss: 1.7722\n",
      "Epoch [16/100], Step [23400/24597], Loss: 1.6149\n",
      "Epoch [16/100], Step [23500/24597], Loss: 1.4393\n",
      "Epoch [16/100], Step [23600/24597], Loss: 1.4791\n",
      "Epoch [16/100], Step [23700/24597], Loss: 1.6969\n",
      "Epoch [16/100], Step [23800/24597], Loss: 1.4591\n",
      "Epoch [16/100], Step [23900/24597], Loss: 1.4976\n",
      "Epoch [16/100], Step [24000/24597], Loss: 1.5939\n",
      "Epoch [16/100], Step [24100/24597], Loss: 1.4724\n",
      "Epoch [16/100], Step [24200/24597], Loss: 1.7918\n",
      "Epoch [16/100], Step [24300/24597], Loss: 1.7336\n",
      "Epoch [16/100], Step [24400/24597], Loss: 1.7887\n",
      "Epoch [16/100], Step [24500/24597], Loss: 1.6302\n",
      "Epoch [17/100], Step [100/24597], Loss: 1.6486\n",
      "Epoch [17/100], Step [200/24597], Loss: 1.6314\n",
      "Epoch [17/100], Step [300/24597], Loss: 1.5916\n",
      "Epoch [17/100], Step [400/24597], Loss: 1.4327\n",
      "Epoch [17/100], Step [500/24597], Loss: 1.7045\n",
      "Epoch [17/100], Step [600/24597], Loss: 1.4204\n",
      "Epoch [17/100], Step [700/24597], Loss: 1.5161\n",
      "Epoch [17/100], Step [800/24597], Loss: 1.4215\n",
      "Epoch [17/100], Step [900/24597], Loss: 1.9023\n",
      "Epoch [17/100], Step [1000/24597], Loss: 1.6285\n",
      "Epoch [17/100], Step [1100/24597], Loss: 1.5331\n",
      "Epoch [17/100], Step [1200/24597], Loss: 1.6496\n",
      "Epoch [17/100], Step [1300/24597], Loss: 1.7741\n",
      "Epoch [17/100], Step [1400/24597], Loss: 1.5830\n",
      "Epoch [17/100], Step [1500/24597], Loss: 1.6941\n",
      "Epoch [17/100], Step [1600/24597], Loss: 1.6127\n",
      "Epoch [17/100], Step [1700/24597], Loss: 1.5017\n",
      "Epoch [17/100], Step [1800/24597], Loss: 1.7896\n",
      "Epoch [17/100], Step [1900/24597], Loss: 1.5907\n",
      "Epoch [17/100], Step [2000/24597], Loss: 1.4540\n",
      "Epoch [17/100], Step [2100/24597], Loss: 1.7783\n",
      "Epoch [17/100], Step [2200/24597], Loss: 1.6547\n",
      "Epoch [17/100], Step [2300/24597], Loss: 1.5820\n",
      "Epoch [17/100], Step [2400/24597], Loss: 1.6565\n",
      "Epoch [17/100], Step [2500/24597], Loss: 1.7485\n",
      "Epoch [17/100], Step [2600/24597], Loss: 1.8181\n",
      "Epoch [17/100], Step [2700/24597], Loss: 1.6537\n",
      "Epoch [17/100], Step [2800/24597], Loss: 1.7949\n",
      "Epoch [17/100], Step [2900/24597], Loss: 1.5735\n",
      "Epoch [17/100], Step [3000/24597], Loss: 1.5355\n",
      "Epoch [17/100], Step [3100/24597], Loss: 1.5729\n",
      "Epoch [17/100], Step [3200/24597], Loss: 1.6980\n",
      "Epoch [17/100], Step [3300/24597], Loss: 1.7448\n",
      "Epoch [17/100], Step [3400/24597], Loss: 1.6386\n",
      "Epoch [17/100], Step [3500/24597], Loss: 1.6214\n",
      "Epoch [17/100], Step [3600/24597], Loss: 1.4663\n",
      "Epoch [17/100], Step [3700/24597], Loss: 1.7020\n",
      "Epoch [17/100], Step [3800/24597], Loss: 1.4226\n",
      "Epoch [17/100], Step [3900/24597], Loss: 1.7565\n",
      "Epoch [17/100], Step [4000/24597], Loss: 1.4763\n",
      "Epoch [17/100], Step [4100/24597], Loss: 1.8294\n",
      "Epoch [17/100], Step [4200/24597], Loss: 1.5252\n",
      "Epoch [17/100], Step [4300/24597], Loss: 1.7018\n",
      "Epoch [17/100], Step [4400/24597], Loss: 1.4395\n",
      "Epoch [17/100], Step [4500/24597], Loss: 1.3975\n",
      "Epoch [17/100], Step [4600/24597], Loss: 1.5715\n",
      "Epoch [17/100], Step [4700/24597], Loss: 1.6907\n",
      "Epoch [17/100], Step [4800/24597], Loss: 1.5497\n",
      "Epoch [17/100], Step [4900/24597], Loss: 1.4241\n",
      "Epoch [17/100], Step [5000/24597], Loss: 1.5489\n",
      "Epoch [17/100], Step [5100/24597], Loss: 1.3084\n",
      "Epoch [17/100], Step [5200/24597], Loss: 1.5566\n",
      "Epoch [17/100], Step [5300/24597], Loss: 1.6671\n",
      "Epoch [17/100], Step [5400/24597], Loss: 1.6877\n",
      "Epoch [17/100], Step [5500/24597], Loss: 1.6897\n",
      "Epoch [17/100], Step [5600/24597], Loss: 1.5494\n",
      "Epoch [17/100], Step [5700/24597], Loss: 1.6908\n",
      "Epoch [17/100], Step [5800/24597], Loss: 1.5903\n",
      "Epoch [17/100], Step [5900/24597], Loss: 1.6489\n",
      "Epoch [17/100], Step [6000/24597], Loss: 1.8695\n",
      "Epoch [17/100], Step [6100/24597], Loss: 1.7249\n",
      "Epoch [17/100], Step [6200/24597], Loss: 1.3384\n",
      "Epoch [17/100], Step [6300/24597], Loss: 1.5078\n",
      "Epoch [17/100], Step [6400/24597], Loss: 1.7096\n",
      "Epoch [17/100], Step [6500/24597], Loss: 1.5391\n",
      "Epoch [17/100], Step [6600/24597], Loss: 1.4361\n",
      "Epoch [17/100], Step [6700/24597], Loss: 1.7435\n",
      "Epoch [17/100], Step [6800/24597], Loss: 1.6956\n",
      "Epoch [17/100], Step [6900/24597], Loss: 1.5270\n",
      "Epoch [17/100], Step [7000/24597], Loss: 1.5845\n",
      "Epoch [17/100], Step [7100/24597], Loss: 1.9068\n",
      "Epoch [17/100], Step [7200/24597], Loss: 1.5297\n",
      "Epoch [17/100], Step [7300/24597], Loss: 1.5768\n",
      "Epoch [17/100], Step [7400/24597], Loss: 1.6634\n",
      "Epoch [17/100], Step [7500/24597], Loss: 1.7826\n",
      "Epoch [17/100], Step [7600/24597], Loss: 1.7168\n",
      "Epoch [17/100], Step [7700/24597], Loss: 1.6238\n",
      "Epoch [17/100], Step [7800/24597], Loss: 1.5581\n",
      "Epoch [17/100], Step [7900/24597], Loss: 1.5847\n",
      "Epoch [17/100], Step [8000/24597], Loss: 1.4405\n",
      "Epoch [17/100], Step [8100/24597], Loss: 1.5310\n",
      "Epoch [17/100], Step [8200/24597], Loss: 1.5385\n",
      "Epoch [17/100], Step [8300/24597], Loss: 1.4856\n",
      "Epoch [17/100], Step [8400/24597], Loss: 1.6292\n",
      "Epoch [17/100], Step [8500/24597], Loss: 1.5084\n",
      "Epoch [17/100], Step [8600/24597], Loss: 1.7369\n",
      "Epoch [17/100], Step [8700/24597], Loss: 1.7845\n",
      "Epoch [17/100], Step [8800/24597], Loss: 1.6174\n",
      "Epoch [17/100], Step [8900/24597], Loss: 1.5773\n",
      "Epoch [17/100], Step [9000/24597], Loss: 1.7364\n",
      "Epoch [17/100], Step [9100/24597], Loss: 1.4186\n",
      "Epoch [17/100], Step [9200/24597], Loss: 1.7153\n",
      "Epoch [17/100], Step [9300/24597], Loss: 1.6773\n",
      "Epoch [17/100], Step [9400/24597], Loss: 1.5132\n",
      "Epoch [17/100], Step [9500/24597], Loss: 1.4621\n",
      "Epoch [17/100], Step [9600/24597], Loss: 1.5330\n",
      "Epoch [17/100], Step [9700/24597], Loss: 1.7721\n",
      "Epoch [17/100], Step [9800/24597], Loss: 1.8808\n",
      "Epoch [17/100], Step [9900/24597], Loss: 1.3304\n",
      "Epoch [17/100], Step [10000/24597], Loss: 1.7300\n",
      "Epoch [17/100], Step [10100/24597], Loss: 1.6375\n",
      "Epoch [17/100], Step [10200/24597], Loss: 1.4165\n",
      "Epoch [17/100], Step [10300/24597], Loss: 1.5429\n",
      "Epoch [17/100], Step [10400/24597], Loss: 1.6198\n",
      "Epoch [17/100], Step [10500/24597], Loss: 1.6230\n",
      "Epoch [17/100], Step [10600/24597], Loss: 1.4552\n",
      "Epoch [17/100], Step [10700/24597], Loss: 1.7800\n",
      "Epoch [17/100], Step [10800/24597], Loss: 1.5521\n",
      "Epoch [17/100], Step [10900/24597], Loss: 1.5970\n",
      "Epoch [17/100], Step [11000/24597], Loss: 1.7457\n",
      "Epoch [17/100], Step [11100/24597], Loss: 1.6330\n",
      "Epoch [17/100], Step [11200/24597], Loss: 1.6793\n",
      "Epoch [17/100], Step [11300/24597], Loss: 1.7198\n",
      "Epoch [17/100], Step [11400/24597], Loss: 1.6316\n",
      "Epoch [17/100], Step [11500/24597], Loss: 1.7718\n",
      "Epoch [17/100], Step [11600/24597], Loss: 1.9711\n",
      "Epoch [17/100], Step [11700/24597], Loss: 1.4306\n",
      "Epoch [17/100], Step [11800/24597], Loss: 1.5873\n",
      "Epoch [17/100], Step [11900/24597], Loss: 1.8786\n",
      "Epoch [17/100], Step [12000/24597], Loss: 1.6642\n",
      "Epoch [17/100], Step [12100/24597], Loss: 1.5818\n",
      "Epoch [17/100], Step [12200/24597], Loss: 1.4569\n",
      "Epoch [17/100], Step [12300/24597], Loss: 1.7893\n",
      "Epoch [17/100], Step [12400/24597], Loss: 1.7494\n",
      "Epoch [17/100], Step [12500/24597], Loss: 1.5127\n",
      "Epoch [17/100], Step [12600/24597], Loss: 1.3978\n",
      "Epoch [17/100], Step [12700/24597], Loss: 1.7478\n",
      "Epoch [17/100], Step [12800/24597], Loss: 1.5527\n",
      "Epoch [17/100], Step [12900/24597], Loss: 1.6355\n",
      "Epoch [17/100], Step [13000/24597], Loss: 1.5098\n",
      "Epoch [17/100], Step [13100/24597], Loss: 1.4776\n",
      "Epoch [17/100], Step [13200/24597], Loss: 1.7442\n",
      "Epoch [17/100], Step [13300/24597], Loss: 1.6438\n",
      "Epoch [17/100], Step [13400/24597], Loss: 1.8229\n",
      "Epoch [17/100], Step [13500/24597], Loss: 1.6962\n",
      "Epoch [17/100], Step [13600/24597], Loss: 1.5182\n",
      "Epoch [17/100], Step [13700/24597], Loss: 1.5546\n",
      "Epoch [17/100], Step [13800/24597], Loss: 1.7171\n",
      "Epoch [17/100], Step [13900/24597], Loss: 1.5025\n",
      "Epoch [17/100], Step [14000/24597], Loss: 1.6330\n",
      "Epoch [17/100], Step [14100/24597], Loss: 1.4971\n",
      "Epoch [17/100], Step [14200/24597], Loss: 1.7161\n",
      "Epoch [17/100], Step [14300/24597], Loss: 1.6907\n",
      "Epoch [17/100], Step [14400/24597], Loss: 1.6897\n",
      "Epoch [17/100], Step [14500/24597], Loss: 1.7742\n",
      "Epoch [17/100], Step [14600/24597], Loss: 1.3993\n",
      "Epoch [17/100], Step [14700/24597], Loss: 1.5879\n",
      "Epoch [17/100], Step [14800/24597], Loss: 1.6754\n",
      "Epoch [17/100], Step [14900/24597], Loss: 1.6260\n",
      "Epoch [17/100], Step [15000/24597], Loss: 1.6033\n",
      "Epoch [17/100], Step [15100/24597], Loss: 1.3451\n",
      "Epoch [17/100], Step [15200/24597], Loss: 1.6066\n",
      "Epoch [17/100], Step [15300/24597], Loss: 1.8365\n",
      "Epoch [17/100], Step [15400/24597], Loss: 1.4139\n",
      "Epoch [17/100], Step [15500/24597], Loss: 1.6127\n",
      "Epoch [17/100], Step [15600/24597], Loss: 1.7411\n",
      "Epoch [17/100], Step [15700/24597], Loss: 1.8634\n",
      "Epoch [17/100], Step [15800/24597], Loss: 1.5489\n",
      "Epoch [17/100], Step [15900/24597], Loss: 1.6150\n",
      "Epoch [17/100], Step [16000/24597], Loss: 1.4955\n",
      "Epoch [17/100], Step [16100/24597], Loss: 1.4904\n",
      "Epoch [17/100], Step [16200/24597], Loss: 1.7062\n",
      "Epoch [17/100], Step [16300/24597], Loss: 1.4259\n",
      "Epoch [17/100], Step [16400/24597], Loss: 1.6410\n",
      "Epoch [17/100], Step [16500/24597], Loss: 1.4493\n",
      "Epoch [17/100], Step [16600/24597], Loss: 1.5430\n",
      "Epoch [17/100], Step [16700/24597], Loss: 1.6390\n",
      "Epoch [17/100], Step [16800/24597], Loss: 1.4777\n",
      "Epoch [17/100], Step [16900/24597], Loss: 1.6110\n",
      "Epoch [17/100], Step [17000/24597], Loss: 1.5430\n",
      "Epoch [17/100], Step [17100/24597], Loss: 1.4086\n",
      "Epoch [17/100], Step [17200/24597], Loss: 1.9590\n",
      "Epoch [17/100], Step [17300/24597], Loss: 1.5501\n",
      "Epoch [17/100], Step [17400/24597], Loss: 1.5894\n",
      "Epoch [17/100], Step [17500/24597], Loss: 1.7300\n",
      "Epoch [17/100], Step [17600/24597], Loss: 1.6227\n",
      "Epoch [17/100], Step [17700/24597], Loss: 1.6459\n",
      "Epoch [17/100], Step [17800/24597], Loss: 1.5773\n",
      "Epoch [17/100], Step [17900/24597], Loss: 1.5580\n",
      "Epoch [17/100], Step [18000/24597], Loss: 1.6798\n",
      "Epoch [17/100], Step [18100/24597], Loss: 1.5600\n",
      "Epoch [17/100], Step [18200/24597], Loss: 1.7502\n",
      "Epoch [17/100], Step [18300/24597], Loss: 1.5880\n",
      "Epoch [17/100], Step [18400/24597], Loss: 1.7139\n",
      "Epoch [17/100], Step [18500/24597], Loss: 1.7822\n",
      "Epoch [17/100], Step [18600/24597], Loss: 2.0088\n",
      "Epoch [17/100], Step [18700/24597], Loss: 1.7773\n",
      "Epoch [17/100], Step [18800/24597], Loss: 2.0282\n",
      "Epoch [17/100], Step [18900/24597], Loss: 1.6944\n",
      "Epoch [17/100], Step [19000/24597], Loss: 1.6054\n",
      "Epoch [17/100], Step [19100/24597], Loss: 1.6448\n",
      "Epoch [17/100], Step [19200/24597], Loss: 1.6488\n",
      "Epoch [17/100], Step [19300/24597], Loss: 1.7992\n",
      "Epoch [17/100], Step [19400/24597], Loss: 1.6232\n",
      "Epoch [17/100], Step [19500/24597], Loss: 1.4615\n",
      "Epoch [17/100], Step [19600/24597], Loss: 1.7121\n",
      "Epoch [17/100], Step [19700/24597], Loss: 1.6686\n",
      "Epoch [17/100], Step [19800/24597], Loss: 1.5405\n",
      "Epoch [17/100], Step [19900/24597], Loss: 1.6051\n",
      "Epoch [17/100], Step [20000/24597], Loss: 1.5089\n",
      "Epoch [17/100], Step [20100/24597], Loss: 1.7636\n",
      "Epoch [17/100], Step [20200/24597], Loss: 1.7778\n",
      "Epoch [17/100], Step [20300/24597], Loss: 1.5369\n",
      "Epoch [17/100], Step [20400/24597], Loss: 1.6917\n",
      "Epoch [17/100], Step [20500/24597], Loss: 1.5544\n",
      "Epoch [17/100], Step [20600/24597], Loss: 1.7253\n",
      "Epoch [17/100], Step [20700/24597], Loss: 1.6205\n",
      "Epoch [17/100], Step [20800/24597], Loss: 1.6314\n",
      "Epoch [17/100], Step [20900/24597], Loss: 1.5205\n",
      "Epoch [17/100], Step [21000/24597], Loss: 1.4236\n",
      "Epoch [17/100], Step [21100/24597], Loss: 1.6901\n",
      "Epoch [17/100], Step [21200/24597], Loss: 1.5504\n",
      "Epoch [17/100], Step [21300/24597], Loss: 1.6390\n",
      "Epoch [17/100], Step [21400/24597], Loss: 1.4879\n",
      "Epoch [17/100], Step [21500/24597], Loss: 1.5229\n",
      "Epoch [17/100], Step [21600/24597], Loss: 1.6598\n",
      "Epoch [17/100], Step [21700/24597], Loss: 1.6476\n",
      "Epoch [17/100], Step [21800/24597], Loss: 1.6134\n",
      "Epoch [17/100], Step [21900/24597], Loss: 1.7670\n",
      "Epoch [17/100], Step [22000/24597], Loss: 1.4956\n",
      "Epoch [17/100], Step [22100/24597], Loss: 1.5754\n",
      "Epoch [17/100], Step [22200/24597], Loss: 1.6000\n",
      "Epoch [17/100], Step [22300/24597], Loss: 1.7433\n",
      "Epoch [17/100], Step [22400/24597], Loss: 1.7039\n",
      "Epoch [17/100], Step [22500/24597], Loss: 1.7634\n",
      "Epoch [17/100], Step [22600/24597], Loss: 1.6489\n",
      "Epoch [17/100], Step [22700/24597], Loss: 1.6290\n",
      "Epoch [17/100], Step [22800/24597], Loss: 1.6021\n",
      "Epoch [17/100], Step [22900/24597], Loss: 1.6474\n",
      "Epoch [17/100], Step [23000/24597], Loss: 1.7807\n",
      "Epoch [17/100], Step [23100/24597], Loss: 1.4872\n",
      "Epoch [17/100], Step [23200/24597], Loss: 1.7181\n",
      "Epoch [17/100], Step [23300/24597], Loss: 1.5781\n",
      "Epoch [17/100], Step [23400/24597], Loss: 1.6564\n",
      "Epoch [17/100], Step [23500/24597], Loss: 1.4770\n",
      "Epoch [17/100], Step [23600/24597], Loss: 1.4377\n",
      "Epoch [17/100], Step [23700/24597], Loss: 1.6026\n",
      "Epoch [17/100], Step [23800/24597], Loss: 1.5637\n",
      "Epoch [17/100], Step [23900/24597], Loss: 1.4928\n",
      "Epoch [17/100], Step [24000/24597], Loss: 1.6657\n",
      "Epoch [17/100], Step [24100/24597], Loss: 1.3947\n",
      "Epoch [17/100], Step [24200/24597], Loss: 1.5334\n",
      "Epoch [17/100], Step [24300/24597], Loss: 1.6043\n",
      "Epoch [17/100], Step [24400/24597], Loss: 1.6320\n",
      "Epoch [17/100], Step [24500/24597], Loss: 1.8719\n",
      "Epoch [18/100], Step [100/24597], Loss: 1.4679\n",
      "Epoch [18/100], Step [200/24597], Loss: 1.4255\n",
      "Epoch [18/100], Step [300/24597], Loss: 1.4752\n",
      "Epoch [18/100], Step [400/24597], Loss: 1.7044\n",
      "Epoch [18/100], Step [500/24597], Loss: 1.6675\n",
      "Epoch [18/100], Step [600/24597], Loss: 1.6982\n",
      "Epoch [18/100], Step [700/24597], Loss: 1.5156\n",
      "Epoch [18/100], Step [800/24597], Loss: 1.7425\n",
      "Epoch [18/100], Step [900/24597], Loss: 1.5658\n",
      "Epoch [18/100], Step [1000/24597], Loss: 1.6102\n",
      "Epoch [18/100], Step [1100/24597], Loss: 1.6502\n",
      "Epoch [18/100], Step [1200/24597], Loss: 1.5911\n",
      "Epoch [18/100], Step [1300/24597], Loss: 2.0304\n",
      "Epoch [18/100], Step [1400/24597], Loss: 1.4727\n",
      "Epoch [18/100], Step [1500/24597], Loss: 1.7405\n",
      "Epoch [18/100], Step [1600/24597], Loss: 1.6809\n",
      "Epoch [18/100], Step [1700/24597], Loss: 1.5689\n",
      "Epoch [18/100], Step [1800/24597], Loss: 1.5152\n",
      "Epoch [18/100], Step [1900/24597], Loss: 1.6913\n",
      "Epoch [18/100], Step [2000/24597], Loss: 1.4860\n",
      "Epoch [18/100], Step [2100/24597], Loss: 1.5313\n",
      "Epoch [18/100], Step [2200/24597], Loss: 1.7035\n",
      "Epoch [18/100], Step [2300/24597], Loss: 1.5072\n",
      "Epoch [18/100], Step [2400/24597], Loss: 1.6780\n",
      "Epoch [18/100], Step [2500/24597], Loss: 1.9396\n",
      "Epoch [18/100], Step [2600/24597], Loss: 1.6746\n",
      "Epoch [18/100], Step [2700/24597], Loss: 1.6335\n",
      "Epoch [18/100], Step [2800/24597], Loss: 1.6147\n",
      "Epoch [18/100], Step [2900/24597], Loss: 1.5818\n",
      "Epoch [18/100], Step [3000/24597], Loss: 1.8035\n",
      "Epoch [18/100], Step [3100/24597], Loss: 1.7153\n",
      "Epoch [18/100], Step [3200/24597], Loss: 1.6428\n",
      "Epoch [18/100], Step [3300/24597], Loss: 1.8677\n",
      "Epoch [18/100], Step [3400/24597], Loss: 1.7553\n",
      "Epoch [18/100], Step [3500/24597], Loss: 1.5224\n",
      "Epoch [18/100], Step [3600/24597], Loss: 1.5280\n",
      "Epoch [18/100], Step [3700/24597], Loss: 1.8943\n",
      "Epoch [18/100], Step [3800/24597], Loss: 1.6778\n",
      "Epoch [18/100], Step [3900/24597], Loss: 1.5596\n",
      "Epoch [18/100], Step [4000/24597], Loss: 1.6510\n",
      "Epoch [18/100], Step [4100/24597], Loss: 1.4644\n",
      "Epoch [18/100], Step [4200/24597], Loss: 1.5033\n",
      "Epoch [18/100], Step [4300/24597], Loss: 1.7314\n",
      "Epoch [18/100], Step [4400/24597], Loss: 1.4676\n",
      "Epoch [18/100], Step [4500/24597], Loss: 1.5364\n",
      "Epoch [18/100], Step [4600/24597], Loss: 1.6167\n",
      "Epoch [18/100], Step [4700/24597], Loss: 1.6507\n",
      "Epoch [18/100], Step [4800/24597], Loss: 1.7281\n",
      "Epoch [18/100], Step [4900/24597], Loss: 1.7387\n",
      "Epoch [18/100], Step [5000/24597], Loss: 1.7329\n",
      "Epoch [18/100], Step [5100/24597], Loss: 1.5598\n",
      "Epoch [18/100], Step [5200/24597], Loss: 1.4993\n",
      "Epoch [18/100], Step [5300/24597], Loss: 1.6487\n",
      "Epoch [18/100], Step [5400/24597], Loss: 1.7282\n",
      "Epoch [18/100], Step [5500/24597], Loss: 1.7498\n",
      "Epoch [18/100], Step [5600/24597], Loss: 1.6075\n",
      "Epoch [18/100], Step [5700/24597], Loss: 1.6310\n",
      "Epoch [18/100], Step [5800/24597], Loss: 1.5553\n",
      "Epoch [18/100], Step [5900/24597], Loss: 1.4984\n",
      "Epoch [18/100], Step [6000/24597], Loss: 1.6918\n",
      "Epoch [18/100], Step [6100/24597], Loss: 1.6807\n",
      "Epoch [18/100], Step [6200/24597], Loss: 1.6042\n",
      "Epoch [18/100], Step [6300/24597], Loss: 1.7063\n",
      "Epoch [18/100], Step [6400/24597], Loss: 1.5577\n",
      "Epoch [18/100], Step [6500/24597], Loss: 1.7556\n",
      "Epoch [18/100], Step [6600/24597], Loss: 1.4233\n",
      "Epoch [18/100], Step [6700/24597], Loss: 1.6249\n",
      "Epoch [18/100], Step [6800/24597], Loss: 1.8584\n",
      "Epoch [18/100], Step [6900/24597], Loss: 1.7329\n",
      "Epoch [18/100], Step [7000/24597], Loss: 1.6345\n",
      "Epoch [18/100], Step [7100/24597], Loss: 1.5949\n",
      "Epoch [18/100], Step [7200/24597], Loss: 1.6286\n",
      "Epoch [18/100], Step [7300/24597], Loss: 1.6061\n",
      "Epoch [18/100], Step [7400/24597], Loss: 1.4136\n",
      "Epoch [18/100], Step [7500/24597], Loss: 1.6010\n",
      "Epoch [18/100], Step [7600/24597], Loss: 1.5059\n",
      "Epoch [18/100], Step [7700/24597], Loss: 1.7062\n",
      "Epoch [18/100], Step [7800/24597], Loss: 1.5539\n",
      "Epoch [18/100], Step [7900/24597], Loss: 1.4525\n",
      "Epoch [18/100], Step [8000/24597], Loss: 1.6497\n",
      "Epoch [18/100], Step [8100/24597], Loss: 1.4937\n",
      "Epoch [18/100], Step [8200/24597], Loss: 1.6190\n",
      "Epoch [18/100], Step [8300/24597], Loss: 1.6120\n",
      "Epoch [18/100], Step [8400/24597], Loss: 1.7805\n",
      "Epoch [18/100], Step [8500/24597], Loss: 1.6691\n",
      "Epoch [18/100], Step [8600/24597], Loss: 1.5441\n",
      "Epoch [18/100], Step [8700/24597], Loss: 1.6285\n",
      "Epoch [18/100], Step [8800/24597], Loss: 1.4721\n",
      "Epoch [18/100], Step [8900/24597], Loss: 1.5271\n",
      "Epoch [18/100], Step [9000/24597], Loss: 1.6404\n",
      "Epoch [18/100], Step [9100/24597], Loss: 1.8965\n",
      "Epoch [18/100], Step [9200/24597], Loss: 1.9085\n",
      "Epoch [18/100], Step [9300/24597], Loss: 1.5528\n",
      "Epoch [18/100], Step [9400/24597], Loss: 1.5681\n",
      "Epoch [18/100], Step [9500/24597], Loss: 1.7106\n",
      "Epoch [18/100], Step [9600/24597], Loss: 1.5845\n",
      "Epoch [18/100], Step [9700/24597], Loss: 1.5712\n",
      "Epoch [18/100], Step [9800/24597], Loss: 1.7281\n",
      "Epoch [18/100], Step [9900/24597], Loss: 1.4898\n",
      "Epoch [18/100], Step [10000/24597], Loss: 1.7841\n",
      "Epoch [18/100], Step [10100/24597], Loss: 1.5285\n",
      "Epoch [18/100], Step [10200/24597], Loss: 1.4291\n",
      "Epoch [18/100], Step [10300/24597], Loss: 1.6806\n",
      "Epoch [18/100], Step [10400/24597], Loss: 1.5340\n",
      "Epoch [18/100], Step [10500/24597], Loss: 1.8094\n",
      "Epoch [18/100], Step [10600/24597], Loss: 1.5384\n",
      "Epoch [18/100], Step [10700/24597], Loss: 1.5620\n",
      "Epoch [18/100], Step [10800/24597], Loss: 1.6655\n",
      "Epoch [18/100], Step [10900/24597], Loss: 1.7024\n",
      "Epoch [18/100], Step [11000/24597], Loss: 1.7850\n",
      "Epoch [18/100], Step [11100/24597], Loss: 1.5419\n",
      "Epoch [18/100], Step [11200/24597], Loss: 1.6089\n",
      "Epoch [18/100], Step [11300/24597], Loss: 1.6686\n",
      "Epoch [18/100], Step [11400/24597], Loss: 1.5779\n",
      "Epoch [18/100], Step [11500/24597], Loss: 1.3425\n",
      "Epoch [18/100], Step [11600/24597], Loss: 1.6769\n",
      "Epoch [18/100], Step [11700/24597], Loss: 1.5328\n",
      "Epoch [18/100], Step [11800/24597], Loss: 1.5399\n",
      "Epoch [18/100], Step [11900/24597], Loss: 1.7443\n",
      "Epoch [18/100], Step [12000/24597], Loss: 1.5959\n",
      "Epoch [18/100], Step [12100/24597], Loss: 1.4793\n",
      "Epoch [18/100], Step [12200/24597], Loss: 1.4398\n",
      "Epoch [18/100], Step [12300/24597], Loss: 1.6049\n",
      "Epoch [18/100], Step [12400/24597], Loss: 1.8024\n",
      "Epoch [18/100], Step [12500/24597], Loss: 1.8404\n",
      "Epoch [18/100], Step [12600/24597], Loss: 1.5099\n",
      "Epoch [18/100], Step [12700/24597], Loss: 1.6455\n",
      "Epoch [18/100], Step [12800/24597], Loss: 1.4905\n",
      "Epoch [18/100], Step [12900/24597], Loss: 1.7173\n",
      "Epoch [18/100], Step [13000/24597], Loss: 1.5254\n",
      "Epoch [18/100], Step [13100/24597], Loss: 1.5028\n",
      "Epoch [18/100], Step [13200/24597], Loss: 1.6796\n",
      "Epoch [18/100], Step [13300/24597], Loss: 1.6112\n",
      "Epoch [18/100], Step [13400/24597], Loss: 1.8221\n",
      "Epoch [18/100], Step [13500/24597], Loss: 1.5287\n",
      "Epoch [18/100], Step [13600/24597], Loss: 1.5321\n",
      "Epoch [18/100], Step [13700/24597], Loss: 1.5993\n",
      "Epoch [18/100], Step [13800/24597], Loss: 1.6446\n",
      "Epoch [18/100], Step [13900/24597], Loss: 1.5723\n",
      "Epoch [18/100], Step [14000/24597], Loss: 1.7740\n",
      "Epoch [18/100], Step [14100/24597], Loss: 1.5395\n",
      "Epoch [18/100], Step [14200/24597], Loss: 1.4987\n",
      "Epoch [18/100], Step [14300/24597], Loss: 1.4991\n",
      "Epoch [18/100], Step [14400/24597], Loss: 1.6201\n",
      "Epoch [18/100], Step [14500/24597], Loss: 1.6384\n",
      "Epoch [18/100], Step [14600/24597], Loss: 1.4780\n",
      "Epoch [18/100], Step [14700/24597], Loss: 1.4306\n",
      "Epoch [18/100], Step [14800/24597], Loss: 1.6614\n",
      "Epoch [18/100], Step [14900/24597], Loss: 1.7762\n",
      "Epoch [18/100], Step [15000/24597], Loss: 1.6377\n",
      "Epoch [18/100], Step [15100/24597], Loss: 1.6022\n",
      "Epoch [18/100], Step [15200/24597], Loss: 1.5677\n",
      "Epoch [18/100], Step [15300/24597], Loss: 1.5300\n",
      "Epoch [18/100], Step [15400/24597], Loss: 1.5878\n",
      "Epoch [18/100], Step [15500/24597], Loss: 1.7113\n",
      "Epoch [18/100], Step [15600/24597], Loss: 1.4531\n",
      "Epoch [18/100], Step [15700/24597], Loss: 1.5726\n",
      "Epoch [18/100], Step [15800/24597], Loss: 1.3684\n",
      "Epoch [18/100], Step [15900/24597], Loss: 1.6766\n",
      "Epoch [18/100], Step [16000/24597], Loss: 1.7083\n",
      "Epoch [18/100], Step [16100/24597], Loss: 1.6230\n",
      "Epoch [18/100], Step [16200/24597], Loss: 1.4932\n",
      "Epoch [18/100], Step [16300/24597], Loss: 1.6757\n",
      "Epoch [18/100], Step [16400/24597], Loss: 1.4815\n",
      "Epoch [18/100], Step [16500/24597], Loss: 1.6999\n",
      "Epoch [18/100], Step [16600/24597], Loss: 1.6800\n",
      "Epoch [18/100], Step [16700/24597], Loss: 1.6726\n",
      "Epoch [18/100], Step [16800/24597], Loss: 1.6470\n",
      "Epoch [18/100], Step [16900/24597], Loss: 1.5939\n",
      "Epoch [18/100], Step [17000/24597], Loss: 1.4414\n",
      "Epoch [18/100], Step [17100/24597], Loss: 1.5929\n",
      "Epoch [18/100], Step [17200/24597], Loss: 1.9683\n",
      "Epoch [18/100], Step [17300/24597], Loss: 1.5472\n",
      "Epoch [18/100], Step [17400/24597], Loss: 1.4697\n",
      "Epoch [18/100], Step [17500/24597], Loss: 1.4287\n",
      "Epoch [18/100], Step [17600/24597], Loss: 1.5789\n",
      "Epoch [18/100], Step [17700/24597], Loss: 1.5611\n",
      "Epoch [18/100], Step [17800/24597], Loss: 1.4681\n",
      "Epoch [18/100], Step [17900/24597], Loss: 1.6380\n",
      "Epoch [18/100], Step [18000/24597], Loss: 1.6464\n",
      "Epoch [18/100], Step [18100/24597], Loss: 1.7035\n",
      "Epoch [18/100], Step [18200/24597], Loss: 1.6016\n",
      "Epoch [18/100], Step [18300/24597], Loss: 1.6829\n",
      "Epoch [18/100], Step [18400/24597], Loss: 1.4929\n",
      "Epoch [18/100], Step [18500/24597], Loss: 1.6448\n",
      "Epoch [18/100], Step [18600/24597], Loss: 1.5622\n",
      "Epoch [18/100], Step [18700/24597], Loss: 1.6546\n",
      "Epoch [18/100], Step [18800/24597], Loss: 1.4357\n",
      "Epoch [18/100], Step [18900/24597], Loss: 1.6930\n",
      "Epoch [18/100], Step [19000/24597], Loss: 1.5793\n",
      "Epoch [18/100], Step [19100/24597], Loss: 1.7096\n",
      "Epoch [18/100], Step [19200/24597], Loss: 1.6663\n",
      "Epoch [18/100], Step [19300/24597], Loss: 1.6644\n",
      "Epoch [18/100], Step [19400/24597], Loss: 1.6803\n",
      "Epoch [18/100], Step [19500/24597], Loss: 1.5622\n",
      "Epoch [18/100], Step [19600/24597], Loss: 1.7546\n",
      "Epoch [18/100], Step [19700/24597], Loss: 1.4126\n",
      "Epoch [18/100], Step [19800/24597], Loss: 1.5813\n",
      "Epoch [18/100], Step [19900/24597], Loss: 1.5708\n",
      "Epoch [18/100], Step [20000/24597], Loss: 1.3905\n",
      "Epoch [18/100], Step [20100/24597], Loss: 1.6704\n",
      "Epoch [18/100], Step [20200/24597], Loss: 1.6497\n",
      "Epoch [18/100], Step [20300/24597], Loss: 1.7582\n",
      "Epoch [18/100], Step [20400/24597], Loss: 1.4921\n",
      "Epoch [18/100], Step [20500/24597], Loss: 1.6333\n",
      "Epoch [18/100], Step [20600/24597], Loss: 1.6799\n",
      "Epoch [18/100], Step [20700/24597], Loss: 1.6363\n",
      "Epoch [18/100], Step [20800/24597], Loss: 1.6750\n",
      "Epoch [18/100], Step [20900/24597], Loss: 1.6325\n",
      "Epoch [18/100], Step [21000/24597], Loss: 1.6977\n",
      "Epoch [18/100], Step [21100/24597], Loss: 1.7349\n",
      "Epoch [18/100], Step [21200/24597], Loss: 1.5373\n",
      "Epoch [18/100], Step [21300/24597], Loss: 1.5609\n",
      "Epoch [18/100], Step [21400/24597], Loss: 1.7597\n",
      "Epoch [18/100], Step [21500/24597], Loss: 1.7404\n",
      "Epoch [18/100], Step [21600/24597], Loss: 1.5287\n",
      "Epoch [18/100], Step [21700/24597], Loss: 1.6366\n",
      "Epoch [18/100], Step [21800/24597], Loss: 1.7224\n",
      "Epoch [18/100], Step [21900/24597], Loss: 1.5152\n",
      "Epoch [18/100], Step [22000/24597], Loss: 1.8050\n",
      "Epoch [18/100], Step [22100/24597], Loss: 1.5476\n",
      "Epoch [18/100], Step [22200/24597], Loss: 1.5800\n",
      "Epoch [18/100], Step [22300/24597], Loss: 1.6161\n",
      "Epoch [18/100], Step [22400/24597], Loss: 1.6282\n",
      "Epoch [18/100], Step [22500/24597], Loss: 1.7515\n",
      "Epoch [18/100], Step [22600/24597], Loss: 1.5712\n",
      "Epoch [18/100], Step [22700/24597], Loss: 1.7431\n",
      "Epoch [18/100], Step [22800/24597], Loss: 1.6973\n",
      "Epoch [18/100], Step [22900/24597], Loss: 1.7400\n",
      "Epoch [18/100], Step [23000/24597], Loss: 1.6219\n",
      "Epoch [18/100], Step [23100/24597], Loss: 1.6296\n",
      "Epoch [18/100], Step [23200/24597], Loss: 1.5173\n",
      "Epoch [18/100], Step [23300/24597], Loss: 1.5347\n",
      "Epoch [18/100], Step [23400/24597], Loss: 1.5829\n",
      "Epoch [18/100], Step [23500/24597], Loss: 1.7534\n",
      "Epoch [18/100], Step [23600/24597], Loss: 1.6989\n",
      "Epoch [18/100], Step [23700/24597], Loss: 1.6931\n",
      "Epoch [18/100], Step [23800/24597], Loss: 1.6253\n",
      "Epoch [18/100], Step [23900/24597], Loss: 1.6770\n",
      "Epoch [18/100], Step [24000/24597], Loss: 1.6321\n",
      "Epoch [18/100], Step [24100/24597], Loss: 1.4287\n",
      "Epoch [18/100], Step [24200/24597], Loss: 1.6042\n",
      "Epoch [18/100], Step [24300/24597], Loss: 1.6612\n",
      "Epoch [18/100], Step [24400/24597], Loss: 1.5797\n",
      "Epoch [18/100], Step [24500/24597], Loss: 1.6896\n",
      "Epoch [19/100], Step [100/24597], Loss: 1.4129\n",
      "Epoch [19/100], Step [200/24597], Loss: 1.5873\n",
      "Epoch [19/100], Step [300/24597], Loss: 1.9696\n",
      "Epoch [19/100], Step [400/24597], Loss: 1.5020\n",
      "Epoch [19/100], Step [500/24597], Loss: 1.5811\n",
      "Epoch [19/100], Step [600/24597], Loss: 1.4563\n",
      "Epoch [19/100], Step [700/24597], Loss: 1.5311\n",
      "Epoch [19/100], Step [800/24597], Loss: 1.7793\n",
      "Epoch [19/100], Step [900/24597], Loss: 1.5938\n",
      "Epoch [19/100], Step [1000/24597], Loss: 1.6222\n",
      "Epoch [19/100], Step [1100/24597], Loss: 1.7321\n",
      "Epoch [19/100], Step [1200/24597], Loss: 1.7525\n",
      "Epoch [19/100], Step [1300/24597], Loss: 1.5750\n",
      "Epoch [19/100], Step [1400/24597], Loss: 1.7115\n",
      "Epoch [19/100], Step [1500/24597], Loss: 1.5021\n",
      "Epoch [19/100], Step [1600/24597], Loss: 1.6440\n",
      "Epoch [19/100], Step [1700/24597], Loss: 1.4252\n",
      "Epoch [19/100], Step [1800/24597], Loss: 1.6647\n",
      "Epoch [19/100], Step [1900/24597], Loss: 1.6095\n",
      "Epoch [19/100], Step [2000/24597], Loss: 1.4807\n",
      "Epoch [19/100], Step [2100/24597], Loss: 1.5376\n",
      "Epoch [19/100], Step [2200/24597], Loss: 1.6881\n",
      "Epoch [19/100], Step [2300/24597], Loss: 1.3625\n",
      "Epoch [19/100], Step [2400/24597], Loss: 1.5903\n",
      "Epoch [19/100], Step [2500/24597], Loss: 1.6513\n",
      "Epoch [19/100], Step [2600/24597], Loss: 1.6796\n",
      "Epoch [19/100], Step [2700/24597], Loss: 1.5445\n",
      "Epoch [19/100], Step [2800/24597], Loss: 1.4654\n",
      "Epoch [19/100], Step [2900/24597], Loss: 1.4673\n",
      "Epoch [19/100], Step [3000/24597], Loss: 1.5334\n",
      "Epoch [19/100], Step [3100/24597], Loss: 1.4225\n",
      "Epoch [19/100], Step [3200/24597], Loss: 1.5116\n",
      "Epoch [19/100], Step [3300/24597], Loss: 1.4858\n",
      "Epoch [19/100], Step [3400/24597], Loss: 1.6400\n",
      "Epoch [19/100], Step [3500/24597], Loss: 1.7384\n",
      "Epoch [19/100], Step [3600/24597], Loss: 1.5866\n",
      "Epoch [19/100], Step [3700/24597], Loss: 1.7141\n",
      "Epoch [19/100], Step [3800/24597], Loss: 1.6513\n",
      "Epoch [19/100], Step [3900/24597], Loss: 1.6485\n",
      "Epoch [19/100], Step [4000/24597], Loss: 1.4568\n",
      "Epoch [19/100], Step [4100/24597], Loss: 1.5655\n",
      "Epoch [19/100], Step [4200/24597], Loss: 1.4521\n",
      "Epoch [19/100], Step [4300/24597], Loss: 1.7121\n",
      "Epoch [19/100], Step [4400/24597], Loss: 1.8021\n",
      "Epoch [19/100], Step [4500/24597], Loss: 1.6240\n",
      "Epoch [19/100], Step [4600/24597], Loss: 1.8213\n",
      "Epoch [19/100], Step [4700/24597], Loss: 1.5357\n",
      "Epoch [19/100], Step [4800/24597], Loss: 1.6016\n",
      "Epoch [19/100], Step [4900/24597], Loss: 1.4646\n",
      "Epoch [19/100], Step [5000/24597], Loss: 1.5978\n",
      "Epoch [19/100], Step [5100/24597], Loss: 1.5774\n",
      "Epoch [19/100], Step [5200/24597], Loss: 1.9309\n",
      "Epoch [19/100], Step [5300/24597], Loss: 1.4211\n",
      "Epoch [19/100], Step [5400/24597], Loss: 1.6904\n",
      "Epoch [19/100], Step [5500/24597], Loss: 1.5556\n",
      "Epoch [19/100], Step [5600/24597], Loss: 1.5517\n",
      "Epoch [19/100], Step [5700/24597], Loss: 1.5824\n",
      "Epoch [19/100], Step [5800/24597], Loss: 1.5698\n",
      "Epoch [19/100], Step [5900/24597], Loss: 1.5610\n",
      "Epoch [19/100], Step [6000/24597], Loss: 1.7127\n",
      "Epoch [19/100], Step [6100/24597], Loss: 1.5850\n",
      "Epoch [19/100], Step [6200/24597], Loss: 1.5623\n",
      "Epoch [19/100], Step [6300/24597], Loss: 1.6787\n",
      "Epoch [19/100], Step [6400/24597], Loss: 1.6184\n",
      "Epoch [19/100], Step [6500/24597], Loss: 1.4127\n",
      "Epoch [19/100], Step [6600/24597], Loss: 1.4399\n",
      "Epoch [19/100], Step [6700/24597], Loss: 1.5174\n",
      "Epoch [19/100], Step [6800/24597], Loss: 1.4972\n",
      "Epoch [19/100], Step [6900/24597], Loss: 1.6148\n",
      "Epoch [19/100], Step [7000/24597], Loss: 1.5690\n",
      "Epoch [19/100], Step [7100/24597], Loss: 1.8357\n",
      "Epoch [19/100], Step [7200/24597], Loss: 1.5270\n",
      "Epoch [19/100], Step [7300/24597], Loss: 1.5340\n",
      "Epoch [19/100], Step [7400/24597], Loss: 1.4107\n",
      "Epoch [19/100], Step [7500/24597], Loss: 1.4966\n",
      "Epoch [19/100], Step [7600/24597], Loss: 1.3670\n",
      "Epoch [19/100], Step [7700/24597], Loss: 1.7303\n",
      "Epoch [19/100], Step [7800/24597], Loss: 1.5390\n",
      "Epoch [19/100], Step [7900/24597], Loss: 1.5082\n",
      "Epoch [19/100], Step [8000/24597], Loss: 1.6448\n",
      "Epoch [19/100], Step [8100/24597], Loss: 1.7942\n",
      "Epoch [19/100], Step [8200/24597], Loss: 1.7536\n",
      "Epoch [19/100], Step [8300/24597], Loss: 1.5347\n",
      "Epoch [19/100], Step [8400/24597], Loss: 1.6553\n",
      "Epoch [19/100], Step [8500/24597], Loss: 1.6760\n",
      "Epoch [19/100], Step [8600/24597], Loss: 1.6945\n",
      "Epoch [19/100], Step [8700/24597], Loss: 1.6460\n",
      "Epoch [19/100], Step [8800/24597], Loss: 1.7727\n",
      "Epoch [19/100], Step [8900/24597], Loss: 1.6726\n",
      "Epoch [19/100], Step [9000/24597], Loss: 1.7553\n",
      "Epoch [19/100], Step [9100/24597], Loss: 1.7409\n",
      "Epoch [19/100], Step [9200/24597], Loss: 1.4785\n",
      "Epoch [19/100], Step [9300/24597], Loss: 1.3912\n",
      "Epoch [19/100], Step [9400/24597], Loss: 1.6890\n",
      "Epoch [19/100], Step [9500/24597], Loss: 1.4782\n",
      "Epoch [19/100], Step [9600/24597], Loss: 1.6751\n",
      "Epoch [19/100], Step [9700/24597], Loss: 1.7287\n",
      "Epoch [19/100], Step [9800/24597], Loss: 1.6061\n",
      "Epoch [19/100], Step [9900/24597], Loss: 1.6721\n",
      "Epoch [19/100], Step [10000/24597], Loss: 1.5239\n",
      "Epoch [19/100], Step [10100/24597], Loss: 1.6179\n",
      "Epoch [19/100], Step [10200/24597], Loss: 1.3876\n",
      "Epoch [19/100], Step [10300/24597], Loss: 1.4880\n",
      "Epoch [19/100], Step [10400/24597], Loss: 1.6659\n",
      "Epoch [19/100], Step [10500/24597], Loss: 1.4415\n",
      "Epoch [19/100], Step [10600/24597], Loss: 1.8444\n",
      "Epoch [19/100], Step [10700/24597], Loss: 1.9069\n",
      "Epoch [19/100], Step [10800/24597], Loss: 1.7083\n",
      "Epoch [19/100], Step [10900/24597], Loss: 1.6583\n",
      "Epoch [19/100], Step [11000/24597], Loss: 1.7486\n",
      "Epoch [19/100], Step [11100/24597], Loss: 1.5528\n",
      "Epoch [19/100], Step [11200/24597], Loss: 1.6115\n",
      "Epoch [19/100], Step [11300/24597], Loss: 1.5969\n",
      "Epoch [19/100], Step [11400/24597], Loss: 1.6766\n",
      "Epoch [19/100], Step [11500/24597], Loss: 1.8504\n",
      "Epoch [19/100], Step [11600/24597], Loss: 1.3056\n",
      "Epoch [19/100], Step [11700/24597], Loss: 1.5362\n",
      "Epoch [19/100], Step [11800/24597], Loss: 1.9112\n",
      "Epoch [19/100], Step [11900/24597], Loss: 1.3301\n",
      "Epoch [19/100], Step [12000/24597], Loss: 1.5388\n",
      "Epoch [19/100], Step [12100/24597], Loss: 1.5596\n",
      "Epoch [19/100], Step [12200/24597], Loss: 1.6850\n",
      "Epoch [19/100], Step [12300/24597], Loss: 1.5556\n",
      "Epoch [19/100], Step [12400/24597], Loss: 1.6533\n",
      "Epoch [19/100], Step [12500/24597], Loss: 1.8146\n",
      "Epoch [19/100], Step [12600/24597], Loss: 1.5216\n",
      "Epoch [19/100], Step [12700/24597], Loss: 1.8451\n",
      "Epoch [19/100], Step [12800/24597], Loss: 1.9318\n",
      "Epoch [19/100], Step [12900/24597], Loss: 1.5931\n",
      "Epoch [19/100], Step [13000/24597], Loss: 1.5546\n",
      "Epoch [19/100], Step [13100/24597], Loss: 1.7473\n",
      "Epoch [19/100], Step [13200/24597], Loss: 1.5468\n",
      "Epoch [19/100], Step [13300/24597], Loss: 1.5409\n",
      "Epoch [19/100], Step [13400/24597], Loss: 1.7018\n",
      "Epoch [19/100], Step [13500/24597], Loss: 1.7111\n",
      "Epoch [19/100], Step [13600/24597], Loss: 1.7125\n",
      "Epoch [19/100], Step [13700/24597], Loss: 1.4696\n",
      "Epoch [19/100], Step [13800/24597], Loss: 1.5805\n",
      "Epoch [19/100], Step [13900/24597], Loss: 1.7200\n",
      "Epoch [19/100], Step [14000/24597], Loss: 1.6797\n",
      "Epoch [19/100], Step [14100/24597], Loss: 1.3998\n",
      "Epoch [19/100], Step [14200/24597], Loss: 1.5188\n",
      "Epoch [19/100], Step [14300/24597], Loss: 1.7103\n",
      "Epoch [19/100], Step [14400/24597], Loss: 1.5719\n",
      "Epoch [19/100], Step [14500/24597], Loss: 1.5313\n",
      "Epoch [19/100], Step [14600/24597], Loss: 1.6907\n",
      "Epoch [19/100], Step [14700/24597], Loss: 1.6602\n",
      "Epoch [19/100], Step [14800/24597], Loss: 1.7383\n",
      "Epoch [19/100], Step [14900/24597], Loss: 1.7602\n",
      "Epoch [19/100], Step [15000/24597], Loss: 1.7040\n",
      "Epoch [19/100], Step [15100/24597], Loss: 1.4328\n",
      "Epoch [19/100], Step [15200/24597], Loss: 1.7278\n",
      "Epoch [19/100], Step [15300/24597], Loss: 1.4295\n",
      "Epoch [19/100], Step [15400/24597], Loss: 1.7003\n",
      "Epoch [19/100], Step [15500/24597], Loss: 1.7733\n",
      "Epoch [19/100], Step [15600/24597], Loss: 1.6768\n",
      "Epoch [19/100], Step [15700/24597], Loss: 1.4081\n",
      "Epoch [19/100], Step [15800/24597], Loss: 1.4483\n",
      "Epoch [19/100], Step [15900/24597], Loss: 1.4572\n",
      "Epoch [19/100], Step [16000/24597], Loss: 1.4774\n",
      "Epoch [19/100], Step [16100/24597], Loss: 1.4589\n",
      "Epoch [19/100], Step [16200/24597], Loss: 1.5884\n",
      "Epoch [19/100], Step [16300/24597], Loss: 1.7480\n",
      "Epoch [19/100], Step [16400/24597], Loss: 1.6770\n",
      "Epoch [19/100], Step [16500/24597], Loss: 1.5256\n",
      "Epoch [19/100], Step [16600/24597], Loss: 1.4947\n",
      "Epoch [19/100], Step [16700/24597], Loss: 1.7842\n",
      "Epoch [19/100], Step [16800/24597], Loss: 1.5533\n",
      "Epoch [19/100], Step [16900/24597], Loss: 1.6586\n",
      "Epoch [19/100], Step [17000/24597], Loss: 1.4208\n",
      "Epoch [19/100], Step [17100/24597], Loss: 1.3572\n",
      "Epoch [19/100], Step [17200/24597], Loss: 1.6322\n",
      "Epoch [19/100], Step [17300/24597], Loss: 1.7029\n",
      "Epoch [19/100], Step [17400/24597], Loss: 1.6215\n",
      "Epoch [19/100], Step [17500/24597], Loss: 1.5965\n",
      "Epoch [19/100], Step [17600/24597], Loss: 1.7992\n",
      "Epoch [19/100], Step [17700/24597], Loss: 1.7153\n",
      "Epoch [19/100], Step [17800/24597], Loss: 1.6220\n",
      "Epoch [19/100], Step [17900/24597], Loss: 1.4352\n",
      "Epoch [19/100], Step [18000/24597], Loss: 1.5940\n",
      "Epoch [19/100], Step [18100/24597], Loss: 1.8557\n",
      "Epoch [19/100], Step [18200/24597], Loss: 1.5162\n",
      "Epoch [19/100], Step [18300/24597], Loss: 1.4981\n",
      "Epoch [19/100], Step [18400/24597], Loss: 1.5438\n",
      "Epoch [19/100], Step [18500/24597], Loss: 1.6589\n",
      "Epoch [19/100], Step [18600/24597], Loss: 1.7612\n",
      "Epoch [19/100], Step [18700/24597], Loss: 1.6614\n",
      "Epoch [19/100], Step [18800/24597], Loss: 1.5521\n",
      "Epoch [19/100], Step [18900/24597], Loss: 1.8045\n",
      "Epoch [19/100], Step [19000/24597], Loss: 1.5138\n",
      "Epoch [19/100], Step [19100/24597], Loss: 1.4358\n",
      "Epoch [19/100], Step [19200/24597], Loss: 1.5081\n",
      "Epoch [19/100], Step [19300/24597], Loss: 1.7158\n",
      "Epoch [19/100], Step [19400/24597], Loss: 1.7392\n",
      "Epoch [19/100], Step [19500/24597], Loss: 1.6183\n",
      "Epoch [19/100], Step [19600/24597], Loss: 1.7901\n",
      "Epoch [19/100], Step [19700/24597], Loss: 1.3911\n",
      "Epoch [19/100], Step [19800/24597], Loss: 1.4491\n",
      "Epoch [19/100], Step [19900/24597], Loss: 1.4206\n",
      "Epoch [19/100], Step [20000/24597], Loss: 1.5803\n",
      "Epoch [19/100], Step [20100/24597], Loss: 1.8238\n",
      "Epoch [19/100], Step [20200/24597], Loss: 1.5671\n",
      "Epoch [19/100], Step [20300/24597], Loss: 1.7682\n",
      "Epoch [19/100], Step [20400/24597], Loss: 1.5107\n",
      "Epoch [19/100], Step [20500/24597], Loss: 1.3982\n",
      "Epoch [19/100], Step [20600/24597], Loss: 1.6547\n",
      "Epoch [19/100], Step [20700/24597], Loss: 1.6519\n",
      "Epoch [19/100], Step [20800/24597], Loss: 1.6655\n",
      "Epoch [19/100], Step [20900/24597], Loss: 1.7008\n",
      "Epoch [19/100], Step [21000/24597], Loss: 1.4647\n",
      "Epoch [19/100], Step [21100/24597], Loss: 1.5615\n",
      "Epoch [19/100], Step [21200/24597], Loss: 1.6689\n",
      "Epoch [19/100], Step [21300/24597], Loss: 1.4852\n",
      "Epoch [19/100], Step [21400/24597], Loss: 1.5910\n",
      "Epoch [19/100], Step [21500/24597], Loss: 1.4520\n",
      "Epoch [19/100], Step [21600/24597], Loss: 1.7832\n",
      "Epoch [19/100], Step [21700/24597], Loss: 1.6203\n",
      "Epoch [19/100], Step [21800/24597], Loss: 1.6496\n",
      "Epoch [19/100], Step [21900/24597], Loss: 1.8094\n",
      "Epoch [19/100], Step [22000/24597], Loss: 1.8824\n",
      "Epoch [19/100], Step [22100/24597], Loss: 1.5864\n",
      "Epoch [19/100], Step [22200/24597], Loss: 1.6459\n",
      "Epoch [19/100], Step [22300/24597], Loss: 1.7218\n",
      "Epoch [19/100], Step [22400/24597], Loss: 1.6611\n",
      "Epoch [19/100], Step [22500/24597], Loss: 1.6171\n",
      "Epoch [19/100], Step [22600/24597], Loss: 1.4802\n",
      "Epoch [19/100], Step [22700/24597], Loss: 1.5976\n",
      "Epoch [19/100], Step [22800/24597], Loss: 1.5447\n",
      "Epoch [19/100], Step [22900/24597], Loss: 1.4742\n",
      "Epoch [19/100], Step [23000/24597], Loss: 1.5939\n",
      "Epoch [19/100], Step [23100/24597], Loss: 1.5052\n",
      "Epoch [19/100], Step [23200/24597], Loss: 1.7848\n",
      "Epoch [19/100], Step [23300/24597], Loss: 1.6850\n",
      "Epoch [19/100], Step [23400/24597], Loss: 1.6325\n",
      "Epoch [19/100], Step [23500/24597], Loss: 1.5659\n",
      "Epoch [19/100], Step [23600/24597], Loss: 1.5065\n",
      "Epoch [19/100], Step [23700/24597], Loss: 1.4804\n",
      "Epoch [19/100], Step [23800/24597], Loss: 1.6168\n",
      "Epoch [19/100], Step [23900/24597], Loss: 1.8373\n",
      "Epoch [19/100], Step [24000/24597], Loss: 1.6770\n",
      "Epoch [19/100], Step [24100/24597], Loss: 1.8606\n",
      "Epoch [19/100], Step [24200/24597], Loss: 1.8057\n",
      "Epoch [19/100], Step [24300/24597], Loss: 1.6160\n",
      "Epoch [19/100], Step [24400/24597], Loss: 1.6210\n",
      "Epoch [19/100], Step [24500/24597], Loss: 1.5980\n",
      "Epoch [20/100], Step [100/24597], Loss: 1.4819\n",
      "Epoch [20/100], Step [200/24597], Loss: 1.6334\n",
      "Epoch [20/100], Step [300/24597], Loss: 1.9314\n",
      "Epoch [20/100], Step [400/24597], Loss: 1.6711\n",
      "Epoch [20/100], Step [500/24597], Loss: 1.6449\n",
      "Epoch [20/100], Step [600/24597], Loss: 1.5960\n",
      "Epoch [20/100], Step [700/24597], Loss: 1.6446\n",
      "Epoch [20/100], Step [800/24597], Loss: 1.5281\n",
      "Epoch [20/100], Step [900/24597], Loss: 1.5870\n",
      "Epoch [20/100], Step [1000/24597], Loss: 1.5985\n",
      "Epoch [20/100], Step [1100/24597], Loss: 1.6223\n",
      "Epoch [20/100], Step [1200/24597], Loss: 1.7009\n",
      "Epoch [20/100], Step [1300/24597], Loss: 1.7795\n",
      "Epoch [20/100], Step [1400/24597], Loss: 1.4961\n",
      "Epoch [20/100], Step [1500/24597], Loss: 1.7344\n",
      "Epoch [20/100], Step [1600/24597], Loss: 1.6518\n",
      "Epoch [20/100], Step [1700/24597], Loss: 1.4044\n",
      "Epoch [20/100], Step [1800/24597], Loss: 1.5729\n",
      "Epoch [20/100], Step [1900/24597], Loss: 1.7337\n",
      "Epoch [20/100], Step [2000/24597], Loss: 1.4209\n",
      "Epoch [20/100], Step [2100/24597], Loss: 1.6431\n",
      "Epoch [20/100], Step [2200/24597], Loss: 1.7636\n",
      "Epoch [20/100], Step [2300/24597], Loss: 1.5758\n",
      "Epoch [20/100], Step [2400/24597], Loss: 1.4892\n",
      "Epoch [20/100], Step [2500/24597], Loss: 1.4539\n",
      "Epoch [20/100], Step [2600/24597], Loss: 1.7320\n",
      "Epoch [20/100], Step [2700/24597], Loss: 1.6738\n",
      "Epoch [20/100], Step [2800/24597], Loss: 1.5660\n",
      "Epoch [20/100], Step [2900/24597], Loss: 1.4904\n",
      "Epoch [20/100], Step [3000/24597], Loss: 1.6318\n",
      "Epoch [20/100], Step [3100/24597], Loss: 1.6683\n",
      "Epoch [20/100], Step [3200/24597], Loss: 1.5412\n",
      "Epoch [20/100], Step [3300/24597], Loss: 1.8053\n",
      "Epoch [20/100], Step [3400/24597], Loss: 1.3774\n",
      "Epoch [20/100], Step [3500/24597], Loss: 1.5626\n",
      "Epoch [20/100], Step [3600/24597], Loss: 1.4436\n",
      "Epoch [20/100], Step [3700/24597], Loss: 1.6208\n",
      "Epoch [20/100], Step [3800/24597], Loss: 1.8348\n",
      "Epoch [20/100], Step [3900/24597], Loss: 1.5333\n",
      "Epoch [20/100], Step [4000/24597], Loss: 1.6175\n",
      "Epoch [20/100], Step [4100/24597], Loss: 1.5814\n",
      "Epoch [20/100], Step [4200/24597], Loss: 1.7798\n",
      "Epoch [20/100], Step [4300/24597], Loss: 1.4700\n",
      "Epoch [20/100], Step [4400/24597], Loss: 1.4458\n",
      "Epoch [20/100], Step [4500/24597], Loss: 1.7277\n",
      "Epoch [20/100], Step [4600/24597], Loss: 1.5470\n",
      "Epoch [20/100], Step [4700/24597], Loss: 1.5316\n",
      "Epoch [20/100], Step [4800/24597], Loss: 1.6220\n",
      "Epoch [20/100], Step [4900/24597], Loss: 1.6695\n",
      "Epoch [20/100], Step [5000/24597], Loss: 1.4579\n",
      "Epoch [20/100], Step [5100/24597], Loss: 1.5301\n",
      "Epoch [20/100], Step [5200/24597], Loss: 1.5642\n",
      "Epoch [20/100], Step [5300/24597], Loss: 1.5349\n",
      "Epoch [20/100], Step [5400/24597], Loss: 1.7220\n",
      "Epoch [20/100], Step [5500/24597], Loss: 1.5841\n",
      "Epoch [20/100], Step [5600/24597], Loss: 1.9887\n",
      "Epoch [20/100], Step [5700/24597], Loss: 1.8071\n",
      "Epoch [20/100], Step [5800/24597], Loss: 1.5665\n",
      "Epoch [20/100], Step [5900/24597], Loss: 1.7110\n",
      "Epoch [20/100], Step [6000/24597], Loss: 1.5335\n",
      "Epoch [20/100], Step [6100/24597], Loss: 1.6034\n",
      "Epoch [20/100], Step [6200/24597], Loss: 1.7049\n",
      "Epoch [20/100], Step [6300/24597], Loss: 1.8491\n",
      "Epoch [20/100], Step [6400/24597], Loss: 1.6287\n",
      "Epoch [20/100], Step [6500/24597], Loss: 1.3793\n",
      "Epoch [20/100], Step [6600/24597], Loss: 1.4500\n",
      "Epoch [20/100], Step [6700/24597], Loss: 1.6317\n",
      "Epoch [20/100], Step [6800/24597], Loss: 1.7137\n",
      "Epoch [20/100], Step [6900/24597], Loss: 1.5479\n",
      "Epoch [20/100], Step [7000/24597], Loss: 1.5898\n",
      "Epoch [20/100], Step [7100/24597], Loss: 1.6099\n",
      "Epoch [20/100], Step [7200/24597], Loss: 1.9237\n",
      "Epoch [20/100], Step [7300/24597], Loss: 1.5498\n",
      "Epoch [20/100], Step [7400/24597], Loss: 1.5590\n",
      "Epoch [20/100], Step [7500/24597], Loss: 1.5262\n",
      "Epoch [20/100], Step [7600/24597], Loss: 1.6216\n",
      "Epoch [20/100], Step [7700/24597], Loss: 1.6172\n",
      "Epoch [20/100], Step [7800/24597], Loss: 1.6048\n",
      "Epoch [20/100], Step [7900/24597], Loss: 1.6740\n",
      "Epoch [20/100], Step [8000/24597], Loss: 1.5763\n",
      "Epoch [20/100], Step [8100/24597], Loss: 1.5834\n",
      "Epoch [20/100], Step [8200/24597], Loss: 1.7387\n",
      "Epoch [20/100], Step [8300/24597], Loss: 1.6182\n",
      "Epoch [20/100], Step [8400/24597], Loss: 1.8251\n",
      "Epoch [20/100], Step [8500/24597], Loss: 1.5161\n",
      "Epoch [20/100], Step [8600/24597], Loss: 1.5587\n",
      "Epoch [20/100], Step [8700/24597], Loss: 1.7464\n",
      "Epoch [20/100], Step [8800/24597], Loss: 1.6501\n",
      "Epoch [20/100], Step [8900/24597], Loss: 1.5541\n",
      "Epoch [20/100], Step [9000/24597], Loss: 1.5635\n",
      "Epoch [20/100], Step [9100/24597], Loss: 1.4866\n",
      "Epoch [20/100], Step [9200/24597], Loss: 1.5878\n",
      "Epoch [20/100], Step [9300/24597], Loss: 1.4337\n",
      "Epoch [20/100], Step [9400/24597], Loss: 1.5982\n",
      "Epoch [20/100], Step [9500/24597], Loss: 1.5944\n",
      "Epoch [20/100], Step [9600/24597], Loss: 1.6669\n",
      "Epoch [20/100], Step [9700/24597], Loss: 1.6351\n",
      "Epoch [20/100], Step [9800/24597], Loss: 1.2807\n",
      "Epoch [20/100], Step [9900/24597], Loss: 1.2441\n",
      "Epoch [20/100], Step [10000/24597], Loss: 1.5621\n",
      "Epoch [20/100], Step [10100/24597], Loss: 1.7453\n",
      "Epoch [20/100], Step [10200/24597], Loss: 1.5477\n",
      "Epoch [20/100], Step [10300/24597], Loss: 1.6723\n",
      "Epoch [20/100], Step [10400/24597], Loss: 1.7839\n",
      "Epoch [20/100], Step [10500/24597], Loss: 1.4701\n",
      "Epoch [20/100], Step [10600/24597], Loss: 1.5125\n",
      "Epoch [20/100], Step [10700/24597], Loss: 1.5230\n",
      "Epoch [20/100], Step [10800/24597], Loss: 1.6999\n",
      "Epoch [20/100], Step [10900/24597], Loss: 1.6421\n",
      "Epoch [20/100], Step [11000/24597], Loss: 1.5559\n",
      "Epoch [20/100], Step [11100/24597], Loss: 1.5328\n",
      "Epoch [20/100], Step [11200/24597], Loss: 1.7856\n",
      "Epoch [20/100], Step [11300/24597], Loss: 1.7501\n",
      "Epoch [20/100], Step [11400/24597], Loss: 1.3544\n",
      "Epoch [20/100], Step [11500/24597], Loss: 1.7480\n",
      "Epoch [20/100], Step [11600/24597], Loss: 1.5828\n",
      "Epoch [20/100], Step [11700/24597], Loss: 1.5085\n",
      "Epoch [20/100], Step [11800/24597], Loss: 1.8233\n",
      "Epoch [20/100], Step [11900/24597], Loss: 1.6114\n",
      "Epoch [20/100], Step [12000/24597], Loss: 1.5874\n",
      "Epoch [20/100], Step [12100/24597], Loss: 1.4602\n",
      "Epoch [20/100], Step [12200/24597], Loss: 1.5999\n",
      "Epoch [20/100], Step [12300/24597], Loss: 1.3708\n",
      "Epoch [20/100], Step [12400/24597], Loss: 1.7858\n",
      "Epoch [20/100], Step [12500/24597], Loss: 1.6401\n",
      "Epoch [20/100], Step [12600/24597], Loss: 1.6559\n",
      "Epoch [20/100], Step [12700/24597], Loss: 1.6281\n",
      "Epoch [20/100], Step [12800/24597], Loss: 1.4664\n",
      "Epoch [20/100], Step [12900/24597], Loss: 1.6934\n",
      "Epoch [20/100], Step [13000/24597], Loss: 1.7371\n",
      "Epoch [20/100], Step [13100/24597], Loss: 1.5283\n",
      "Epoch [20/100], Step [13200/24597], Loss: 1.3916\n",
      "Epoch [20/100], Step [13300/24597], Loss: 1.8475\n",
      "Epoch [20/100], Step [13400/24597], Loss: 1.6216\n",
      "Epoch [20/100], Step [13500/24597], Loss: 1.5742\n",
      "Epoch [20/100], Step [13600/24597], Loss: 1.6933\n",
      "Epoch [20/100], Step [13700/24597], Loss: 1.5873\n",
      "Epoch [20/100], Step [13800/24597], Loss: 1.6302\n",
      "Epoch [20/100], Step [13900/24597], Loss: 1.6646\n",
      "Epoch [20/100], Step [14000/24597], Loss: 1.5897\n",
      "Epoch [20/100], Step [14100/24597], Loss: 1.5065\n",
      "Epoch [20/100], Step [14200/24597], Loss: 1.7339\n",
      "Epoch [20/100], Step [14300/24597], Loss: 1.6248\n",
      "Epoch [20/100], Step [14400/24597], Loss: 1.6220\n",
      "Epoch [20/100], Step [14500/24597], Loss: 1.7045\n",
      "Epoch [20/100], Step [14600/24597], Loss: 1.6708\n",
      "Epoch [20/100], Step [14700/24597], Loss: 1.5001\n",
      "Epoch [20/100], Step [14800/24597], Loss: 1.7188\n",
      "Epoch [20/100], Step [14900/24597], Loss: 1.4323\n",
      "Epoch [20/100], Step [15000/24597], Loss: 1.4917\n",
      "Epoch [20/100], Step [15100/24597], Loss: 1.5190\n",
      "Epoch [20/100], Step [15200/24597], Loss: 1.5756\n",
      "Epoch [20/100], Step [15300/24597], Loss: 1.6237\n",
      "Epoch [20/100], Step [15400/24597], Loss: 1.3645\n",
      "Epoch [20/100], Step [15500/24597], Loss: 1.6300\n",
      "Epoch [20/100], Step [15600/24597], Loss: 1.5440\n",
      "Epoch [20/100], Step [15700/24597], Loss: 1.5837\n",
      "Epoch [20/100], Step [15800/24597], Loss: 1.4766\n",
      "Epoch [20/100], Step [15900/24597], Loss: 1.6155\n",
      "Epoch [20/100], Step [16000/24597], Loss: 1.5357\n",
      "Epoch [20/100], Step [16100/24597], Loss: 1.5238\n",
      "Epoch [20/100], Step [16200/24597], Loss: 1.5545\n",
      "Epoch [20/100], Step [16300/24597], Loss: 1.7505\n",
      "Epoch [20/100], Step [16400/24597], Loss: 1.5797\n",
      "Epoch [20/100], Step [16500/24597], Loss: 1.7014\n",
      "Epoch [20/100], Step [16600/24597], Loss: 1.7010\n",
      "Epoch [20/100], Step [16700/24597], Loss: 1.5728\n",
      "Epoch [20/100], Step [16800/24597], Loss: 1.4131\n",
      "Epoch [20/100], Step [16900/24597], Loss: 1.5648\n",
      "Epoch [20/100], Step [17000/24597], Loss: 1.6762\n",
      "Epoch [20/100], Step [17100/24597], Loss: 1.5104\n",
      "Epoch [20/100], Step [17200/24597], Loss: 1.5352\n",
      "Epoch [20/100], Step [17300/24597], Loss: 1.6416\n",
      "Epoch [20/100], Step [17400/24597], Loss: 1.5720\n",
      "Epoch [20/100], Step [17500/24597], Loss: 1.6426\n",
      "Epoch [20/100], Step [17600/24597], Loss: 1.4320\n",
      "Epoch [20/100], Step [17700/24597], Loss: 1.6717\n",
      "Epoch [20/100], Step [17800/24597], Loss: 1.6150\n",
      "Epoch [20/100], Step [17900/24597], Loss: 1.7787\n",
      "Epoch [20/100], Step [18000/24597], Loss: 1.6775\n",
      "Epoch [20/100], Step [18100/24597], Loss: 1.6787\n",
      "Epoch [20/100], Step [18200/24597], Loss: 1.5208\n",
      "Epoch [20/100], Step [18300/24597], Loss: 1.4998\n",
      "Epoch [20/100], Step [18400/24597], Loss: 1.4864\n",
      "Epoch [20/100], Step [18500/24597], Loss: 1.6736\n",
      "Epoch [20/100], Step [18600/24597], Loss: 1.7505\n",
      "Epoch [20/100], Step [18700/24597], Loss: 1.7424\n",
      "Epoch [20/100], Step [18800/24597], Loss: 1.6680\n",
      "Epoch [20/100], Step [18900/24597], Loss: 1.7035\n",
      "Epoch [20/100], Step [19000/24597], Loss: 1.6187\n",
      "Epoch [20/100], Step [19100/24597], Loss: 1.7632\n",
      "Epoch [20/100], Step [19200/24597], Loss: 2.0189\n",
      "Epoch [20/100], Step [19300/24597], Loss: 1.8179\n",
      "Epoch [20/100], Step [19400/24597], Loss: 1.3982\n",
      "Epoch [20/100], Step [19500/24597], Loss: 1.5428\n",
      "Epoch [20/100], Step [19600/24597], Loss: 1.6815\n",
      "Epoch [20/100], Step [19700/24597], Loss: 1.5909\n",
      "Epoch [20/100], Step [19800/24597], Loss: 1.4567\n",
      "Epoch [20/100], Step [19900/24597], Loss: 1.6478\n",
      "Epoch [20/100], Step [20000/24597], Loss: 1.6226\n",
      "Epoch [20/100], Step [20100/24597], Loss: 1.4456\n",
      "Epoch [20/100], Step [20200/24597], Loss: 1.5501\n",
      "Epoch [20/100], Step [20300/24597], Loss: 1.7516\n",
      "Epoch [20/100], Step [20400/24597], Loss: 1.6013\n",
      "Epoch [20/100], Step [20500/24597], Loss: 1.5026\n",
      "Epoch [20/100], Step [20600/24597], Loss: 1.4139\n",
      "Epoch [20/100], Step [20700/24597], Loss: 1.6423\n",
      "Epoch [20/100], Step [20800/24597], Loss: 1.5023\n",
      "Epoch [20/100], Step [20900/24597], Loss: 1.4222\n",
      "Epoch [20/100], Step [21000/24597], Loss: 1.5506\n",
      "Epoch [20/100], Step [21100/24597], Loss: 1.5203\n",
      "Epoch [20/100], Step [21200/24597], Loss: 1.8030\n",
      "Epoch [20/100], Step [21300/24597], Loss: 1.4907\n",
      "Epoch [20/100], Step [21400/24597], Loss: 1.7874\n",
      "Epoch [20/100], Step [21500/24597], Loss: 1.8416\n",
      "Epoch [20/100], Step [21600/24597], Loss: 1.7228\n",
      "Epoch [20/100], Step [21700/24597], Loss: 1.7928\n",
      "Epoch [20/100], Step [21800/24597], Loss: 1.5804\n",
      "Epoch [20/100], Step [21900/24597], Loss: 1.4701\n",
      "Epoch [20/100], Step [22000/24597], Loss: 1.7268\n",
      "Epoch [20/100], Step [22100/24597], Loss: 1.7300\n",
      "Epoch [20/100], Step [22200/24597], Loss: 1.4361\n",
      "Epoch [20/100], Step [22300/24597], Loss: 1.5263\n",
      "Epoch [20/100], Step [22400/24597], Loss: 1.6758\n",
      "Epoch [20/100], Step [22500/24597], Loss: 1.5947\n",
      "Epoch [20/100], Step [22600/24597], Loss: 1.7343\n",
      "Epoch [20/100], Step [22700/24597], Loss: 1.7028\n",
      "Epoch [20/100], Step [22800/24597], Loss: 1.7663\n",
      "Epoch [20/100], Step [22900/24597], Loss: 1.6303\n",
      "Epoch [20/100], Step [23000/24597], Loss: 1.4949\n",
      "Epoch [20/100], Step [23100/24597], Loss: 1.5722\n",
      "Epoch [20/100], Step [23200/24597], Loss: 1.6203\n",
      "Epoch [20/100], Step [23300/24597], Loss: 1.3654\n",
      "Epoch [20/100], Step [23400/24597], Loss: 1.8190\n",
      "Epoch [20/100], Step [23500/24597], Loss: 1.5091\n",
      "Epoch [20/100], Step [23600/24597], Loss: 1.6967\n",
      "Epoch [20/100], Step [23700/24597], Loss: 1.4870\n",
      "Epoch [20/100], Step [23800/24597], Loss: 1.2856\n",
      "Epoch [20/100], Step [23900/24597], Loss: 1.5396\n",
      "Epoch [20/100], Step [24000/24597], Loss: 1.4097\n",
      "Epoch [20/100], Step [24100/24597], Loss: 1.4823\n",
      "Epoch [20/100], Step [24200/24597], Loss: 1.5938\n",
      "Epoch [20/100], Step [24300/24597], Loss: 1.6226\n",
      "Epoch [20/100], Step [24400/24597], Loss: 1.6651\n",
      "Epoch [20/100], Step [24500/24597], Loss: 1.6695\n",
      "Epoch [21/100], Step [100/24597], Loss: 1.6544\n",
      "Epoch [21/100], Step [200/24597], Loss: 1.7878\n",
      "Epoch [21/100], Step [300/24597], Loss: 1.7501\n",
      "Epoch [21/100], Step [400/24597], Loss: 1.6645\n",
      "Epoch [21/100], Step [500/24597], Loss: 1.6060\n",
      "Epoch [21/100], Step [600/24597], Loss: 1.4757\n",
      "Epoch [21/100], Step [700/24597], Loss: 1.7746\n",
      "Epoch [21/100], Step [800/24597], Loss: 1.7647\n",
      "Epoch [21/100], Step [900/24597], Loss: 1.5950\n",
      "Epoch [21/100], Step [1000/24597], Loss: 1.5407\n",
      "Epoch [21/100], Step [1100/24597], Loss: 1.5086\n",
      "Epoch [21/100], Step [1200/24597], Loss: 1.6714\n",
      "Epoch [21/100], Step [1300/24597], Loss: 1.4950\n",
      "Epoch [21/100], Step [1400/24597], Loss: 1.6188\n",
      "Epoch [21/100], Step [1500/24597], Loss: 1.5837\n",
      "Epoch [21/100], Step [1600/24597], Loss: 1.6490\n",
      "Epoch [21/100], Step [1700/24597], Loss: 1.8257\n",
      "Epoch [21/100], Step [1800/24597], Loss: 1.5647\n",
      "Epoch [21/100], Step [1900/24597], Loss: 1.5680\n",
      "Epoch [21/100], Step [2000/24597], Loss: 1.6488\n",
      "Epoch [21/100], Step [2100/24597], Loss: 1.6769\n",
      "Epoch [21/100], Step [2200/24597], Loss: 1.5353\n",
      "Epoch [21/100], Step [2300/24597], Loss: 1.6847\n",
      "Epoch [21/100], Step [2400/24597], Loss: 1.6794\n",
      "Epoch [21/100], Step [2500/24597], Loss: 1.5467\n",
      "Epoch [21/100], Step [2600/24597], Loss: 1.7074\n",
      "Epoch [21/100], Step [2700/24597], Loss: 1.8487\n",
      "Epoch [21/100], Step [2800/24597], Loss: 1.6390\n",
      "Epoch [21/100], Step [2900/24597], Loss: 1.6107\n",
      "Epoch [21/100], Step [3000/24597], Loss: 1.4170\n",
      "Epoch [21/100], Step [3100/24597], Loss: 1.6931\n",
      "Epoch [21/100], Step [3200/24597], Loss: 1.6704\n",
      "Epoch [21/100], Step [3300/24597], Loss: 1.5997\n",
      "Epoch [21/100], Step [3400/24597], Loss: 1.5483\n",
      "Epoch [21/100], Step [3500/24597], Loss: 1.5674\n",
      "Epoch [21/100], Step [3600/24597], Loss: 1.5377\n",
      "Epoch [21/100], Step [3700/24597], Loss: 1.6790\n",
      "Epoch [21/100], Step [3800/24597], Loss: 1.6618\n",
      "Epoch [21/100], Step [3900/24597], Loss: 1.4842\n",
      "Epoch [21/100], Step [4000/24597], Loss: 1.8075\n",
      "Epoch [21/100], Step [4100/24597], Loss: 1.4909\n",
      "Epoch [21/100], Step [4200/24597], Loss: 1.6133\n",
      "Epoch [21/100], Step [4300/24597], Loss: 1.7879\n",
      "Epoch [21/100], Step [4400/24597], Loss: 1.5191\n",
      "Epoch [21/100], Step [4500/24597], Loss: 1.7171\n",
      "Epoch [21/100], Step [4600/24597], Loss: 1.6388\n",
      "Epoch [21/100], Step [4700/24597], Loss: 1.6431\n",
      "Epoch [21/100], Step [4800/24597], Loss: 1.6651\n",
      "Epoch [21/100], Step [4900/24597], Loss: 1.5467\n",
      "Epoch [21/100], Step [5000/24597], Loss: 1.7576\n",
      "Epoch [21/100], Step [5100/24597], Loss: 1.4571\n",
      "Epoch [21/100], Step [5200/24597], Loss: 1.5992\n",
      "Epoch [21/100], Step [5300/24597], Loss: 1.6671\n",
      "Epoch [21/100], Step [5400/24597], Loss: 1.3863\n",
      "Epoch [21/100], Step [5500/24597], Loss: 1.4542\n",
      "Epoch [21/100], Step [5600/24597], Loss: 1.5691\n",
      "Epoch [21/100], Step [5700/24597], Loss: 1.4787\n",
      "Epoch [21/100], Step [5800/24597], Loss: 1.6500\n",
      "Epoch [21/100], Step [5900/24597], Loss: 1.6045\n",
      "Epoch [21/100], Step [6000/24597], Loss: 1.4744\n",
      "Epoch [21/100], Step [6100/24597], Loss: 1.7817\n",
      "Epoch [21/100], Step [6200/24597], Loss: 1.7103\n",
      "Epoch [21/100], Step [6300/24597], Loss: 1.6082\n",
      "Epoch [21/100], Step [6400/24597], Loss: 1.6091\n",
      "Epoch [21/100], Step [6500/24597], Loss: 1.6743\n",
      "Epoch [21/100], Step [6600/24597], Loss: 1.4777\n",
      "Epoch [21/100], Step [6700/24597], Loss: 1.6068\n",
      "Epoch [21/100], Step [6800/24597], Loss: 1.5434\n",
      "Epoch [21/100], Step [6900/24597], Loss: 1.7193\n",
      "Epoch [21/100], Step [7000/24597], Loss: 1.5311\n",
      "Epoch [21/100], Step [7100/24597], Loss: 1.5465\n",
      "Epoch [21/100], Step [7200/24597], Loss: 1.5869\n",
      "Epoch [21/100], Step [7300/24597], Loss: 1.6148\n",
      "Epoch [21/100], Step [7400/24597], Loss: 1.6988\n",
      "Epoch [21/100], Step [7500/24597], Loss: 1.6172\n",
      "Epoch [21/100], Step [7600/24597], Loss: 1.6618\n",
      "Epoch [21/100], Step [7700/24597], Loss: 1.6624\n",
      "Epoch [21/100], Step [7800/24597], Loss: 1.5804\n",
      "Epoch [21/100], Step [7900/24597], Loss: 1.7826\n",
      "Epoch [21/100], Step [8000/24597], Loss: 1.4326\n",
      "Epoch [21/100], Step [8100/24597], Loss: 1.6116\n",
      "Epoch [21/100], Step [8200/24597], Loss: 1.6398\n",
      "Epoch [21/100], Step [8300/24597], Loss: 1.7068\n",
      "Epoch [21/100], Step [8400/24597], Loss: 1.5544\n",
      "Epoch [21/100], Step [8500/24597], Loss: 1.5793\n",
      "Epoch [21/100], Step [8600/24597], Loss: 1.5216\n",
      "Epoch [21/100], Step [8700/24597], Loss: 1.5024\n",
      "Epoch [21/100], Step [8800/24597], Loss: 1.9144\n",
      "Epoch [21/100], Step [8900/24597], Loss: 1.7081\n",
      "Epoch [21/100], Step [9000/24597], Loss: 1.7166\n",
      "Epoch [21/100], Step [9100/24597], Loss: 1.5648\n",
      "Epoch [21/100], Step [9200/24597], Loss: 1.5767\n",
      "Epoch [21/100], Step [9300/24597], Loss: 1.4893\n",
      "Epoch [21/100], Step [9400/24597], Loss: 1.5559\n",
      "Epoch [21/100], Step [9500/24597], Loss: 1.5106\n",
      "Epoch [21/100], Step [9600/24597], Loss: 1.6752\n",
      "Epoch [21/100], Step [9700/24597], Loss: 1.4512\n",
      "Epoch [21/100], Step [9800/24597], Loss: 1.4720\n",
      "Epoch [21/100], Step [9900/24597], Loss: 1.7800\n",
      "Epoch [21/100], Step [10000/24597], Loss: 1.6427\n",
      "Epoch [21/100], Step [10100/24597], Loss: 1.7050\n",
      "Epoch [21/100], Step [10200/24597], Loss: 1.8830\n",
      "Epoch [21/100], Step [10300/24597], Loss: 1.4799\n",
      "Epoch [21/100], Step [10400/24597], Loss: 1.7929\n",
      "Epoch [21/100], Step [10500/24597], Loss: 1.7033\n",
      "Epoch [21/100], Step [10600/24597], Loss: 1.5760\n",
      "Epoch [21/100], Step [10700/24597], Loss: 1.6205\n",
      "Epoch [21/100], Step [10800/24597], Loss: 1.6062\n",
      "Epoch [21/100], Step [10900/24597], Loss: 1.3557\n",
      "Epoch [21/100], Step [11000/24597], Loss: 1.6951\n",
      "Epoch [21/100], Step [11100/24597], Loss: 1.5946\n",
      "Epoch [21/100], Step [11200/24597], Loss: 1.6190\n",
      "Epoch [21/100], Step [11300/24597], Loss: 1.6698\n",
      "Epoch [21/100], Step [11400/24597], Loss: 1.7780\n",
      "Epoch [21/100], Step [11500/24597], Loss: 1.4905\n",
      "Epoch [21/100], Step [11600/24597], Loss: 1.6658\n",
      "Epoch [21/100], Step [11700/24597], Loss: 1.4159\n",
      "Epoch [21/100], Step [11800/24597], Loss: 1.5120\n",
      "Epoch [21/100], Step [11900/24597], Loss: 1.5523\n",
      "Epoch [21/100], Step [12000/24597], Loss: 1.6301\n",
      "Epoch [21/100], Step [12100/24597], Loss: 1.9749\n",
      "Epoch [21/100], Step [12200/24597], Loss: 1.5154\n",
      "Epoch [21/100], Step [12300/24597], Loss: 1.6202\n",
      "Epoch [21/100], Step [12400/24597], Loss: 1.5816\n",
      "Epoch [21/100], Step [12500/24597], Loss: 1.4984\n",
      "Epoch [21/100], Step [12600/24597], Loss: 1.5731\n",
      "Epoch [21/100], Step [12700/24597], Loss: 1.6139\n",
      "Epoch [21/100], Step [12800/24597], Loss: 1.7280\n",
      "Epoch [21/100], Step [12900/24597], Loss: 1.8634\n",
      "Epoch [21/100], Step [13000/24597], Loss: 1.7081\n",
      "Epoch [21/100], Step [13100/24597], Loss: 1.7365\n",
      "Epoch [21/100], Step [13200/24597], Loss: 1.7809\n",
      "Epoch [21/100], Step [13300/24597], Loss: 1.6238\n",
      "Epoch [21/100], Step [13400/24597], Loss: 1.6423\n",
      "Epoch [21/100], Step [13500/24597], Loss: 1.6160\n",
      "Epoch [21/100], Step [13600/24597], Loss: 1.6849\n",
      "Epoch [21/100], Step [13700/24597], Loss: 1.7044\n",
      "Epoch [21/100], Step [13800/24597], Loss: 1.5292\n",
      "Epoch [21/100], Step [13900/24597], Loss: 1.5831\n",
      "Epoch [21/100], Step [14000/24597], Loss: 1.8052\n",
      "Epoch [21/100], Step [14100/24597], Loss: 1.5137\n",
      "Epoch [21/100], Step [14200/24597], Loss: 1.6449\n",
      "Epoch [21/100], Step [14300/24597], Loss: 1.4940\n",
      "Epoch [21/100], Step [14400/24597], Loss: 1.7924\n",
      "Epoch [21/100], Step [14500/24597], Loss: 1.6244\n",
      "Epoch [21/100], Step [14600/24597], Loss: 1.4973\n",
      "Epoch [21/100], Step [14700/24597], Loss: 1.7979\n",
      "Epoch [21/100], Step [14800/24597], Loss: 1.5444\n",
      "Epoch [21/100], Step [14900/24597], Loss: 1.5778\n",
      "Epoch [21/100], Step [15000/24597], Loss: 1.4552\n",
      "Epoch [21/100], Step [15100/24597], Loss: 1.4947\n",
      "Epoch [21/100], Step [15200/24597], Loss: 1.7376\n",
      "Epoch [21/100], Step [15300/24597], Loss: 1.6382\n",
      "Epoch [21/100], Step [15400/24597], Loss: 1.5496\n",
      "Epoch [21/100], Step [15500/24597], Loss: 1.4627\n",
      "Epoch [21/100], Step [15600/24597], Loss: 1.5059\n",
      "Epoch [21/100], Step [15700/24597], Loss: 1.7600\n",
      "Epoch [21/100], Step [15800/24597], Loss: 1.5445\n",
      "Epoch [21/100], Step [15900/24597], Loss: 1.6510\n",
      "Epoch [21/100], Step [16000/24597], Loss: 1.7130\n",
      "Epoch [21/100], Step [16100/24597], Loss: 1.7471\n",
      "Epoch [21/100], Step [16200/24597], Loss: 1.5547\n",
      "Epoch [21/100], Step [16300/24597], Loss: 1.7942\n",
      "Epoch [21/100], Step [16400/24597], Loss: 1.8568\n",
      "Epoch [21/100], Step [16500/24597], Loss: 1.8234\n",
      "Epoch [21/100], Step [16600/24597], Loss: 1.5936\n",
      "Epoch [21/100], Step [16700/24597], Loss: 1.5754\n",
      "Epoch [21/100], Step [16800/24597], Loss: 1.5509\n",
      "Epoch [21/100], Step [16900/24597], Loss: 1.8351\n",
      "Epoch [21/100], Step [17000/24597], Loss: 1.5575\n",
      "Epoch [21/100], Step [17100/24597], Loss: 1.5699\n",
      "Epoch [21/100], Step [17200/24597], Loss: 1.7074\n",
      "Epoch [21/100], Step [17300/24597], Loss: 1.8039\n",
      "Epoch [21/100], Step [17400/24597], Loss: 1.6595\n",
      "Epoch [21/100], Step [17500/24597], Loss: 1.7378\n",
      "Epoch [21/100], Step [17600/24597], Loss: 1.5660\n",
      "Epoch [21/100], Step [17700/24597], Loss: 1.5013\n",
      "Epoch [21/100], Step [17800/24597], Loss: 1.5617\n",
      "Epoch [21/100], Step [17900/24597], Loss: 1.5194\n",
      "Epoch [21/100], Step [18000/24597], Loss: 1.6286\n",
      "Epoch [21/100], Step [18100/24597], Loss: 1.5831\n",
      "Epoch [21/100], Step [18200/24597], Loss: 1.6149\n",
      "Epoch [21/100], Step [18300/24597], Loss: 1.4276\n",
      "Epoch [21/100], Step [18400/24597], Loss: 1.6286\n",
      "Epoch [21/100], Step [18500/24597], Loss: 1.6296\n",
      "Epoch [21/100], Step [18600/24597], Loss: 1.5598\n",
      "Epoch [21/100], Step [18700/24597], Loss: 1.4844\n",
      "Epoch [21/100], Step [18800/24597], Loss: 1.5810\n",
      "Epoch [21/100], Step [18900/24597], Loss: 1.7365\n",
      "Epoch [21/100], Step [19000/24597], Loss: 1.5993\n",
      "Epoch [21/100], Step [19100/24597], Loss: 1.7173\n",
      "Epoch [21/100], Step [19200/24597], Loss: 1.4287\n",
      "Epoch [21/100], Step [19300/24597], Loss: 1.5220\n",
      "Epoch [21/100], Step [19400/24597], Loss: 1.7276\n",
      "Epoch [21/100], Step [19500/24597], Loss: 1.6808\n",
      "Epoch [21/100], Step [19600/24597], Loss: 1.6049\n",
      "Epoch [21/100], Step [19700/24597], Loss: 1.5625\n",
      "Epoch [21/100], Step [19800/24597], Loss: 1.6099\n",
      "Epoch [21/100], Step [19900/24597], Loss: 1.5927\n",
      "Epoch [21/100], Step [20000/24597], Loss: 1.6310\n",
      "Epoch [21/100], Step [20100/24597], Loss: 1.6620\n",
      "Epoch [21/100], Step [20200/24597], Loss: 1.5962\n",
      "Epoch [21/100], Step [20300/24597], Loss: 1.6286\n",
      "Epoch [21/100], Step [20400/24597], Loss: 1.7417\n",
      "Epoch [21/100], Step [20500/24597], Loss: 1.4261\n",
      "Epoch [21/100], Step [20600/24597], Loss: 1.4851\n",
      "Epoch [21/100], Step [20700/24597], Loss: 1.3894\n",
      "Epoch [21/100], Step [20800/24597], Loss: 1.7591\n",
      "Epoch [21/100], Step [20900/24597], Loss: 1.5946\n",
      "Epoch [21/100], Step [21000/24597], Loss: 1.5513\n",
      "Epoch [21/100], Step [21100/24597], Loss: 1.6534\n",
      "Epoch [21/100], Step [21200/24597], Loss: 1.6840\n",
      "Epoch [21/100], Step [21300/24597], Loss: 1.7336\n",
      "Epoch [21/100], Step [21400/24597], Loss: 1.4193\n",
      "Epoch [21/100], Step [21500/24597], Loss: 1.6560\n",
      "Epoch [21/100], Step [21600/24597], Loss: 1.6300\n",
      "Epoch [21/100], Step [21700/24597], Loss: 1.6524\n",
      "Epoch [21/100], Step [21800/24597], Loss: 1.6875\n",
      "Epoch [21/100], Step [21900/24597], Loss: 1.6502\n",
      "Epoch [21/100], Step [22000/24597], Loss: 1.4641\n",
      "Epoch [21/100], Step [22100/24597], Loss: 1.4686\n",
      "Epoch [21/100], Step [22200/24597], Loss: 1.6723\n",
      "Epoch [21/100], Step [22300/24597], Loss: 1.4548\n",
      "Epoch [21/100], Step [22400/24597], Loss: 1.6936\n",
      "Epoch [21/100], Step [22500/24597], Loss: 1.5697\n",
      "Epoch [21/100], Step [22600/24597], Loss: 1.6096\n",
      "Epoch [21/100], Step [22700/24597], Loss: 1.6052\n",
      "Epoch [21/100], Step [22800/24597], Loss: 1.7196\n",
      "Epoch [21/100], Step [22900/24597], Loss: 1.6134\n",
      "Epoch [21/100], Step [23000/24597], Loss: 1.6310\n",
      "Epoch [21/100], Step [23100/24597], Loss: 1.8568\n",
      "Epoch [21/100], Step [23200/24597], Loss: 1.6677\n",
      "Epoch [21/100], Step [23300/24597], Loss: 1.6494\n",
      "Epoch [21/100], Step [23400/24597], Loss: 1.6500\n",
      "Epoch [21/100], Step [23500/24597], Loss: 1.6649\n",
      "Epoch [21/100], Step [23600/24597], Loss: 1.6296\n",
      "Epoch [21/100], Step [23700/24597], Loss: 1.6583\n",
      "Epoch [21/100], Step [23800/24597], Loss: 1.4366\n",
      "Epoch [21/100], Step [23900/24597], Loss: 1.5598\n",
      "Epoch [21/100], Step [24000/24597], Loss: 1.7698\n",
      "Epoch [21/100], Step [24100/24597], Loss: 1.6124\n",
      "Epoch [21/100], Step [24200/24597], Loss: 1.5469\n",
      "Epoch [21/100], Step [24300/24597], Loss: 1.5161\n",
      "Epoch [21/100], Step [24400/24597], Loss: 1.6147\n",
      "Epoch [21/100], Step [24500/24597], Loss: 1.8730\n",
      "Epoch [22/100], Step [100/24597], Loss: 1.6324\n",
      "Epoch [22/100], Step [200/24597], Loss: 1.5948\n",
      "Epoch [22/100], Step [300/24597], Loss: 1.4614\n",
      "Epoch [22/100], Step [400/24597], Loss: 1.7083\n",
      "Epoch [22/100], Step [500/24597], Loss: 1.7161\n",
      "Epoch [22/100], Step [600/24597], Loss: 1.5082\n",
      "Epoch [22/100], Step [700/24597], Loss: 1.5673\n",
      "Epoch [22/100], Step [800/24597], Loss: 1.7779\n",
      "Epoch [22/100], Step [900/24597], Loss: 1.7010\n",
      "Epoch [22/100], Step [1000/24597], Loss: 1.7016\n",
      "Epoch [22/100], Step [1100/24597], Loss: 1.5923\n",
      "Epoch [22/100], Step [1200/24597], Loss: 1.5837\n",
      "Epoch [22/100], Step [1300/24597], Loss: 1.4095\n",
      "Epoch [22/100], Step [1400/24597], Loss: 1.6320\n",
      "Epoch [22/100], Step [1500/24597], Loss: 1.4505\n",
      "Epoch [22/100], Step [1600/24597], Loss: 1.6139\n",
      "Epoch [22/100], Step [1700/24597], Loss: 1.5781\n",
      "Epoch [22/100], Step [1800/24597], Loss: 1.5486\n",
      "Epoch [22/100], Step [1900/24597], Loss: 1.6894\n",
      "Epoch [22/100], Step [2000/24597], Loss: 1.5393\n",
      "Epoch [22/100], Step [2100/24597], Loss: 1.4090\n",
      "Epoch [22/100], Step [2200/24597], Loss: 1.4683\n",
      "Epoch [22/100], Step [2300/24597], Loss: 1.6474\n",
      "Epoch [22/100], Step [2400/24597], Loss: 1.5666\n",
      "Epoch [22/100], Step [2500/24597], Loss: 1.4191\n",
      "Epoch [22/100], Step [2600/24597], Loss: 1.7008\n",
      "Epoch [22/100], Step [2700/24597], Loss: 1.4862\n",
      "Epoch [22/100], Step [2800/24597], Loss: 1.9026\n",
      "Epoch [22/100], Step [2900/24597], Loss: 1.7000\n",
      "Epoch [22/100], Step [3000/24597], Loss: 1.6107\n",
      "Epoch [22/100], Step [3100/24597], Loss: 1.4333\n",
      "Epoch [22/100], Step [3200/24597], Loss: 1.5762\n",
      "Epoch [22/100], Step [3300/24597], Loss: 1.5607\n",
      "Epoch [22/100], Step [3400/24597], Loss: 1.6931\n",
      "Epoch [22/100], Step [3500/24597], Loss: 1.6777\n",
      "Epoch [22/100], Step [3600/24597], Loss: 1.5396\n",
      "Epoch [22/100], Step [3700/24597], Loss: 1.5185\n",
      "Epoch [22/100], Step [3800/24597], Loss: 1.5173\n",
      "Epoch [22/100], Step [3900/24597], Loss: 1.6690\n",
      "Epoch [22/100], Step [4000/24597], Loss: 1.7421\n",
      "Epoch [22/100], Step [4100/24597], Loss: 1.6859\n",
      "Epoch [22/100], Step [4200/24597], Loss: 1.3358\n",
      "Epoch [22/100], Step [4300/24597], Loss: 1.8015\n",
      "Epoch [22/100], Step [4400/24597], Loss: 1.8130\n",
      "Epoch [22/100], Step [4500/24597], Loss: 1.7655\n",
      "Epoch [22/100], Step [4600/24597], Loss: 1.6263\n",
      "Epoch [22/100], Step [4700/24597], Loss: 1.4800\n",
      "Epoch [22/100], Step [4800/24597], Loss: 1.6725\n",
      "Epoch [22/100], Step [4900/24597], Loss: 1.6754\n",
      "Epoch [22/100], Step [5000/24597], Loss: 1.7009\n",
      "Epoch [22/100], Step [5100/24597], Loss: 1.6416\n",
      "Epoch [22/100], Step [5200/24597], Loss: 1.7648\n",
      "Epoch [22/100], Step [5300/24597], Loss: 1.5514\n",
      "Epoch [22/100], Step [5400/24597], Loss: 1.4748\n",
      "Epoch [22/100], Step [5500/24597], Loss: 1.4372\n",
      "Epoch [22/100], Step [5600/24597], Loss: 1.4841\n",
      "Epoch [22/100], Step [5700/24597], Loss: 1.7681\n",
      "Epoch [22/100], Step [5800/24597], Loss: 1.5133\n",
      "Epoch [22/100], Step [5900/24597], Loss: 1.4929\n",
      "Epoch [22/100], Step [6000/24597], Loss: 1.6702\n",
      "Epoch [22/100], Step [6100/24597], Loss: 1.5708\n",
      "Epoch [22/100], Step [6200/24597], Loss: 1.5635\n",
      "Epoch [22/100], Step [6300/24597], Loss: 1.7840\n",
      "Epoch [22/100], Step [6400/24597], Loss: 1.4749\n",
      "Epoch [22/100], Step [6500/24597], Loss: 1.7108\n",
      "Epoch [22/100], Step [6600/24597], Loss: 1.4965\n",
      "Epoch [22/100], Step [6700/24597], Loss: 1.6710\n",
      "Epoch [22/100], Step [6800/24597], Loss: 1.5123\n",
      "Epoch [22/100], Step [6900/24597], Loss: 1.7512\n",
      "Epoch [22/100], Step [7000/24597], Loss: 1.6433\n",
      "Epoch [22/100], Step [7100/24597], Loss: 1.8103\n",
      "Epoch [22/100], Step [7200/24597], Loss: 1.5100\n",
      "Epoch [22/100], Step [7300/24597], Loss: 1.6412\n",
      "Epoch [22/100], Step [7400/24597], Loss: 1.7018\n",
      "Epoch [22/100], Step [7500/24597], Loss: 1.4134\n",
      "Epoch [22/100], Step [7600/24597], Loss: 1.6312\n",
      "Epoch [22/100], Step [7700/24597], Loss: 1.6641\n",
      "Epoch [22/100], Step [7800/24597], Loss: 1.8337\n",
      "Epoch [22/100], Step [7900/24597], Loss: 1.6200\n",
      "Epoch [22/100], Step [8000/24597], Loss: 1.7403\n",
      "Epoch [22/100], Step [8100/24597], Loss: 1.5987\n",
      "Epoch [22/100], Step [8200/24597], Loss: 1.5344\n",
      "Epoch [22/100], Step [8300/24597], Loss: 1.5557\n",
      "Epoch [22/100], Step [8400/24597], Loss: 1.3830\n",
      "Epoch [22/100], Step [8500/24597], Loss: 1.3982\n",
      "Epoch [22/100], Step [8600/24597], Loss: 1.6097\n",
      "Epoch [22/100], Step [8700/24597], Loss: 1.6329\n",
      "Epoch [22/100], Step [8800/24597], Loss: 1.6332\n",
      "Epoch [22/100], Step [8900/24597], Loss: 1.6192\n",
      "Epoch [22/100], Step [9000/24597], Loss: 1.6312\n",
      "Epoch [22/100], Step [9100/24597], Loss: 1.7343\n",
      "Epoch [22/100], Step [9200/24597], Loss: 1.6571\n",
      "Epoch [22/100], Step [9300/24597], Loss: 1.6526\n",
      "Epoch [22/100], Step [9400/24597], Loss: 1.8860\n",
      "Epoch [22/100], Step [9500/24597], Loss: 1.6128\n",
      "Epoch [22/100], Step [9600/24597], Loss: 1.7462\n",
      "Epoch [22/100], Step [9700/24597], Loss: 1.4958\n",
      "Epoch [22/100], Step [9800/24597], Loss: 1.6629\n",
      "Epoch [22/100], Step [9900/24597], Loss: 1.6636\n",
      "Epoch [22/100], Step [10000/24597], Loss: 1.6561\n",
      "Epoch [22/100], Step [10100/24597], Loss: 1.6340\n",
      "Epoch [22/100], Step [10200/24597], Loss: 1.6713\n",
      "Epoch [22/100], Step [10300/24597], Loss: 1.4609\n",
      "Epoch [22/100], Step [10400/24597], Loss: 1.5078\n",
      "Epoch [22/100], Step [10500/24597], Loss: 1.5302\n",
      "Epoch [22/100], Step [10600/24597], Loss: 1.7770\n",
      "Epoch [22/100], Step [10700/24597], Loss: 1.5728\n",
      "Epoch [22/100], Step [10800/24597], Loss: 1.6021\n",
      "Epoch [22/100], Step [10900/24597], Loss: 1.5982\n",
      "Epoch [22/100], Step [11000/24597], Loss: 1.5133\n",
      "Epoch [22/100], Step [11100/24597], Loss: 1.6971\n",
      "Epoch [22/100], Step [11200/24597], Loss: 1.7360\n",
      "Epoch [22/100], Step [11300/24597], Loss: 1.7351\n",
      "Epoch [22/100], Step [11400/24597], Loss: 1.6420\n",
      "Epoch [22/100], Step [11500/24597], Loss: 1.4479\n",
      "Epoch [22/100], Step [11600/24597], Loss: 1.5405\n",
      "Epoch [22/100], Step [11700/24597], Loss: 1.6061\n",
      "Epoch [22/100], Step [11800/24597], Loss: 1.3676\n",
      "Epoch [22/100], Step [11900/24597], Loss: 1.5387\n",
      "Epoch [22/100], Step [12000/24597], Loss: 1.5734\n",
      "Epoch [22/100], Step [12100/24597], Loss: 1.5238\n",
      "Epoch [22/100], Step [12200/24597], Loss: 1.6744\n",
      "Epoch [22/100], Step [12300/24597], Loss: 1.9023\n",
      "Epoch [22/100], Step [12400/24597], Loss: 1.7610\n",
      "Epoch [22/100], Step [12500/24597], Loss: 1.6796\n",
      "Epoch [22/100], Step [12600/24597], Loss: 1.4733\n",
      "Epoch [22/100], Step [12700/24597], Loss: 1.6154\n",
      "Epoch [22/100], Step [12800/24597], Loss: 1.7171\n",
      "Epoch [22/100], Step [12900/24597], Loss: 1.5596\n",
      "Epoch [22/100], Step [13000/24597], Loss: 2.0196\n",
      "Epoch [22/100], Step [13100/24597], Loss: 1.7470\n",
      "Epoch [22/100], Step [13200/24597], Loss: 1.4068\n",
      "Epoch [22/100], Step [13300/24597], Loss: 1.8953\n",
      "Epoch [22/100], Step [13400/24597], Loss: 1.5500\n",
      "Epoch [22/100], Step [13500/24597], Loss: 1.5231\n",
      "Epoch [22/100], Step [13600/24597], Loss: 1.4864\n",
      "Epoch [22/100], Step [13700/24597], Loss: 1.5749\n",
      "Epoch [22/100], Step [13800/24597], Loss: 1.3588\n",
      "Epoch [22/100], Step [13900/24597], Loss: 1.5992\n",
      "Epoch [22/100], Step [14000/24597], Loss: 1.5989\n",
      "Epoch [22/100], Step [14100/24597], Loss: 1.4020\n",
      "Epoch [22/100], Step [14200/24597], Loss: 1.5878\n",
      "Epoch [22/100], Step [14300/24597], Loss: 1.4136\n",
      "Epoch [22/100], Step [14400/24597], Loss: 1.8739\n",
      "Epoch [22/100], Step [14500/24597], Loss: 1.5252\n",
      "Epoch [22/100], Step [14600/24597], Loss: 1.6612\n",
      "Epoch [22/100], Step [14700/24597], Loss: 1.7159\n",
      "Epoch [22/100], Step [14800/24597], Loss: 1.5902\n",
      "Epoch [22/100], Step [14900/24597], Loss: 1.7604\n",
      "Epoch [22/100], Step [15000/24597], Loss: 1.5139\n",
      "Epoch [22/100], Step [15100/24597], Loss: 1.4373\n",
      "Epoch [22/100], Step [15200/24597], Loss: 1.7266\n",
      "Epoch [22/100], Step [15300/24597], Loss: 1.7767\n",
      "Epoch [22/100], Step [15400/24597], Loss: 1.4614\n",
      "Epoch [22/100], Step [15500/24597], Loss: 1.6466\n",
      "Epoch [22/100], Step [15600/24597], Loss: 1.7475\n",
      "Epoch [22/100], Step [15700/24597], Loss: 1.6586\n",
      "Epoch [22/100], Step [15800/24597], Loss: 1.5238\n",
      "Epoch [22/100], Step [15900/24597], Loss: 1.7770\n",
      "Epoch [22/100], Step [16000/24597], Loss: 1.5287\n",
      "Epoch [22/100], Step [16100/24597], Loss: 1.4641\n",
      "Epoch [22/100], Step [16200/24597], Loss: 1.6233\n",
      "Epoch [22/100], Step [16300/24597], Loss: 1.6851\n",
      "Epoch [22/100], Step [16400/24597], Loss: 1.6016\n",
      "Epoch [22/100], Step [16500/24597], Loss: 1.4479\n",
      "Epoch [22/100], Step [16600/24597], Loss: 1.7186\n",
      "Epoch [22/100], Step [16700/24597], Loss: 1.4846\n",
      "Epoch [22/100], Step [16800/24597], Loss: 1.7051\n",
      "Epoch [22/100], Step [16900/24597], Loss: 1.4919\n",
      "Epoch [22/100], Step [17000/24597], Loss: 1.6122\n",
      "Epoch [22/100], Step [17100/24597], Loss: 1.6322\n",
      "Epoch [22/100], Step [17200/24597], Loss: 1.5430\n",
      "Epoch [22/100], Step [17300/24597], Loss: 1.7365\n",
      "Epoch [22/100], Step [17400/24597], Loss: 1.5605\n",
      "Epoch [22/100], Step [17500/24597], Loss: 1.6775\n",
      "Epoch [22/100], Step [17600/24597], Loss: 1.5773\n",
      "Epoch [22/100], Step [17700/24597], Loss: 1.8795\n",
      "Epoch [22/100], Step [17800/24597], Loss: 1.5349\n",
      "Epoch [22/100], Step [17900/24597], Loss: 1.3840\n",
      "Epoch [22/100], Step [18000/24597], Loss: 1.4812\n",
      "Epoch [22/100], Step [18100/24597], Loss: 1.4564\n",
      "Epoch [22/100], Step [18200/24597], Loss: 1.7110\n",
      "Epoch [22/100], Step [18300/24597], Loss: 1.5836\n",
      "Epoch [22/100], Step [18400/24597], Loss: 1.8650\n",
      "Epoch [22/100], Step [18500/24597], Loss: 1.4224\n",
      "Epoch [22/100], Step [18600/24597], Loss: 1.7692\n",
      "Epoch [22/100], Step [18700/24597], Loss: 1.7471\n",
      "Epoch [22/100], Step [18800/24597], Loss: 1.6303\n",
      "Epoch [22/100], Step [18900/24597], Loss: 1.7367\n",
      "Epoch [22/100], Step [19000/24597], Loss: 1.5399\n",
      "Epoch [22/100], Step [19100/24597], Loss: 1.5194\n",
      "Epoch [22/100], Step [19200/24597], Loss: 1.7079\n",
      "Epoch [22/100], Step [19300/24597], Loss: 1.5641\n",
      "Epoch [22/100], Step [19400/24597], Loss: 1.6672\n",
      "Epoch [22/100], Step [19500/24597], Loss: 1.4589\n",
      "Epoch [22/100], Step [19600/24597], Loss: 1.5321\n",
      "Epoch [22/100], Step [19700/24597], Loss: 1.6132\n",
      "Epoch [22/100], Step [19800/24597], Loss: 1.8828\n",
      "Epoch [22/100], Step [19900/24597], Loss: 1.6695\n",
      "Epoch [22/100], Step [20000/24597], Loss: 1.6136\n",
      "Epoch [22/100], Step [20100/24597], Loss: 1.6026\n",
      "Epoch [22/100], Step [20200/24597], Loss: 1.6307\n",
      "Epoch [22/100], Step [20300/24597], Loss: 1.8239\n",
      "Epoch [22/100], Step [20400/24597], Loss: 1.6618\n",
      "Epoch [22/100], Step [20500/24597], Loss: 1.8745\n",
      "Epoch [22/100], Step [20600/24597], Loss: 1.5676\n",
      "Epoch [22/100], Step [20700/24597], Loss: 1.3188\n",
      "Epoch [22/100], Step [20800/24597], Loss: 1.5845\n",
      "Epoch [22/100], Step [20900/24597], Loss: 1.3420\n",
      "Epoch [22/100], Step [21000/24597], Loss: 1.5422\n",
      "Epoch [22/100], Step [21100/24597], Loss: 1.7220\n",
      "Epoch [22/100], Step [21200/24597], Loss: 1.7349\n",
      "Epoch [22/100], Step [21300/24597], Loss: 1.4888\n",
      "Epoch [22/100], Step [21400/24597], Loss: 1.5144\n",
      "Epoch [22/100], Step [21500/24597], Loss: 1.5619\n",
      "Epoch [22/100], Step [21600/24597], Loss: 1.5472\n",
      "Epoch [22/100], Step [21700/24597], Loss: 1.7994\n",
      "Epoch [22/100], Step [21800/24597], Loss: 1.5751\n",
      "Epoch [22/100], Step [21900/24597], Loss: 1.6591\n",
      "Epoch [22/100], Step [22000/24597], Loss: 1.7584\n",
      "Epoch [22/100], Step [22100/24597], Loss: 1.5916\n",
      "Epoch [22/100], Step [22200/24597], Loss: 1.6252\n",
      "Epoch [22/100], Step [22300/24597], Loss: 1.6014\n",
      "Epoch [22/100], Step [22400/24597], Loss: 1.6224\n",
      "Epoch [22/100], Step [22500/24597], Loss: 1.7317\n",
      "Epoch [22/100], Step [22600/24597], Loss: 1.9239\n",
      "Epoch [22/100], Step [22700/24597], Loss: 1.5534\n",
      "Epoch [22/100], Step [22800/24597], Loss: 1.4951\n",
      "Epoch [22/100], Step [22900/24597], Loss: 1.6028\n",
      "Epoch [22/100], Step [23000/24597], Loss: 1.5671\n",
      "Epoch [22/100], Step [23100/24597], Loss: 1.6855\n",
      "Epoch [22/100], Step [23200/24597], Loss: 1.5407\n",
      "Epoch [22/100], Step [23300/24597], Loss: 1.7326\n",
      "Epoch [22/100], Step [23400/24597], Loss: 1.6320\n",
      "Epoch [22/100], Step [23500/24597], Loss: 1.5377\n",
      "Epoch [22/100], Step [23600/24597], Loss: 1.5827\n",
      "Epoch [22/100], Step [23700/24597], Loss: 1.6972\n",
      "Epoch [22/100], Step [23800/24597], Loss: 1.8696\n",
      "Epoch [22/100], Step [23900/24597], Loss: 1.7597\n",
      "Epoch [22/100], Step [24000/24597], Loss: 1.5375\n",
      "Epoch [22/100], Step [24100/24597], Loss: 1.7235\n",
      "Epoch [22/100], Step [24200/24597], Loss: 1.7845\n",
      "Epoch [22/100], Step [24300/24597], Loss: 1.8100\n",
      "Epoch [22/100], Step [24400/24597], Loss: 1.7727\n",
      "Epoch [22/100], Step [24500/24597], Loss: 1.3371\n",
      "Epoch [23/100], Step [100/24597], Loss: 1.5395\n",
      "Epoch [23/100], Step [200/24597], Loss: 1.5564\n",
      "Epoch [23/100], Step [300/24597], Loss: 1.5586\n",
      "Epoch [23/100], Step [400/24597], Loss: 1.3552\n",
      "Epoch [23/100], Step [500/24597], Loss: 1.4294\n",
      "Epoch [23/100], Step [600/24597], Loss: 1.4435\n",
      "Epoch [23/100], Step [700/24597], Loss: 1.6587\n",
      "Epoch [23/100], Step [800/24597], Loss: 1.5471\n",
      "Epoch [23/100], Step [900/24597], Loss: 1.7156\n",
      "Epoch [23/100], Step [1000/24597], Loss: 1.6268\n",
      "Epoch [23/100], Step [1100/24597], Loss: 1.7719\n",
      "Epoch [23/100], Step [1200/24597], Loss: 1.6084\n",
      "Epoch [23/100], Step [1300/24597], Loss: 1.5392\n",
      "Epoch [23/100], Step [1400/24597], Loss: 1.3578\n",
      "Epoch [23/100], Step [1500/24597], Loss: 1.7382\n",
      "Epoch [23/100], Step [1600/24597], Loss: 1.7897\n",
      "Epoch [23/100], Step [1700/24597], Loss: 1.5479\n",
      "Epoch [23/100], Step [1800/24597], Loss: 1.6384\n",
      "Epoch [23/100], Step [1900/24597], Loss: 1.5933\n",
      "Epoch [23/100], Step [2000/24597], Loss: 1.5381\n",
      "Epoch [23/100], Step [2100/24597], Loss: 1.4103\n",
      "Epoch [23/100], Step [2200/24597], Loss: 1.6827\n",
      "Epoch [23/100], Step [2300/24597], Loss: 1.6149\n",
      "Epoch [23/100], Step [2400/24597], Loss: 1.7299\n",
      "Epoch [23/100], Step [2500/24597], Loss: 1.4901\n",
      "Epoch [23/100], Step [2600/24597], Loss: 1.7406\n",
      "Epoch [23/100], Step [2700/24597], Loss: 1.7399\n",
      "Epoch [23/100], Step [2800/24597], Loss: 1.6307\n",
      "Epoch [23/100], Step [2900/24597], Loss: 1.6207\n",
      "Epoch [23/100], Step [3000/24597], Loss: 1.5727\n",
      "Epoch [23/100], Step [3100/24597], Loss: 1.8101\n",
      "Epoch [23/100], Step [3200/24597], Loss: 1.4073\n",
      "Epoch [23/100], Step [3300/24597], Loss: 1.5203\n",
      "Epoch [23/100], Step [3400/24597], Loss: 1.6013\n",
      "Epoch [23/100], Step [3500/24597], Loss: 1.5603\n",
      "Epoch [23/100], Step [3600/24597], Loss: 1.6485\n",
      "Epoch [23/100], Step [3700/24597], Loss: 1.7075\n",
      "Epoch [23/100], Step [3800/24597], Loss: 1.6038\n",
      "Epoch [23/100], Step [3900/24597], Loss: 1.6621\n",
      "Epoch [23/100], Step [4000/24597], Loss: 1.6510\n",
      "Epoch [23/100], Step [4100/24597], Loss: 1.5454\n",
      "Epoch [23/100], Step [4200/24597], Loss: 1.6905\n",
      "Epoch [23/100], Step [4300/24597], Loss: 1.8049\n",
      "Epoch [23/100], Step [4400/24597], Loss: 1.7582\n",
      "Epoch [23/100], Step [4500/24597], Loss: 1.3967\n",
      "Epoch [23/100], Step [4600/24597], Loss: 1.4389\n",
      "Epoch [23/100], Step [4700/24597], Loss: 1.4868\n",
      "Epoch [23/100], Step [4800/24597], Loss: 1.7807\n",
      "Epoch [23/100], Step [4900/24597], Loss: 1.6529\n",
      "Epoch [23/100], Step [5000/24597], Loss: 1.7230\n",
      "Epoch [23/100], Step [5100/24597], Loss: 1.6106\n",
      "Epoch [23/100], Step [5200/24597], Loss: 1.5388\n",
      "Epoch [23/100], Step [5300/24597], Loss: 1.6598\n",
      "Epoch [23/100], Step [5400/24597], Loss: 1.5948\n",
      "Epoch [23/100], Step [5500/24597], Loss: 1.6824\n",
      "Epoch [23/100], Step [5600/24597], Loss: 1.6922\n",
      "Epoch [23/100], Step [5700/24597], Loss: 1.8014\n",
      "Epoch [23/100], Step [5800/24597], Loss: 1.6190\n",
      "Epoch [23/100], Step [5900/24597], Loss: 1.5283\n",
      "Epoch [23/100], Step [6000/24597], Loss: 1.7969\n",
      "Epoch [23/100], Step [6100/24597], Loss: 1.6896\n",
      "Epoch [23/100], Step [6200/24597], Loss: 1.5170\n",
      "Epoch [23/100], Step [6300/24597], Loss: 1.3289\n",
      "Epoch [23/100], Step [6400/24597], Loss: 1.7259\n",
      "Epoch [23/100], Step [6500/24597], Loss: 1.6287\n",
      "Epoch [23/100], Step [6600/24597], Loss: 1.5693\n",
      "Epoch [23/100], Step [6700/24597], Loss: 1.5540\n",
      "Epoch [23/100], Step [6800/24597], Loss: 1.4481\n",
      "Epoch [23/100], Step [6900/24597], Loss: 1.7427\n",
      "Epoch [23/100], Step [7000/24597], Loss: 1.4156\n",
      "Epoch [23/100], Step [7100/24597], Loss: 1.6583\n",
      "Epoch [23/100], Step [7200/24597], Loss: 1.6092\n",
      "Epoch [23/100], Step [7300/24597], Loss: 1.5216\n",
      "Epoch [23/100], Step [7400/24597], Loss: 1.6870\n",
      "Epoch [23/100], Step [7500/24597], Loss: 1.4335\n",
      "Epoch [23/100], Step [7600/24597], Loss: 1.6992\n",
      "Epoch [23/100], Step [7700/24597], Loss: 1.6653\n",
      "Epoch [23/100], Step [7800/24597], Loss: 1.5894\n",
      "Epoch [23/100], Step [7900/24597], Loss: 1.5717\n",
      "Epoch [23/100], Step [8000/24597], Loss: 1.6188\n",
      "Epoch [23/100], Step [8100/24597], Loss: 1.5701\n",
      "Epoch [23/100], Step [8200/24597], Loss: 1.3397\n",
      "Epoch [23/100], Step [8300/24597], Loss: 1.4941\n",
      "Epoch [23/100], Step [8400/24597], Loss: 1.8042\n",
      "Epoch [23/100], Step [8500/24597], Loss: 1.4080\n",
      "Epoch [23/100], Step [8600/24597], Loss: 1.7541\n",
      "Epoch [23/100], Step [8700/24597], Loss: 1.4570\n",
      "Epoch [23/100], Step [8800/24597], Loss: 1.5414\n",
      "Epoch [23/100], Step [8900/24597], Loss: 1.6174\n",
      "Epoch [23/100], Step [9000/24597], Loss: 1.5216\n",
      "Epoch [23/100], Step [9100/24597], Loss: 1.4169\n",
      "Epoch [23/100], Step [9200/24597], Loss: 1.4468\n",
      "Epoch [23/100], Step [9300/24597], Loss: 1.6181\n",
      "Epoch [23/100], Step [9400/24597], Loss: 1.6534\n",
      "Epoch [23/100], Step [9500/24597], Loss: 1.7848\n",
      "Epoch [23/100], Step [9600/24597], Loss: 1.6170\n",
      "Epoch [23/100], Step [9700/24597], Loss: 1.5165\n",
      "Epoch [23/100], Step [9800/24597], Loss: 1.7222\n",
      "Epoch [23/100], Step [9900/24597], Loss: 1.5462\n",
      "Epoch [23/100], Step [10000/24597], Loss: 1.7675\n",
      "Epoch [23/100], Step [10100/24597], Loss: 1.5480\n",
      "Epoch [23/100], Step [10200/24597], Loss: 1.5476\n",
      "Epoch [23/100], Step [10300/24597], Loss: 1.5845\n",
      "Epoch [23/100], Step [10400/24597], Loss: 1.8035\n",
      "Epoch [23/100], Step [10500/24597], Loss: 1.3160\n",
      "Epoch [23/100], Step [10600/24597], Loss: 1.4511\n",
      "Epoch [23/100], Step [10700/24597], Loss: 1.7430\n",
      "Epoch [23/100], Step [10800/24597], Loss: 1.5664\n",
      "Epoch [23/100], Step [10900/24597], Loss: 1.5060\n",
      "Epoch [23/100], Step [11000/24597], Loss: 1.6702\n",
      "Epoch [23/100], Step [11100/24597], Loss: 1.5705\n",
      "Epoch [23/100], Step [11200/24597], Loss: 1.6005\n",
      "Epoch [23/100], Step [11300/24597], Loss: 1.8048\n",
      "Epoch [23/100], Step [11400/24597], Loss: 1.4485\n",
      "Epoch [23/100], Step [11500/24597], Loss: 1.7265\n",
      "Epoch [23/100], Step [11600/24597], Loss: 1.4362\n",
      "Epoch [23/100], Step [11700/24597], Loss: 1.6252\n",
      "Epoch [23/100], Step [11800/24597], Loss: 1.6831\n",
      "Epoch [23/100], Step [11900/24597], Loss: 1.7756\n",
      "Epoch [23/100], Step [12000/24597], Loss: 1.5950\n",
      "Epoch [23/100], Step [12100/24597], Loss: 1.6498\n",
      "Epoch [23/100], Step [12200/24597], Loss: 1.7008\n",
      "Epoch [23/100], Step [12300/24597], Loss: 1.4400\n",
      "Epoch [23/100], Step [12400/24597], Loss: 1.4739\n",
      "Epoch [23/100], Step [12500/24597], Loss: 1.4295\n",
      "Epoch [23/100], Step [12600/24597], Loss: 1.6490\n",
      "Epoch [23/100], Step [12700/24597], Loss: 1.5134\n",
      "Epoch [23/100], Step [12800/24597], Loss: 1.7018\n",
      "Epoch [23/100], Step [12900/24597], Loss: 1.5801\n",
      "Epoch [23/100], Step [13000/24597], Loss: 1.8191\n",
      "Epoch [23/100], Step [13100/24597], Loss: 1.3753\n",
      "Epoch [23/100], Step [13200/24597], Loss: 1.5613\n",
      "Epoch [23/100], Step [13300/24597], Loss: 1.5429\n",
      "Epoch [23/100], Step [13400/24597], Loss: 1.8685\n",
      "Epoch [23/100], Step [13500/24597], Loss: 1.7407\n",
      "Epoch [23/100], Step [13600/24597], Loss: 1.7473\n",
      "Epoch [23/100], Step [13700/24597], Loss: 1.4148\n",
      "Epoch [23/100], Step [13800/24597], Loss: 1.5820\n",
      "Epoch [23/100], Step [13900/24597], Loss: 1.6254\n",
      "Epoch [23/100], Step [14000/24597], Loss: 1.5480\n",
      "Epoch [23/100], Step [14100/24597], Loss: 1.6974\n",
      "Epoch [23/100], Step [14200/24597], Loss: 1.3902\n",
      "Epoch [23/100], Step [14300/24597], Loss: 1.5421\n",
      "Epoch [23/100], Step [14400/24597], Loss: 1.6238\n",
      "Epoch [23/100], Step [14500/24597], Loss: 1.5675\n",
      "Epoch [23/100], Step [14600/24597], Loss: 1.6861\n",
      "Epoch [23/100], Step [14700/24597], Loss: 1.5058\n",
      "Epoch [23/100], Step [14800/24597], Loss: 1.6474\n",
      "Epoch [23/100], Step [14900/24597], Loss: 1.7287\n",
      "Epoch [23/100], Step [15000/24597], Loss: 1.5273\n",
      "Epoch [23/100], Step [15100/24597], Loss: 1.5680\n",
      "Epoch [23/100], Step [15200/24597], Loss: 1.7854\n",
      "Epoch [23/100], Step [15300/24597], Loss: 1.7160\n",
      "Epoch [23/100], Step [15400/24597], Loss: 1.7148\n",
      "Epoch [23/100], Step [15500/24597], Loss: 1.6044\n",
      "Epoch [23/100], Step [15600/24597], Loss: 1.7567\n",
      "Epoch [23/100], Step [15700/24597], Loss: 1.8202\n",
      "Epoch [23/100], Step [15800/24597], Loss: 1.7266\n",
      "Epoch [23/100], Step [15900/24597], Loss: 1.6219\n",
      "Epoch [23/100], Step [16000/24597], Loss: 1.8539\n",
      "Epoch [23/100], Step [16100/24597], Loss: 1.7768\n",
      "Epoch [23/100], Step [16200/24597], Loss: 1.5852\n",
      "Epoch [23/100], Step [16300/24597], Loss: 1.7768\n",
      "Epoch [23/100], Step [16400/24597], Loss: 1.6068\n",
      "Epoch [23/100], Step [16500/24597], Loss: 1.5275\n",
      "Epoch [23/100], Step [16600/24597], Loss: 1.6858\n",
      "Epoch [23/100], Step [16700/24597], Loss: 1.5295\n",
      "Epoch [23/100], Step [16800/24597], Loss: 1.8562\n",
      "Epoch [23/100], Step [16900/24597], Loss: 1.7134\n",
      "Epoch [23/100], Step [17000/24597], Loss: 1.5399\n",
      "Epoch [23/100], Step [17100/24597], Loss: 1.6223\n",
      "Epoch [23/100], Step [17200/24597], Loss: 1.5647\n",
      "Epoch [23/100], Step [17300/24597], Loss: 1.5061\n",
      "Epoch [23/100], Step [17400/24597], Loss: 1.7202\n",
      "Epoch [23/100], Step [17500/24597], Loss: 1.6850\n",
      "Epoch [23/100], Step [17600/24597], Loss: 1.6040\n",
      "Epoch [23/100], Step [17700/24597], Loss: 1.9297\n",
      "Epoch [23/100], Step [17800/24597], Loss: 1.7037\n",
      "Epoch [23/100], Step [17900/24597], Loss: 1.5115\n",
      "Epoch [23/100], Step [18000/24597], Loss: 1.8648\n",
      "Epoch [23/100], Step [18100/24597], Loss: 1.7644\n",
      "Epoch [23/100], Step [18200/24597], Loss: 1.8261\n",
      "Epoch [23/100], Step [18300/24597], Loss: 1.7908\n",
      "Epoch [23/100], Step [18400/24597], Loss: 1.6749\n",
      "Epoch [23/100], Step [18500/24597], Loss: 1.5101\n",
      "Epoch [23/100], Step [18600/24597], Loss: 1.3933\n",
      "Epoch [23/100], Step [18700/24597], Loss: 1.7315\n",
      "Epoch [23/100], Step [18800/24597], Loss: 1.7480\n",
      "Epoch [23/100], Step [18900/24597], Loss: 1.6012\n",
      "Epoch [23/100], Step [19000/24597], Loss: 1.5366\n",
      "Epoch [23/100], Step [19100/24597], Loss: 1.6231\n",
      "Epoch [23/100], Step [19200/24597], Loss: 1.7136\n",
      "Epoch [23/100], Step [19300/24597], Loss: 1.4825\n",
      "Epoch [23/100], Step [19400/24597], Loss: 1.7253\n",
      "Epoch [23/100], Step [19500/24597], Loss: 1.6837\n",
      "Epoch [23/100], Step [19600/24597], Loss: 1.7676\n",
      "Epoch [23/100], Step [19700/24597], Loss: 1.4677\n",
      "Epoch [23/100], Step [19800/24597], Loss: 1.5245\n",
      "Epoch [23/100], Step [19900/24597], Loss: 1.5890\n",
      "Epoch [23/100], Step [20000/24597], Loss: 1.5265\n",
      "Epoch [23/100], Step [20100/24597], Loss: 1.4652\n",
      "Epoch [23/100], Step [20200/24597], Loss: 1.6604\n",
      "Epoch [23/100], Step [20300/24597], Loss: 1.5403\n",
      "Epoch [23/100], Step [20400/24597], Loss: 1.5492\n",
      "Epoch [23/100], Step [20500/24597], Loss: 1.3500\n",
      "Epoch [23/100], Step [20600/24597], Loss: 1.5389\n",
      "Epoch [23/100], Step [20700/24597], Loss: 1.7260\n",
      "Epoch [23/100], Step [20800/24597], Loss: 1.6428\n",
      "Epoch [23/100], Step [20900/24597], Loss: 1.5317\n",
      "Epoch [23/100], Step [21000/24597], Loss: 1.7747\n",
      "Epoch [23/100], Step [21100/24597], Loss: 1.4807\n",
      "Epoch [23/100], Step [21200/24597], Loss: 1.7447\n",
      "Epoch [23/100], Step [21300/24597], Loss: 1.5115\n",
      "Epoch [23/100], Step [21400/24597], Loss: 1.5371\n",
      "Epoch [23/100], Step [21500/24597], Loss: 1.5714\n",
      "Epoch [23/100], Step [21600/24597], Loss: 1.6075\n",
      "Epoch [23/100], Step [21700/24597], Loss: 1.5798\n",
      "Epoch [23/100], Step [21800/24597], Loss: 1.6148\n",
      "Epoch [23/100], Step [21900/24597], Loss: 1.6876\n",
      "Epoch [23/100], Step [22000/24597], Loss: 1.5473\n",
      "Epoch [23/100], Step [22100/24597], Loss: 1.5172\n",
      "Epoch [23/100], Step [22200/24597], Loss: 1.5192\n",
      "Epoch [23/100], Step [22300/24597], Loss: 1.2287\n",
      "Epoch [23/100], Step [22400/24597], Loss: 1.5147\n",
      "Epoch [23/100], Step [22500/24597], Loss: 1.7517\n",
      "Epoch [23/100], Step [22600/24597], Loss: 1.6557\n",
      "Epoch [23/100], Step [22700/24597], Loss: 1.5394\n",
      "Epoch [23/100], Step [22800/24597], Loss: 1.8218\n",
      "Epoch [23/100], Step [22900/24597], Loss: 1.7040\n",
      "Epoch [23/100], Step [23000/24597], Loss: 1.5052\n",
      "Epoch [23/100], Step [23100/24597], Loss: 1.7793\n",
      "Epoch [23/100], Step [23200/24597], Loss: 1.6622\n",
      "Epoch [23/100], Step [23300/24597], Loss: 1.5452\n",
      "Epoch [23/100], Step [23400/24597], Loss: 1.7054\n",
      "Epoch [23/100], Step [23500/24597], Loss: 1.5610\n",
      "Epoch [23/100], Step [23600/24597], Loss: 1.6330\n",
      "Epoch [23/100], Step [23700/24597], Loss: 1.7761\n",
      "Epoch [23/100], Step [23800/24597], Loss: 1.5556\n",
      "Epoch [23/100], Step [23900/24597], Loss: 1.7467\n",
      "Epoch [23/100], Step [24000/24597], Loss: 1.5973\n",
      "Epoch [23/100], Step [24100/24597], Loss: 1.4864\n",
      "Epoch [23/100], Step [24200/24597], Loss: 1.6443\n",
      "Epoch [23/100], Step [24300/24597], Loss: 1.6016\n",
      "Epoch [23/100], Step [24400/24597], Loss: 1.8201\n",
      "Epoch [23/100], Step [24500/24597], Loss: 1.4292\n",
      "Epoch [24/100], Step [100/24597], Loss: 1.6195\n",
      "Epoch [24/100], Step [200/24597], Loss: 1.5289\n",
      "Epoch [24/100], Step [300/24597], Loss: 1.6244\n",
      "Epoch [24/100], Step [400/24597], Loss: 1.5139\n",
      "Epoch [24/100], Step [500/24597], Loss: 1.9352\n",
      "Epoch [24/100], Step [600/24597], Loss: 1.6402\n",
      "Epoch [24/100], Step [700/24597], Loss: 1.7079\n",
      "Epoch [24/100], Step [800/24597], Loss: 1.5562\n",
      "Epoch [24/100], Step [900/24597], Loss: 1.4696\n",
      "Epoch [24/100], Step [1000/24597], Loss: 1.6862\n",
      "Epoch [24/100], Step [1100/24597], Loss: 1.3412\n",
      "Epoch [24/100], Step [1200/24597], Loss: 1.7193\n",
      "Epoch [24/100], Step [1300/24597], Loss: 1.7979\n",
      "Epoch [24/100], Step [1400/24597], Loss: 1.6935\n",
      "Epoch [24/100], Step [1500/24597], Loss: 1.7106\n",
      "Epoch [24/100], Step [1600/24597], Loss: 1.5979\n",
      "Epoch [24/100], Step [1700/24597], Loss: 1.6632\n",
      "Epoch [24/100], Step [1800/24597], Loss: 1.4999\n",
      "Epoch [24/100], Step [1900/24597], Loss: 1.9078\n",
      "Epoch [24/100], Step [2000/24597], Loss: 1.5912\n",
      "Epoch [24/100], Step [2100/24597], Loss: 1.5252\n",
      "Epoch [24/100], Step [2200/24597], Loss: 1.7218\n",
      "Epoch [24/100], Step [2300/24597], Loss: 1.6288\n",
      "Epoch [24/100], Step [2400/24597], Loss: 1.7001\n",
      "Epoch [24/100], Step [2500/24597], Loss: 1.6374\n",
      "Epoch [24/100], Step [2600/24597], Loss: 1.6538\n",
      "Epoch [24/100], Step [2700/24597], Loss: 1.6713\n",
      "Epoch [24/100], Step [2800/24597], Loss: 1.7286\n",
      "Epoch [24/100], Step [2900/24597], Loss: 1.6441\n",
      "Epoch [24/100], Step [3000/24597], Loss: 1.5399\n",
      "Epoch [24/100], Step [3100/24597], Loss: 1.6283\n",
      "Epoch [24/100], Step [3200/24597], Loss: 1.4690\n",
      "Epoch [24/100], Step [3300/24597], Loss: 1.6423\n",
      "Epoch [24/100], Step [3400/24597], Loss: 1.4878\n",
      "Epoch [24/100], Step [3500/24597], Loss: 1.6881\n",
      "Epoch [24/100], Step [3600/24597], Loss: 1.4273\n",
      "Epoch [24/100], Step [3700/24597], Loss: 1.4326\n",
      "Epoch [24/100], Step [3800/24597], Loss: 1.6278\n",
      "Epoch [24/100], Step [3900/24597], Loss: 1.6887\n",
      "Epoch [24/100], Step [4000/24597], Loss: 1.6524\n",
      "Epoch [24/100], Step [4100/24597], Loss: 1.5851\n",
      "Epoch [24/100], Step [4200/24597], Loss: 1.7024\n",
      "Epoch [24/100], Step [4300/24597], Loss: 1.5824\n",
      "Epoch [24/100], Step [4400/24597], Loss: 1.6894\n",
      "Epoch [24/100], Step [4500/24597], Loss: 1.7087\n",
      "Epoch [24/100], Step [4600/24597], Loss: 1.6916\n",
      "Epoch [24/100], Step [4700/24597], Loss: 1.6655\n",
      "Epoch [24/100], Step [4800/24597], Loss: 1.6273\n",
      "Epoch [24/100], Step [4900/24597], Loss: 1.6076\n",
      "Epoch [24/100], Step [5000/24597], Loss: 1.6803\n",
      "Epoch [24/100], Step [5100/24597], Loss: 1.4479\n",
      "Epoch [24/100], Step [5200/24597], Loss: 1.5718\n",
      "Epoch [24/100], Step [5300/24597], Loss: 1.7389\n",
      "Epoch [24/100], Step [5400/24597], Loss: 1.8169\n",
      "Epoch [24/100], Step [5500/24597], Loss: 1.8104\n",
      "Epoch [24/100], Step [5600/24597], Loss: 1.4696\n",
      "Epoch [24/100], Step [5700/24597], Loss: 1.4525\n",
      "Epoch [24/100], Step [5800/24597], Loss: 1.4827\n",
      "Epoch [24/100], Step [5900/24597], Loss: 1.5087\n",
      "Epoch [24/100], Step [6000/24597], Loss: 1.6080\n",
      "Epoch [24/100], Step [6100/24597], Loss: 1.5162\n",
      "Epoch [24/100], Step [6200/24597], Loss: 1.5827\n",
      "Epoch [24/100], Step [6300/24597], Loss: 1.6153\n",
      "Epoch [24/100], Step [6400/24597], Loss: 1.6827\n",
      "Epoch [24/100], Step [6500/24597], Loss: 1.5887\n",
      "Epoch [24/100], Step [6600/24597], Loss: 1.7299\n",
      "Epoch [24/100], Step [6700/24597], Loss: 1.6782\n",
      "Epoch [24/100], Step [6800/24597], Loss: 1.9087\n",
      "Epoch [24/100], Step [6900/24597], Loss: 1.7020\n",
      "Epoch [24/100], Step [7000/24597], Loss: 1.6153\n",
      "Epoch [24/100], Step [7100/24597], Loss: 1.5760\n",
      "Epoch [24/100], Step [7200/24597], Loss: 1.5900\n",
      "Epoch [24/100], Step [7300/24597], Loss: 1.6309\n",
      "Epoch [24/100], Step [7400/24597], Loss: 1.7325\n",
      "Epoch [24/100], Step [7500/24597], Loss: 1.7901\n",
      "Epoch [24/100], Step [7600/24597], Loss: 1.7892\n",
      "Epoch [24/100], Step [7700/24597], Loss: 1.6584\n",
      "Epoch [24/100], Step [7800/24597], Loss: 1.4456\n",
      "Epoch [24/100], Step [7900/24597], Loss: 1.5336\n",
      "Epoch [24/100], Step [8000/24597], Loss: 1.8235\n",
      "Epoch [24/100], Step [8100/24597], Loss: 1.5785\n",
      "Epoch [24/100], Step [8200/24597], Loss: 1.5132\n",
      "Epoch [24/100], Step [8300/24597], Loss: 1.6185\n",
      "Epoch [24/100], Step [8400/24597], Loss: 1.6534\n",
      "Epoch [24/100], Step [8500/24597], Loss: 1.3595\n",
      "Epoch [24/100], Step [8600/24597], Loss: 1.4854\n",
      "Epoch [24/100], Step [8700/24597], Loss: 1.6646\n",
      "Epoch [24/100], Step [8800/24597], Loss: 1.6238\n",
      "Epoch [24/100], Step [8900/24597], Loss: 1.6540\n",
      "Epoch [24/100], Step [9000/24597], Loss: 1.5480\n",
      "Epoch [24/100], Step [9100/24597], Loss: 1.6199\n",
      "Epoch [24/100], Step [9200/24597], Loss: 1.9193\n",
      "Epoch [24/100], Step [9300/24597], Loss: 1.4237\n",
      "Epoch [24/100], Step [9400/24597], Loss: 1.6118\n",
      "Epoch [24/100], Step [9500/24597], Loss: 1.7314\n",
      "Epoch [24/100], Step [9600/24597], Loss: 1.4898\n",
      "Epoch [24/100], Step [9700/24597], Loss: 1.4652\n",
      "Epoch [24/100], Step [9800/24597], Loss: 1.5663\n",
      "Epoch [24/100], Step [9900/24597], Loss: 1.4055\n",
      "Epoch [24/100], Step [10000/24597], Loss: 1.6545\n",
      "Epoch [24/100], Step [10100/24597], Loss: 1.6270\n",
      "Epoch [24/100], Step [10200/24597], Loss: 1.5396\n",
      "Epoch [24/100], Step [10300/24597], Loss: 1.7047\n",
      "Epoch [24/100], Step [10400/24597], Loss: 1.8015\n",
      "Epoch [24/100], Step [10500/24597], Loss: 1.6231\n",
      "Epoch [24/100], Step [10600/24597], Loss: 1.7256\n",
      "Epoch [24/100], Step [10700/24597], Loss: 1.4368\n",
      "Epoch [24/100], Step [10800/24597], Loss: 1.7858\n",
      "Epoch [24/100], Step [10900/24597], Loss: 1.8395\n",
      "Epoch [24/100], Step [11000/24597], Loss: 1.7073\n",
      "Epoch [24/100], Step [11100/24597], Loss: 1.7218\n",
      "Epoch [24/100], Step [11200/24597], Loss: 1.5202\n",
      "Epoch [24/100], Step [11300/24597], Loss: 1.7721\n",
      "Epoch [24/100], Step [11400/24597], Loss: 1.7780\n",
      "Epoch [24/100], Step [11500/24597], Loss: 1.8088\n",
      "Epoch [24/100], Step [11600/24597], Loss: 2.0559\n",
      "Epoch [24/100], Step [11700/24597], Loss: 1.6169\n",
      "Epoch [24/100], Step [11800/24597], Loss: 1.6306\n",
      "Epoch [24/100], Step [11900/24597], Loss: 1.8238\n",
      "Epoch [24/100], Step [12000/24597], Loss: 1.6209\n",
      "Epoch [24/100], Step [12100/24597], Loss: 1.8456\n",
      "Epoch [24/100], Step [12200/24597], Loss: 1.6013\n",
      "Epoch [24/100], Step [12300/24597], Loss: 1.4481\n",
      "Epoch [24/100], Step [12400/24597], Loss: 1.5075\n",
      "Epoch [24/100], Step [12500/24597], Loss: 2.1064\n",
      "Epoch [24/100], Step [12600/24597], Loss: 1.3601\n",
      "Epoch [24/100], Step [12700/24597], Loss: 1.5460\n",
      "Epoch [24/100], Step [12800/24597], Loss: 1.7615\n",
      "Epoch [24/100], Step [12900/24597], Loss: 1.4239\n",
      "Epoch [24/100], Step [13000/24597], Loss: 1.5994\n",
      "Epoch [24/100], Step [13100/24597], Loss: 1.6760\n",
      "Epoch [24/100], Step [13200/24597], Loss: 1.5775\n",
      "Epoch [24/100], Step [13300/24597], Loss: 1.5595\n",
      "Epoch [24/100], Step [13400/24597], Loss: 1.7823\n",
      "Epoch [24/100], Step [13500/24597], Loss: 1.7078\n",
      "Epoch [24/100], Step [13600/24597], Loss: 1.5839\n",
      "Epoch [24/100], Step [13700/24597], Loss: 1.6303\n",
      "Epoch [24/100], Step [13800/24597], Loss: 1.5972\n",
      "Epoch [24/100], Step [13900/24597], Loss: 1.4864\n",
      "Epoch [24/100], Step [14000/24597], Loss: 1.6765\n",
      "Epoch [24/100], Step [14100/24597], Loss: 1.5790\n",
      "Epoch [24/100], Step [14200/24597], Loss: 1.6058\n",
      "Epoch [24/100], Step [14300/24597], Loss: 1.5799\n",
      "Epoch [24/100], Step [14400/24597], Loss: 1.5046\n",
      "Epoch [24/100], Step [14500/24597], Loss: 1.6350\n",
      "Epoch [24/100], Step [14600/24597], Loss: 1.8871\n",
      "Epoch [24/100], Step [14700/24597], Loss: 1.3952\n",
      "Epoch [24/100], Step [14800/24597], Loss: 1.7441\n",
      "Epoch [24/100], Step [14900/24597], Loss: 1.6699\n",
      "Epoch [24/100], Step [15000/24597], Loss: 1.5707\n",
      "Epoch [24/100], Step [15100/24597], Loss: 1.6232\n",
      "Epoch [24/100], Step [15200/24597], Loss: 1.5982\n",
      "Epoch [24/100], Step [15300/24597], Loss: 1.7774\n",
      "Epoch [24/100], Step [15400/24597], Loss: 1.4742\n",
      "Epoch [24/100], Step [15500/24597], Loss: 1.5508\n",
      "Epoch [24/100], Step [15600/24597], Loss: 1.5943\n",
      "Epoch [24/100], Step [15700/24597], Loss: 1.5551\n",
      "Epoch [24/100], Step [15800/24597], Loss: 1.6413\n",
      "Epoch [24/100], Step [15900/24597], Loss: 1.5799\n",
      "Epoch [24/100], Step [16000/24597], Loss: 1.5696\n",
      "Epoch [24/100], Step [16100/24597], Loss: 1.5419\n",
      "Epoch [24/100], Step [16200/24597], Loss: 1.4698\n",
      "Epoch [24/100], Step [16300/24597], Loss: 1.5113\n",
      "Epoch [24/100], Step [16400/24597], Loss: 1.9229\n",
      "Epoch [24/100], Step [16500/24597], Loss: 1.5444\n",
      "Epoch [24/100], Step [16600/24597], Loss: 1.4379\n",
      "Epoch [24/100], Step [16700/24597], Loss: 1.5119\n",
      "Epoch [24/100], Step [16800/24597], Loss: 1.6149\n",
      "Epoch [24/100], Step [16900/24597], Loss: 1.5139\n",
      "Epoch [24/100], Step [17000/24597], Loss: 1.5133\n",
      "Epoch [24/100], Step [17100/24597], Loss: 1.7194\n",
      "Epoch [24/100], Step [17200/24597], Loss: 1.4071\n",
      "Epoch [24/100], Step [17300/24597], Loss: 1.6309\n",
      "Epoch [24/100], Step [17400/24597], Loss: 1.7120\n",
      "Epoch [24/100], Step [17500/24597], Loss: 1.6429\n",
      "Epoch [24/100], Step [17600/24597], Loss: 1.5744\n",
      "Epoch [24/100], Step [17700/24597], Loss: 1.6872\n",
      "Epoch [24/100], Step [17800/24597], Loss: 1.4131\n",
      "Epoch [24/100], Step [17900/24597], Loss: 1.4776\n",
      "Epoch [24/100], Step [18000/24597], Loss: 1.5642\n",
      "Epoch [24/100], Step [18100/24597], Loss: 1.5179\n",
      "Epoch [24/100], Step [18200/24597], Loss: 1.4768\n",
      "Epoch [24/100], Step [18300/24597], Loss: 1.4308\n",
      "Epoch [24/100], Step [18400/24597], Loss: 1.8905\n",
      "Epoch [24/100], Step [18500/24597], Loss: 1.7678\n",
      "Epoch [24/100], Step [18600/24597], Loss: 1.4531\n",
      "Epoch [24/100], Step [18700/24597], Loss: 1.6799\n",
      "Epoch [24/100], Step [18800/24597], Loss: 1.7410\n",
      "Epoch [24/100], Step [18900/24597], Loss: 1.6468\n",
      "Epoch [24/100], Step [19000/24597], Loss: 1.5054\n",
      "Epoch [24/100], Step [19100/24597], Loss: 1.6882\n",
      "Epoch [24/100], Step [19200/24597], Loss: 1.8343\n",
      "Epoch [24/100], Step [19300/24597], Loss: 1.5362\n",
      "Epoch [24/100], Step [19400/24597], Loss: 1.6697\n",
      "Epoch [24/100], Step [19500/24597], Loss: 1.8312\n",
      "Epoch [24/100], Step [19600/24597], Loss: 1.4524\n",
      "Epoch [24/100], Step [19700/24597], Loss: 1.6015\n",
      "Epoch [24/100], Step [19800/24597], Loss: 1.4886\n",
      "Epoch [24/100], Step [19900/24597], Loss: 1.6245\n",
      "Epoch [24/100], Step [20000/24597], Loss: 1.7476\n",
      "Epoch [24/100], Step [20100/24597], Loss: 1.5565\n",
      "Epoch [24/100], Step [20200/24597], Loss: 1.2569\n",
      "Epoch [24/100], Step [20300/24597], Loss: 1.4359\n",
      "Epoch [24/100], Step [20400/24597], Loss: 1.5667\n",
      "Epoch [24/100], Step [20500/24597], Loss: 1.6513\n",
      "Epoch [24/100], Step [20600/24597], Loss: 1.6023\n",
      "Epoch [24/100], Step [20700/24597], Loss: 1.6276\n",
      "Epoch [24/100], Step [20800/24597], Loss: 1.4583\n",
      "Epoch [24/100], Step [20900/24597], Loss: 1.4407\n",
      "Epoch [24/100], Step [21000/24597], Loss: 1.8351\n",
      "Epoch [24/100], Step [21100/24597], Loss: 1.5021\n",
      "Epoch [24/100], Step [21200/24597], Loss: 1.5211\n",
      "Epoch [24/100], Step [21300/24597], Loss: 1.4481\n",
      "Epoch [24/100], Step [21400/24597], Loss: 1.6691\n",
      "Epoch [24/100], Step [21500/24597], Loss: 1.8358\n",
      "Epoch [24/100], Step [21600/24597], Loss: 1.5837\n",
      "Epoch [24/100], Step [21700/24597], Loss: 1.8432\n",
      "Epoch [24/100], Step [21800/24597], Loss: 1.4212\n",
      "Epoch [24/100], Step [21900/24597], Loss: 1.5987\n",
      "Epoch [24/100], Step [22000/24597], Loss: 1.4516\n",
      "Epoch [24/100], Step [22100/24597], Loss: 1.3146\n",
      "Epoch [24/100], Step [22200/24597], Loss: 1.5493\n",
      "Epoch [24/100], Step [22300/24597], Loss: 1.7568\n",
      "Epoch [24/100], Step [22400/24597], Loss: 1.7130\n",
      "Epoch [24/100], Step [22500/24597], Loss: 1.6189\n",
      "Epoch [24/100], Step [22600/24597], Loss: 1.4975\n",
      "Epoch [24/100], Step [22700/24597], Loss: 1.4066\n",
      "Epoch [24/100], Step [22800/24597], Loss: 1.4254\n",
      "Epoch [24/100], Step [22900/24597], Loss: 1.5948\n",
      "Epoch [24/100], Step [23000/24597], Loss: 1.6789\n",
      "Epoch [24/100], Step [23100/24597], Loss: 1.6541\n",
      "Epoch [24/100], Step [23200/24597], Loss: 1.9207\n",
      "Epoch [24/100], Step [23300/24597], Loss: 1.3132\n",
      "Epoch [24/100], Step [23400/24597], Loss: 1.4623\n",
      "Epoch [24/100], Step [23500/24597], Loss: 1.7629\n",
      "Epoch [24/100], Step [23600/24597], Loss: 1.5433\n",
      "Epoch [24/100], Step [23700/24597], Loss: 1.7590\n",
      "Epoch [24/100], Step [23800/24597], Loss: 1.7670\n",
      "Epoch [24/100], Step [23900/24597], Loss: 1.5255\n",
      "Epoch [24/100], Step [24000/24597], Loss: 1.6609\n",
      "Epoch [24/100], Step [24100/24597], Loss: 1.5227\n",
      "Epoch [24/100], Step [24200/24597], Loss: 1.4575\n",
      "Epoch [24/100], Step [24300/24597], Loss: 1.6080\n",
      "Epoch [24/100], Step [24400/24597], Loss: 1.4165\n",
      "Epoch [24/100], Step [24500/24597], Loss: 1.5837\n",
      "Epoch [25/100], Step [100/24597], Loss: 1.5859\n",
      "Epoch [25/100], Step [200/24597], Loss: 1.6755\n",
      "Epoch [25/100], Step [300/24597], Loss: 1.6033\n",
      "Epoch [25/100], Step [400/24597], Loss: 1.5604\n",
      "Epoch [25/100], Step [500/24597], Loss: 1.7985\n",
      "Epoch [25/100], Step [600/24597], Loss: 1.6396\n",
      "Epoch [25/100], Step [700/24597], Loss: 1.6472\n",
      "Epoch [25/100], Step [800/24597], Loss: 1.8920\n",
      "Epoch [25/100], Step [900/24597], Loss: 1.6179\n",
      "Epoch [25/100], Step [1000/24597], Loss: 1.4410\n",
      "Epoch [25/100], Step [1100/24597], Loss: 1.6182\n",
      "Epoch [25/100], Step [1200/24597], Loss: 1.6332\n",
      "Epoch [25/100], Step [1300/24597], Loss: 1.4518\n",
      "Epoch [25/100], Step [1400/24597], Loss: 1.5484\n",
      "Epoch [25/100], Step [1500/24597], Loss: 1.6776\n",
      "Epoch [25/100], Step [1600/24597], Loss: 1.4468\n",
      "Epoch [25/100], Step [1700/24597], Loss: 1.8189\n",
      "Epoch [25/100], Step [1800/24597], Loss: 1.7580\n",
      "Epoch [25/100], Step [1900/24597], Loss: 1.4195\n",
      "Epoch [25/100], Step [2000/24597], Loss: 1.4924\n",
      "Epoch [25/100], Step [2100/24597], Loss: 1.6453\n",
      "Epoch [25/100], Step [2200/24597], Loss: 1.7591\n",
      "Epoch [25/100], Step [2300/24597], Loss: 1.5359\n",
      "Epoch [25/100], Step [2400/24597], Loss: 1.5955\n",
      "Epoch [25/100], Step [2500/24597], Loss: 1.6691\n",
      "Epoch [25/100], Step [2600/24597], Loss: 1.7215\n",
      "Epoch [25/100], Step [2700/24597], Loss: 1.7996\n",
      "Epoch [25/100], Step [2800/24597], Loss: 1.5419\n",
      "Epoch [25/100], Step [2900/24597], Loss: 1.8612\n",
      "Epoch [25/100], Step [3000/24597], Loss: 1.5887\n",
      "Epoch [25/100], Step [3100/24597], Loss: 1.6391\n",
      "Epoch [25/100], Step [3200/24597], Loss: 1.4434\n",
      "Epoch [25/100], Step [3300/24597], Loss: 1.3267\n",
      "Epoch [25/100], Step [3400/24597], Loss: 1.6240\n",
      "Epoch [25/100], Step [3500/24597], Loss: 1.6857\n",
      "Epoch [25/100], Step [3600/24597], Loss: 1.6778\n",
      "Epoch [25/100], Step [3700/24597], Loss: 1.6740\n",
      "Epoch [25/100], Step [3800/24597], Loss: 1.6414\n",
      "Epoch [25/100], Step [3900/24597], Loss: 1.5479\n",
      "Epoch [25/100], Step [4000/24597], Loss: 1.4958\n",
      "Epoch [25/100], Step [4100/24597], Loss: 1.6421\n",
      "Epoch [25/100], Step [4200/24597], Loss: 1.4924\n",
      "Epoch [25/100], Step [4300/24597], Loss: 1.5713\n",
      "Epoch [25/100], Step [4400/24597], Loss: 1.7325\n",
      "Epoch [25/100], Step [4500/24597], Loss: 1.7075\n",
      "Epoch [25/100], Step [4600/24597], Loss: 1.5201\n",
      "Epoch [25/100], Step [4700/24597], Loss: 1.4835\n",
      "Epoch [25/100], Step [4800/24597], Loss: 1.4550\n",
      "Epoch [25/100], Step [4900/24597], Loss: 1.7841\n",
      "Epoch [25/100], Step [5000/24597], Loss: 1.8268\n",
      "Epoch [25/100], Step [5100/24597], Loss: 1.5323\n",
      "Epoch [25/100], Step [5200/24597], Loss: 1.8307\n",
      "Epoch [25/100], Step [5300/24597], Loss: 1.6294\n",
      "Epoch [25/100], Step [5400/24597], Loss: 1.7188\n",
      "Epoch [25/100], Step [5500/24597], Loss: 1.5415\n",
      "Epoch [25/100], Step [5600/24597], Loss: 1.7456\n",
      "Epoch [25/100], Step [5700/24597], Loss: 1.6302\n",
      "Epoch [25/100], Step [5800/24597], Loss: 1.8857\n",
      "Epoch [25/100], Step [5900/24597], Loss: 1.6640\n",
      "Epoch [25/100], Step [6000/24597], Loss: 1.5892\n",
      "Epoch [25/100], Step [6100/24597], Loss: 1.5438\n",
      "Epoch [25/100], Step [6200/24597], Loss: 1.3929\n",
      "Epoch [25/100], Step [6300/24597], Loss: 1.7172\n",
      "Epoch [25/100], Step [6400/24597], Loss: 1.4908\n",
      "Epoch [25/100], Step [6500/24597], Loss: 1.5675\n",
      "Epoch [25/100], Step [6600/24597], Loss: 1.5779\n",
      "Epoch [25/100], Step [6700/24597], Loss: 1.4709\n",
      "Epoch [25/100], Step [6800/24597], Loss: 1.4957\n",
      "Epoch [25/100], Step [6900/24597], Loss: 1.6397\n",
      "Epoch [25/100], Step [7000/24597], Loss: 1.5808\n",
      "Epoch [25/100], Step [7100/24597], Loss: 1.8541\n",
      "Epoch [25/100], Step [7200/24597], Loss: 1.5654\n",
      "Epoch [25/100], Step [7300/24597], Loss: 1.7848\n",
      "Epoch [25/100], Step [7400/24597], Loss: 1.6020\n",
      "Epoch [25/100], Step [7500/24597], Loss: 1.3386\n",
      "Epoch [25/100], Step [7600/24597], Loss: 1.4911\n",
      "Epoch [25/100], Step [7700/24597], Loss: 1.6277\n",
      "Epoch [25/100], Step [7800/24597], Loss: 1.4943\n",
      "Epoch [25/100], Step [7900/24597], Loss: 1.6650\n",
      "Epoch [25/100], Step [8000/24597], Loss: 1.7305\n",
      "Epoch [25/100], Step [8100/24597], Loss: 1.7077\n",
      "Epoch [25/100], Step [8200/24597], Loss: 1.6803\n",
      "Epoch [25/100], Step [8300/24597], Loss: 1.7250\n",
      "Epoch [25/100], Step [8400/24597], Loss: 1.3497\n",
      "Epoch [25/100], Step [8500/24597], Loss: 1.5179\n",
      "Epoch [25/100], Step [8600/24597], Loss: 1.9041\n",
      "Epoch [25/100], Step [8700/24597], Loss: 1.6763\n",
      "Epoch [25/100], Step [8800/24597], Loss: 1.6871\n",
      "Epoch [25/100], Step [8900/24597], Loss: 1.6603\n",
      "Epoch [25/100], Step [9000/24597], Loss: 1.3542\n",
      "Epoch [25/100], Step [9100/24597], Loss: 1.7344\n",
      "Epoch [25/100], Step [9200/24597], Loss: 1.6169\n",
      "Epoch [25/100], Step [9300/24597], Loss: 1.7721\n",
      "Epoch [25/100], Step [9400/24597], Loss: 1.7014\n",
      "Epoch [25/100], Step [9500/24597], Loss: 1.8150\n",
      "Epoch [25/100], Step [9600/24597], Loss: 1.7513\n",
      "Epoch [25/100], Step [9700/24597], Loss: 1.4999\n",
      "Epoch [25/100], Step [9800/24597], Loss: 1.5775\n",
      "Epoch [25/100], Step [9900/24597], Loss: 1.6614\n",
      "Epoch [25/100], Step [10000/24597], Loss: 1.7570\n",
      "Epoch [25/100], Step [10100/24597], Loss: 1.6849\n",
      "Epoch [25/100], Step [10200/24597], Loss: 1.4136\n",
      "Epoch [25/100], Step [10300/24597], Loss: 1.5927\n",
      "Epoch [25/100], Step [10400/24597], Loss: 1.4907\n",
      "Epoch [25/100], Step [10500/24597], Loss: 1.5881\n",
      "Epoch [25/100], Step [10600/24597], Loss: 1.7390\n",
      "Epoch [25/100], Step [10700/24597], Loss: 1.5330\n",
      "Epoch [25/100], Step [10800/24597], Loss: 1.8271\n",
      "Epoch [25/100], Step [10900/24597], Loss: 1.7632\n",
      "Epoch [25/100], Step [11000/24597], Loss: 1.6212\n",
      "Epoch [25/100], Step [11100/24597], Loss: 1.6775\n",
      "Epoch [25/100], Step [11200/24597], Loss: 1.7786\n",
      "Epoch [25/100], Step [11300/24597], Loss: 1.5621\n",
      "Epoch [25/100], Step [11400/24597], Loss: 1.7333\n",
      "Epoch [25/100], Step [11500/24597], Loss: 1.6329\n",
      "Epoch [25/100], Step [11600/24597], Loss: 1.6964\n",
      "Epoch [25/100], Step [11700/24597], Loss: 1.5744\n",
      "Epoch [25/100], Step [11800/24597], Loss: 1.5769\n",
      "Epoch [25/100], Step [11900/24597], Loss: 1.7070\n",
      "Epoch [25/100], Step [12000/24597], Loss: 1.5418\n",
      "Epoch [25/100], Step [12100/24597], Loss: 1.7511\n",
      "Epoch [25/100], Step [12200/24597], Loss: 1.6825\n",
      "Epoch [25/100], Step [12300/24597], Loss: 1.7999\n",
      "Epoch [25/100], Step [12400/24597], Loss: 1.4796\n",
      "Epoch [25/100], Step [12500/24597], Loss: 1.5848\n",
      "Epoch [25/100], Step [12600/24597], Loss: 1.5560\n",
      "Epoch [25/100], Step [12700/24597], Loss: 1.3692\n",
      "Epoch [25/100], Step [12800/24597], Loss: 1.8763\n",
      "Epoch [25/100], Step [12900/24597], Loss: 1.5942\n",
      "Epoch [25/100], Step [13000/24597], Loss: 1.2737\n",
      "Epoch [25/100], Step [13100/24597], Loss: 1.7652\n",
      "Epoch [25/100], Step [13200/24597], Loss: 1.4035\n",
      "Epoch [25/100], Step [13300/24597], Loss: 1.6440\n",
      "Epoch [25/100], Step [13400/24597], Loss: 1.5717\n",
      "Epoch [25/100], Step [13500/24597], Loss: 1.7103\n",
      "Epoch [25/100], Step [13600/24597], Loss: 1.6011\n",
      "Epoch [25/100], Step [13700/24597], Loss: 1.9125\n",
      "Epoch [25/100], Step [13800/24597], Loss: 1.6872\n",
      "Epoch [25/100], Step [13900/24597], Loss: 1.6536\n",
      "Epoch [25/100], Step [14000/24597], Loss: 1.5224\n",
      "Epoch [25/100], Step [14100/24597], Loss: 1.7697\n",
      "Epoch [25/100], Step [14200/24597], Loss: 1.7492\n",
      "Epoch [25/100], Step [14300/24597], Loss: 1.5457\n",
      "Epoch [25/100], Step [14400/24597], Loss: 1.5688\n",
      "Epoch [25/100], Step [14500/24597], Loss: 1.8174\n",
      "Epoch [25/100], Step [14600/24597], Loss: 1.4709\n",
      "Epoch [25/100], Step [14700/24597], Loss: 1.5786\n",
      "Epoch [25/100], Step [14800/24597], Loss: 1.5353\n",
      "Epoch [25/100], Step [14900/24597], Loss: 1.7702\n",
      "Epoch [25/100], Step [15000/24597], Loss: 1.4127\n",
      "Epoch [25/100], Step [15100/24597], Loss: 1.4593\n",
      "Epoch [25/100], Step [15200/24597], Loss: 1.6667\n",
      "Epoch [25/100], Step [15300/24597], Loss: 1.6542\n",
      "Epoch [25/100], Step [15400/24597], Loss: 1.5784\n",
      "Epoch [25/100], Step [15500/24597], Loss: 1.5938\n",
      "Epoch [25/100], Step [15600/24597], Loss: 1.8422\n",
      "Epoch [25/100], Step [15700/24597], Loss: 1.6273\n",
      "Epoch [25/100], Step [15800/24597], Loss: 1.6870\n",
      "Epoch [25/100], Step [15900/24597], Loss: 1.6336\n",
      "Epoch [25/100], Step [16000/24597], Loss: 1.6852\n",
      "Epoch [25/100], Step [16100/24597], Loss: 1.6485\n",
      "Epoch [25/100], Step [16200/24597], Loss: 1.4296\n",
      "Epoch [25/100], Step [16300/24597], Loss: 1.4933\n",
      "Epoch [25/100], Step [16400/24597], Loss: 1.6640\n",
      "Epoch [25/100], Step [16500/24597], Loss: 1.7082\n",
      "Epoch [25/100], Step [16600/24597], Loss: 1.5763\n",
      "Epoch [25/100], Step [16700/24597], Loss: 1.3697\n",
      "Epoch [25/100], Step [16800/24597], Loss: 1.4542\n",
      "Epoch [25/100], Step [16900/24597], Loss: 1.4009\n",
      "Epoch [25/100], Step [17000/24597], Loss: 1.6041\n",
      "Epoch [25/100], Step [17100/24597], Loss: 1.7106\n",
      "Epoch [25/100], Step [17200/24597], Loss: 1.7472\n",
      "Epoch [25/100], Step [17300/24597], Loss: 1.7164\n",
      "Epoch [25/100], Step [17400/24597], Loss: 1.6720\n",
      "Epoch [25/100], Step [17500/24597], Loss: 1.4531\n",
      "Epoch [25/100], Step [17600/24597], Loss: 1.5067\n",
      "Epoch [25/100], Step [17700/24597], Loss: 1.8275\n",
      "Epoch [25/100], Step [17800/24597], Loss: 1.6232\n",
      "Epoch [25/100], Step [17900/24597], Loss: 1.6944\n",
      "Epoch [25/100], Step [18000/24597], Loss: 1.5187\n",
      "Epoch [25/100], Step [18100/24597], Loss: 1.5329\n",
      "Epoch [25/100], Step [18200/24597], Loss: 1.7083\n",
      "Epoch [25/100], Step [18300/24597], Loss: 1.5225\n",
      "Epoch [25/100], Step [18400/24597], Loss: 1.4608\n",
      "Epoch [25/100], Step [18500/24597], Loss: 1.5913\n",
      "Epoch [25/100], Step [18600/24597], Loss: 1.5391\n",
      "Epoch [25/100], Step [18700/24597], Loss: 1.6606\n",
      "Epoch [25/100], Step [18800/24597], Loss: 1.4943\n",
      "Epoch [25/100], Step [18900/24597], Loss: 1.8508\n",
      "Epoch [25/100], Step [19000/24597], Loss: 1.6581\n",
      "Epoch [25/100], Step [19100/24597], Loss: 1.8826\n",
      "Epoch [25/100], Step [19200/24597], Loss: 1.6923\n",
      "Epoch [25/100], Step [19300/24597], Loss: 1.6380\n",
      "Epoch [25/100], Step [19400/24597], Loss: 1.5229\n",
      "Epoch [25/100], Step [19500/24597], Loss: 1.8644\n",
      "Epoch [25/100], Step [19600/24597], Loss: 1.5998\n",
      "Epoch [25/100], Step [19700/24597], Loss: 1.3445\n",
      "Epoch [25/100], Step [19800/24597], Loss: 1.5964\n",
      "Epoch [25/100], Step [19900/24597], Loss: 1.5798\n",
      "Epoch [25/100], Step [20000/24597], Loss: 1.7204\n",
      "Epoch [25/100], Step [20100/24597], Loss: 1.6009\n",
      "Epoch [25/100], Step [20200/24597], Loss: 1.5829\n",
      "Epoch [25/100], Step [20300/24597], Loss: 1.8113\n",
      "Epoch [25/100], Step [20400/24597], Loss: 1.6658\n",
      "Epoch [25/100], Step [20500/24597], Loss: 1.7291\n",
      "Epoch [25/100], Step [20600/24597], Loss: 1.4657\n",
      "Epoch [25/100], Step [20700/24597], Loss: 1.7175\n",
      "Epoch [25/100], Step [20800/24597], Loss: 1.6262\n",
      "Epoch [25/100], Step [20900/24597], Loss: 1.6978\n",
      "Epoch [25/100], Step [21000/24597], Loss: 1.3828\n",
      "Epoch [25/100], Step [21100/24597], Loss: 1.9191\n",
      "Epoch [25/100], Step [21200/24597], Loss: 1.6101\n",
      "Epoch [25/100], Step [21300/24597], Loss: 1.4289\n",
      "Epoch [25/100], Step [21400/24597], Loss: 1.6270\n",
      "Epoch [25/100], Step [21500/24597], Loss: 1.8635\n",
      "Epoch [25/100], Step [21600/24597], Loss: 1.4671\n",
      "Epoch [25/100], Step [21700/24597], Loss: 1.4385\n",
      "Epoch [25/100], Step [21800/24597], Loss: 1.7911\n",
      "Epoch [25/100], Step [21900/24597], Loss: 1.4888\n",
      "Epoch [25/100], Step [22000/24597], Loss: 1.5286\n",
      "Epoch [25/100], Step [22100/24597], Loss: 1.7022\n",
      "Epoch [25/100], Step [22200/24597], Loss: 1.6444\n",
      "Epoch [25/100], Step [22300/24597], Loss: 1.5634\n",
      "Epoch [25/100], Step [22400/24597], Loss: 1.8302\n",
      "Epoch [25/100], Step [22500/24597], Loss: 1.6605\n",
      "Epoch [25/100], Step [22600/24597], Loss: 1.5942\n",
      "Epoch [25/100], Step [22700/24597], Loss: 1.4851\n",
      "Epoch [25/100], Step [22800/24597], Loss: 1.5276\n",
      "Epoch [25/100], Step [22900/24597], Loss: 1.6464\n",
      "Epoch [25/100], Step [23000/24597], Loss: 1.7743\n",
      "Epoch [25/100], Step [23100/24597], Loss: 1.4997\n",
      "Epoch [25/100], Step [23200/24597], Loss: 1.6891\n",
      "Epoch [25/100], Step [23300/24597], Loss: 1.8705\n",
      "Epoch [25/100], Step [23400/24597], Loss: 1.7182\n",
      "Epoch [25/100], Step [23500/24597], Loss: 1.5419\n",
      "Epoch [25/100], Step [23600/24597], Loss: 1.5464\n",
      "Epoch [25/100], Step [23700/24597], Loss: 1.6568\n",
      "Epoch [25/100], Step [23800/24597], Loss: 1.5542\n",
      "Epoch [25/100], Step [23900/24597], Loss: 1.5581\n",
      "Epoch [25/100], Step [24000/24597], Loss: 1.7061\n",
      "Epoch [25/100], Step [24100/24597], Loss: 1.7072\n",
      "Epoch [25/100], Step [24200/24597], Loss: 1.6784\n",
      "Epoch [25/100], Step [24300/24597], Loss: 1.5444\n",
      "Epoch [25/100], Step [24400/24597], Loss: 1.6758\n",
      "Epoch [25/100], Step [24500/24597], Loss: 1.6285\n",
      "Epoch [26/100], Step [100/24597], Loss: 1.8278\n",
      "Epoch [26/100], Step [200/24597], Loss: 1.4634\n",
      "Epoch [26/100], Step [300/24597], Loss: 1.3734\n",
      "Epoch [26/100], Step [400/24597], Loss: 1.5025\n",
      "Epoch [26/100], Step [500/24597], Loss: 1.9334\n",
      "Epoch [26/100], Step [600/24597], Loss: 1.6196\n",
      "Epoch [26/100], Step [700/24597], Loss: 1.6180\n",
      "Epoch [26/100], Step [800/24597], Loss: 1.3648\n",
      "Epoch [26/100], Step [900/24597], Loss: 1.5408\n",
      "Epoch [26/100], Step [1000/24597], Loss: 1.7165\n",
      "Epoch [26/100], Step [1100/24597], Loss: 1.5734\n",
      "Epoch [26/100], Step [1200/24597], Loss: 1.7222\n",
      "Epoch [26/100], Step [1300/24597], Loss: 1.5611\n",
      "Epoch [26/100], Step [1400/24597], Loss: 1.6611\n",
      "Epoch [26/100], Step [1500/24597], Loss: 1.8039\n",
      "Epoch [26/100], Step [1600/24597], Loss: 1.6038\n",
      "Epoch [26/100], Step [1700/24597], Loss: 1.5393\n",
      "Epoch [26/100], Step [1800/24597], Loss: 1.4611\n",
      "Epoch [26/100], Step [1900/24597], Loss: 1.5466\n",
      "Epoch [26/100], Step [2000/24597], Loss: 1.5006\n",
      "Epoch [26/100], Step [2100/24597], Loss: 1.6153\n",
      "Epoch [26/100], Step [2200/24597], Loss: 1.5140\n",
      "Epoch [26/100], Step [2300/24597], Loss: 1.4582\n",
      "Epoch [26/100], Step [2400/24597], Loss: 1.7715\n",
      "Epoch [26/100], Step [2500/24597], Loss: 1.6774\n",
      "Epoch [26/100], Step [2600/24597], Loss: 1.4903\n",
      "Epoch [26/100], Step [2700/24597], Loss: 1.7073\n",
      "Epoch [26/100], Step [2800/24597], Loss: 1.6985\n",
      "Epoch [26/100], Step [2900/24597], Loss: 1.5690\n",
      "Epoch [26/100], Step [3000/24597], Loss: 1.9328\n",
      "Epoch [26/100], Step [3100/24597], Loss: 1.3809\n",
      "Epoch [26/100], Step [3200/24597], Loss: 1.5925\n",
      "Epoch [26/100], Step [3300/24597], Loss: 1.4201\n",
      "Epoch [26/100], Step [3400/24597], Loss: 1.7710\n",
      "Epoch [26/100], Step [3500/24597], Loss: 1.6911\n",
      "Epoch [26/100], Step [3600/24597], Loss: 1.6079\n",
      "Epoch [26/100], Step [3700/24597], Loss: 1.5082\n",
      "Epoch [26/100], Step [3800/24597], Loss: 1.6069\n",
      "Epoch [26/100], Step [3900/24597], Loss: 1.7182\n",
      "Epoch [26/100], Step [4000/24597], Loss: 1.6906\n",
      "Epoch [26/100], Step [4100/24597], Loss: 1.5946\n",
      "Epoch [26/100], Step [4200/24597], Loss: 1.4516\n",
      "Epoch [26/100], Step [4300/24597], Loss: 1.5211\n",
      "Epoch [26/100], Step [4400/24597], Loss: 1.4899\n",
      "Epoch [26/100], Step [4500/24597], Loss: 1.7665\n",
      "Epoch [26/100], Step [4600/24597], Loss: 1.7400\n",
      "Epoch [26/100], Step [4700/24597], Loss: 1.7070\n",
      "Epoch [26/100], Step [4800/24597], Loss: 1.8662\n",
      "Epoch [26/100], Step [4900/24597], Loss: 1.5354\n",
      "Epoch [26/100], Step [5000/24597], Loss: 1.6213\n",
      "Epoch [26/100], Step [5100/24597], Loss: 1.6919\n",
      "Epoch [26/100], Step [5200/24597], Loss: 1.5601\n",
      "Epoch [26/100], Step [5300/24597], Loss: 1.6533\n",
      "Epoch [26/100], Step [5400/24597], Loss: 1.7677\n",
      "Epoch [26/100], Step [5500/24597], Loss: 1.6108\n",
      "Epoch [26/100], Step [5600/24597], Loss: 1.6675\n",
      "Epoch [26/100], Step [5700/24597], Loss: 1.4764\n",
      "Epoch [26/100], Step [5800/24597], Loss: 1.6481\n",
      "Epoch [26/100], Step [5900/24597], Loss: 1.7219\n",
      "Epoch [26/100], Step [6000/24597], Loss: 1.7439\n",
      "Epoch [26/100], Step [6100/24597], Loss: 1.4459\n",
      "Epoch [26/100], Step [6200/24597], Loss: 1.7415\n",
      "Epoch [26/100], Step [6300/24597], Loss: 1.6648\n",
      "Epoch [26/100], Step [6400/24597], Loss: 1.4285\n",
      "Epoch [26/100], Step [6500/24597], Loss: 1.4600\n",
      "Epoch [26/100], Step [6600/24597], Loss: 1.6169\n",
      "Epoch [26/100], Step [6700/24597], Loss: 1.7160\n",
      "Epoch [26/100], Step [6800/24597], Loss: 1.6941\n",
      "Epoch [26/100], Step [6900/24597], Loss: 1.5228\n",
      "Epoch [26/100], Step [7000/24597], Loss: 1.9270\n",
      "Epoch [26/100], Step [7100/24597], Loss: 1.7546\n",
      "Epoch [26/100], Step [7200/24597], Loss: 1.7900\n",
      "Epoch [26/100], Step [7300/24597], Loss: 1.4243\n",
      "Epoch [26/100], Step [7400/24597], Loss: 1.5172\n",
      "Epoch [26/100], Step [7500/24597], Loss: 1.5989\n",
      "Epoch [26/100], Step [7600/24597], Loss: 1.8136\n",
      "Epoch [26/100], Step [7700/24597], Loss: 1.5928\n",
      "Epoch [26/100], Step [7800/24597], Loss: 1.5072\n",
      "Epoch [26/100], Step [7900/24597], Loss: 1.6391\n",
      "Epoch [26/100], Step [8000/24597], Loss: 1.7531\n",
      "Epoch [26/100], Step [8100/24597], Loss: 1.5226\n",
      "Epoch [26/100], Step [8200/24597], Loss: 1.4573\n",
      "Epoch [26/100], Step [8300/24597], Loss: 1.6687\n",
      "Epoch [26/100], Step [8400/24597], Loss: 1.3840\n",
      "Epoch [26/100], Step [8500/24597], Loss: 1.5805\n",
      "Epoch [26/100], Step [8600/24597], Loss: 1.7905\n",
      "Epoch [26/100], Step [8700/24597], Loss: 1.7192\n",
      "Epoch [26/100], Step [8800/24597], Loss: 1.5537\n",
      "Epoch [26/100], Step [8900/24597], Loss: 1.8185\n",
      "Epoch [26/100], Step [9000/24597], Loss: 1.5688\n",
      "Epoch [26/100], Step [9100/24597], Loss: 1.6511\n",
      "Epoch [26/100], Step [9200/24597], Loss: 1.6345\n",
      "Epoch [26/100], Step [9300/24597], Loss: 1.6844\n",
      "Epoch [26/100], Step [9400/24597], Loss: 1.5937\n",
      "Epoch [26/100], Step [9500/24597], Loss: 1.7081\n",
      "Epoch [26/100], Step [9600/24597], Loss: 1.5704\n",
      "Epoch [26/100], Step [9700/24597], Loss: 1.5452\n",
      "Epoch [26/100], Step [9800/24597], Loss: 1.4353\n",
      "Epoch [26/100], Step [9900/24597], Loss: 1.4273\n",
      "Epoch [26/100], Step [10000/24597], Loss: 1.5581\n",
      "Epoch [26/100], Step [10100/24597], Loss: 1.6005\n",
      "Epoch [26/100], Step [10200/24597], Loss: 1.7672\n",
      "Epoch [26/100], Step [10300/24597], Loss: 1.6647\n",
      "Epoch [26/100], Step [10400/24597], Loss: 1.6143\n",
      "Epoch [26/100], Step [10500/24597], Loss: 1.6274\n",
      "Epoch [26/100], Step [10600/24597], Loss: 1.6328\n",
      "Epoch [26/100], Step [10700/24597], Loss: 1.5445\n",
      "Epoch [26/100], Step [10800/24597], Loss: 1.4483\n",
      "Epoch [26/100], Step [10900/24597], Loss: 1.4985\n",
      "Epoch [26/100], Step [11000/24597], Loss: 1.4786\n",
      "Epoch [26/100], Step [11100/24597], Loss: 1.6033\n",
      "Epoch [26/100], Step [11200/24597], Loss: 1.5289\n",
      "Epoch [26/100], Step [11300/24597], Loss: 1.6348\n",
      "Epoch [26/100], Step [11400/24597], Loss: 1.3651\n",
      "Epoch [26/100], Step [11500/24597], Loss: 1.6311\n",
      "Epoch [26/100], Step [11600/24597], Loss: 1.7553\n",
      "Epoch [26/100], Step [11700/24597], Loss: 1.8092\n",
      "Epoch [26/100], Step [11800/24597], Loss: 1.7264\n",
      "Epoch [26/100], Step [11900/24597], Loss: 1.8025\n",
      "Epoch [26/100], Step [12000/24597], Loss: 1.3561\n",
      "Epoch [26/100], Step [12100/24597], Loss: 1.7377\n",
      "Epoch [26/100], Step [12200/24597], Loss: 1.9589\n",
      "Epoch [26/100], Step [12300/24597], Loss: 1.6887\n",
      "Epoch [26/100], Step [12400/24597], Loss: 1.5995\n",
      "Epoch [26/100], Step [12500/24597], Loss: 1.5024\n",
      "Epoch [26/100], Step [12600/24597], Loss: 1.4272\n",
      "Epoch [26/100], Step [12700/24597], Loss: 1.7786\n",
      "Epoch [26/100], Step [12800/24597], Loss: 1.7358\n",
      "Epoch [26/100], Step [12900/24597], Loss: 1.6843\n",
      "Epoch [26/100], Step [13000/24597], Loss: 1.8636\n",
      "Epoch [26/100], Step [13100/24597], Loss: 1.8477\n",
      "Epoch [26/100], Step [13200/24597], Loss: 1.6404\n",
      "Epoch [26/100], Step [13300/24597], Loss: 1.8584\n",
      "Epoch [26/100], Step [13400/24597], Loss: 1.5807\n",
      "Epoch [26/100], Step [13500/24597], Loss: 1.4305\n",
      "Epoch [26/100], Step [13600/24597], Loss: 1.6422\n",
      "Epoch [26/100], Step [13700/24597], Loss: 1.6069\n",
      "Epoch [26/100], Step [13800/24597], Loss: 1.5130\n",
      "Epoch [26/100], Step [13900/24597], Loss: 1.5139\n",
      "Epoch [26/100], Step [14000/24597], Loss: 1.7148\n",
      "Epoch [26/100], Step [14100/24597], Loss: 1.3495\n",
      "Epoch [26/100], Step [14200/24597], Loss: 1.7707\n",
      "Epoch [26/100], Step [14300/24597], Loss: 1.6855\n",
      "Epoch [26/100], Step [14400/24597], Loss: 1.6338\n",
      "Epoch [26/100], Step [14500/24597], Loss: 1.6317\n",
      "Epoch [26/100], Step [14600/24597], Loss: 1.6751\n",
      "Epoch [26/100], Step [14700/24597], Loss: 1.5951\n",
      "Epoch [26/100], Step [14800/24597], Loss: 1.8577\n",
      "Epoch [26/100], Step [14900/24597], Loss: 1.6944\n",
      "Epoch [26/100], Step [15000/24597], Loss: 1.5785\n",
      "Epoch [26/100], Step [15100/24597], Loss: 1.5262\n",
      "Epoch [26/100], Step [15200/24597], Loss: 1.5098\n",
      "Epoch [26/100], Step [15300/24597], Loss: 1.6282\n",
      "Epoch [26/100], Step [15400/24597], Loss: 1.6787\n",
      "Epoch [26/100], Step [15500/24597], Loss: 1.5919\n",
      "Epoch [26/100], Step [15600/24597], Loss: 1.4560\n",
      "Epoch [26/100], Step [15700/24597], Loss: 1.5496\n",
      "Epoch [26/100], Step [15800/24597], Loss: 1.4115\n",
      "Epoch [26/100], Step [15900/24597], Loss: 1.7723\n",
      "Epoch [26/100], Step [16000/24597], Loss: 1.6457\n",
      "Epoch [26/100], Step [16100/24597], Loss: 1.5675\n",
      "Epoch [26/100], Step [16200/24597], Loss: 1.5127\n",
      "Epoch [26/100], Step [16300/24597], Loss: 1.4238\n",
      "Epoch [26/100], Step [16400/24597], Loss: 1.5472\n",
      "Epoch [26/100], Step [16500/24597], Loss: 1.6532\n",
      "Epoch [26/100], Step [16600/24597], Loss: 1.6457\n",
      "Epoch [26/100], Step [16700/24597], Loss: 1.5281\n",
      "Epoch [26/100], Step [16800/24597], Loss: 1.5094\n",
      "Epoch [26/100], Step [16900/24597], Loss: 1.6200\n",
      "Epoch [26/100], Step [17000/24597], Loss: 1.4850\n",
      "Epoch [26/100], Step [17100/24597], Loss: 1.5812\n",
      "Epoch [26/100], Step [17200/24597], Loss: 1.6019\n",
      "Epoch [26/100], Step [17300/24597], Loss: 1.6074\n",
      "Epoch [26/100], Step [17400/24597], Loss: 1.8743\n",
      "Epoch [26/100], Step [17500/24597], Loss: 1.6565\n",
      "Epoch [26/100], Step [17600/24597], Loss: 1.4673\n",
      "Epoch [26/100], Step [17700/24597], Loss: 1.7430\n",
      "Epoch [26/100], Step [17800/24597], Loss: 1.7008\n",
      "Epoch [26/100], Step [17900/24597], Loss: 1.6632\n",
      "Epoch [26/100], Step [18000/24597], Loss: 1.4566\n",
      "Epoch [26/100], Step [18100/24597], Loss: 1.5616\n",
      "Epoch [26/100], Step [18200/24597], Loss: 1.6254\n",
      "Epoch [26/100], Step [18300/24597], Loss: 1.8410\n",
      "Epoch [26/100], Step [18400/24597], Loss: 1.6327\n",
      "Epoch [26/100], Step [18500/24597], Loss: 1.5953\n",
      "Epoch [26/100], Step [18600/24597], Loss: 1.5471\n",
      "Epoch [26/100], Step [18700/24597], Loss: 1.6080\n",
      "Epoch [26/100], Step [18800/24597], Loss: 1.6338\n",
      "Epoch [26/100], Step [18900/24597], Loss: 1.7374\n",
      "Epoch [26/100], Step [19000/24597], Loss: 1.6403\n",
      "Epoch [26/100], Step [19100/24597], Loss: 1.6706\n",
      "Epoch [26/100], Step [19200/24597], Loss: 1.7656\n",
      "Epoch [26/100], Step [19300/24597], Loss: 1.7302\n",
      "Epoch [26/100], Step [19400/24597], Loss: 1.5777\n",
      "Epoch [26/100], Step [19500/24597], Loss: 1.4995\n",
      "Epoch [26/100], Step [19600/24597], Loss: 1.4466\n",
      "Epoch [26/100], Step [19700/24597], Loss: 1.8217\n",
      "Epoch [26/100], Step [19800/24597], Loss: 1.3233\n",
      "Epoch [26/100], Step [19900/24597], Loss: 1.7030\n",
      "Epoch [26/100], Step [20000/24597], Loss: 1.7368\n",
      "Epoch [26/100], Step [20100/24597], Loss: 1.3419\n",
      "Epoch [26/100], Step [20200/24597], Loss: 1.5236\n",
      "Epoch [26/100], Step [20300/24597], Loss: 1.6793\n",
      "Epoch [26/100], Step [20400/24597], Loss: 1.7383\n",
      "Epoch [26/100], Step [20500/24597], Loss: 1.7896\n",
      "Epoch [26/100], Step [20600/24597], Loss: 1.7258\n",
      "Epoch [26/100], Step [20700/24597], Loss: 1.6084\n",
      "Epoch [26/100], Step [20800/24597], Loss: 1.6355\n",
      "Epoch [26/100], Step [20900/24597], Loss: 1.7488\n",
      "Epoch [26/100], Step [21000/24597], Loss: 1.5791\n",
      "Epoch [26/100], Step [21100/24597], Loss: 1.5560\n",
      "Epoch [26/100], Step [21200/24597], Loss: 1.6040\n",
      "Epoch [26/100], Step [21300/24597], Loss: 1.5667\n",
      "Epoch [26/100], Step [21400/24597], Loss: 1.8675\n",
      "Epoch [26/100], Step [21500/24597], Loss: 1.7795\n",
      "Epoch [26/100], Step [21600/24597], Loss: 1.7864\n",
      "Epoch [26/100], Step [21700/24597], Loss: 1.5568\n",
      "Epoch [26/100], Step [21800/24597], Loss: 1.6136\n",
      "Epoch [26/100], Step [21900/24597], Loss: 1.6766\n",
      "Epoch [26/100], Step [22000/24597], Loss: 1.5188\n",
      "Epoch [26/100], Step [22100/24597], Loss: 1.6026\n",
      "Epoch [26/100], Step [22200/24597], Loss: 1.6039\n",
      "Epoch [26/100], Step [22300/24597], Loss: 1.5223\n",
      "Epoch [26/100], Step [22400/24597], Loss: 1.7200\n",
      "Epoch [26/100], Step [22500/24597], Loss: 1.5759\n",
      "Epoch [26/100], Step [22600/24597], Loss: 1.6353\n",
      "Epoch [26/100], Step [22700/24597], Loss: 1.5124\n",
      "Epoch [26/100], Step [22800/24597], Loss: 1.5254\n",
      "Epoch [26/100], Step [22900/24597], Loss: 1.4889\n",
      "Epoch [26/100], Step [23000/24597], Loss: 1.8160\n",
      "Epoch [26/100], Step [23100/24597], Loss: 1.6807\n",
      "Epoch [26/100], Step [23200/24597], Loss: 1.7847\n",
      "Epoch [26/100], Step [23300/24597], Loss: 1.6251\n",
      "Epoch [26/100], Step [23400/24597], Loss: 1.5076\n",
      "Epoch [26/100], Step [23500/24597], Loss: 1.6358\n",
      "Epoch [26/100], Step [23600/24597], Loss: 1.5107\n",
      "Epoch [26/100], Step [23700/24597], Loss: 1.7924\n",
      "Epoch [26/100], Step [23800/24597], Loss: 1.6093\n",
      "Epoch [26/100], Step [23900/24597], Loss: 1.6995\n",
      "Epoch [26/100], Step [24000/24597], Loss: 1.7296\n",
      "Epoch [26/100], Step [24100/24597], Loss: 1.6177\n",
      "Epoch [26/100], Step [24200/24597], Loss: 1.6830\n",
      "Epoch [26/100], Step [24300/24597], Loss: 1.5855\n",
      "Epoch [26/100], Step [24400/24597], Loss: 1.6498\n",
      "Epoch [26/100], Step [24500/24597], Loss: 1.5712\n",
      "Epoch [27/100], Step [100/24597], Loss: 1.6156\n",
      "Epoch [27/100], Step [200/24597], Loss: 1.4845\n",
      "Epoch [27/100], Step [300/24597], Loss: 1.6945\n",
      "Epoch [27/100], Step [400/24597], Loss: 1.8571\n",
      "Epoch [27/100], Step [500/24597], Loss: 1.4804\n",
      "Epoch [27/100], Step [600/24597], Loss: 1.6382\n",
      "Epoch [27/100], Step [700/24597], Loss: 1.6414\n",
      "Epoch [27/100], Step [800/24597], Loss: 1.4593\n",
      "Epoch [27/100], Step [900/24597], Loss: 1.5334\n",
      "Epoch [27/100], Step [1000/24597], Loss: 1.6161\n",
      "Epoch [27/100], Step [1100/24597], Loss: 1.6306\n",
      "Epoch [27/100], Step [1200/24597], Loss: 1.7263\n",
      "Epoch [27/100], Step [1300/24597], Loss: 1.3472\n",
      "Epoch [27/100], Step [1400/24597], Loss: 1.8992\n",
      "Epoch [27/100], Step [1500/24597], Loss: 1.7127\n",
      "Epoch [27/100], Step [1600/24597], Loss: 1.8232\n",
      "Epoch [27/100], Step [1700/24597], Loss: 1.4689\n",
      "Epoch [27/100], Step [1800/24597], Loss: 1.6394\n",
      "Epoch [27/100], Step [1900/24597], Loss: 1.7765\n",
      "Epoch [27/100], Step [2000/24597], Loss: 1.7306\n",
      "Epoch [27/100], Step [2100/24597], Loss: 1.5835\n",
      "Epoch [27/100], Step [2200/24597], Loss: 1.6324\n",
      "Epoch [27/100], Step [2300/24597], Loss: 1.6991\n",
      "Epoch [27/100], Step [2400/24597], Loss: 1.4315\n",
      "Epoch [27/100], Step [2500/24597], Loss: 1.3682\n",
      "Epoch [27/100], Step [2600/24597], Loss: 1.7862\n",
      "Epoch [27/100], Step [2700/24597], Loss: 1.8208\n",
      "Epoch [27/100], Step [2800/24597], Loss: 1.4910\n",
      "Epoch [27/100], Step [2900/24597], Loss: 1.5713\n",
      "Epoch [27/100], Step [3000/24597], Loss: 1.5527\n",
      "Epoch [27/100], Step [3100/24597], Loss: 1.6437\n",
      "Epoch [27/100], Step [3200/24597], Loss: 1.3247\n",
      "Epoch [27/100], Step [3300/24597], Loss: 1.4085\n",
      "Epoch [27/100], Step [3400/24597], Loss: 1.5443\n",
      "Epoch [27/100], Step [3500/24597], Loss: 1.5535\n",
      "Epoch [27/100], Step [3600/24597], Loss: 1.6080\n",
      "Epoch [27/100], Step [3700/24597], Loss: 1.4788\n",
      "Epoch [27/100], Step [3800/24597], Loss: 1.6149\n",
      "Epoch [27/100], Step [3900/24597], Loss: 1.6729\n",
      "Epoch [27/100], Step [4000/24597], Loss: 1.5972\n",
      "Epoch [27/100], Step [4100/24597], Loss: 1.5491\n",
      "Epoch [27/100], Step [4200/24597], Loss: 1.6262\n",
      "Epoch [27/100], Step [4300/24597], Loss: 1.4627\n",
      "Epoch [27/100], Step [4400/24597], Loss: 1.5982\n",
      "Epoch [27/100], Step [4500/24597], Loss: 1.4579\n",
      "Epoch [27/100], Step [4600/24597], Loss: 1.5447\n",
      "Epoch [27/100], Step [4700/24597], Loss: 1.5689\n",
      "Epoch [27/100], Step [4800/24597], Loss: 1.7430\n",
      "Epoch [27/100], Step [4900/24597], Loss: 1.7493\n",
      "Epoch [27/100], Step [5000/24597], Loss: 1.4215\n",
      "Epoch [27/100], Step [5100/24597], Loss: 1.5113\n",
      "Epoch [27/100], Step [5200/24597], Loss: 1.7523\n",
      "Epoch [27/100], Step [5300/24597], Loss: 1.7414\n",
      "Epoch [27/100], Step [5400/24597], Loss: 1.6633\n",
      "Epoch [27/100], Step [5500/24597], Loss: 1.5431\n",
      "Epoch [27/100], Step [5600/24597], Loss: 1.4312\n",
      "Epoch [27/100], Step [5700/24597], Loss: 1.6617\n",
      "Epoch [27/100], Step [5800/24597], Loss: 1.7204\n",
      "Epoch [27/100], Step [5900/24597], Loss: 1.6820\n",
      "Epoch [27/100], Step [6000/24597], Loss: 1.7500\n",
      "Epoch [27/100], Step [6100/24597], Loss: 1.5218\n",
      "Epoch [27/100], Step [6200/24597], Loss: 1.5614\n",
      "Epoch [27/100], Step [6300/24597], Loss: 1.5316\n",
      "Epoch [27/100], Step [6400/24597], Loss: 1.7341\n",
      "Epoch [27/100], Step [6500/24597], Loss: 1.6952\n",
      "Epoch [27/100], Step [6600/24597], Loss: 1.6777\n",
      "Epoch [27/100], Step [6700/24597], Loss: 1.7868\n",
      "Epoch [27/100], Step [6800/24597], Loss: 1.7820\n",
      "Epoch [27/100], Step [6900/24597], Loss: 1.4639\n",
      "Epoch [27/100], Step [7000/24597], Loss: 1.6022\n",
      "Epoch [27/100], Step [7100/24597], Loss: 1.7045\n",
      "Epoch [27/100], Step [7200/24597], Loss: 1.6508\n",
      "Epoch [27/100], Step [7300/24597], Loss: 1.7966\n",
      "Epoch [27/100], Step [7400/24597], Loss: 1.9350\n",
      "Epoch [27/100], Step [7500/24597], Loss: 1.5462\n",
      "Epoch [27/100], Step [7600/24597], Loss: 1.6215\n",
      "Epoch [27/100], Step [7700/24597], Loss: 1.5241\n",
      "Epoch [27/100], Step [7800/24597], Loss: 1.5802\n",
      "Epoch [27/100], Step [7900/24597], Loss: 1.7467\n",
      "Epoch [27/100], Step [8000/24597], Loss: 1.5638\n",
      "Epoch [27/100], Step [8100/24597], Loss: 1.6866\n",
      "Epoch [27/100], Step [8200/24597], Loss: 1.3810\n",
      "Epoch [27/100], Step [8300/24597], Loss: 1.5491\n",
      "Epoch [27/100], Step [8400/24597], Loss: 1.5862\n",
      "Epoch [27/100], Step [8500/24597], Loss: 1.5191\n",
      "Epoch [27/100], Step [8600/24597], Loss: 1.5502\n",
      "Epoch [27/100], Step [8700/24597], Loss: 1.6275\n",
      "Epoch [27/100], Step [8800/24597], Loss: 1.5658\n",
      "Epoch [27/100], Step [8900/24597], Loss: 1.5540\n",
      "Epoch [27/100], Step [9000/24597], Loss: 1.7000\n",
      "Epoch [27/100], Step [9100/24597], Loss: 1.3223\n",
      "Epoch [27/100], Step [9200/24597], Loss: 1.6991\n",
      "Epoch [27/100], Step [9300/24597], Loss: 1.6570\n",
      "Epoch [27/100], Step [9400/24597], Loss: 1.7721\n",
      "Epoch [27/100], Step [9500/24597], Loss: 1.7602\n",
      "Epoch [27/100], Step [9600/24597], Loss: 1.3355\n",
      "Epoch [27/100], Step [9700/24597], Loss: 1.6127\n",
      "Epoch [27/100], Step [9800/24597], Loss: 1.6233\n",
      "Epoch [27/100], Step [9900/24597], Loss: 1.7208\n",
      "Epoch [27/100], Step [10000/24597], Loss: 1.5880\n",
      "Epoch [27/100], Step [10100/24597], Loss: 1.7738\n",
      "Epoch [27/100], Step [10200/24597], Loss: 1.6207\n",
      "Epoch [27/100], Step [10300/24597], Loss: 1.5620\n",
      "Epoch [27/100], Step [10400/24597], Loss: 1.5057\n",
      "Epoch [27/100], Step [10500/24597], Loss: 1.4237\n",
      "Epoch [27/100], Step [10600/24597], Loss: 1.6093\n",
      "Epoch [27/100], Step [10700/24597], Loss: 1.6901\n",
      "Epoch [27/100], Step [10800/24597], Loss: 1.8118\n",
      "Epoch [27/100], Step [10900/24597], Loss: 1.5910\n",
      "Epoch [27/100], Step [11000/24597], Loss: 1.6537\n",
      "Epoch [27/100], Step [11100/24597], Loss: 1.6106\n",
      "Epoch [27/100], Step [11200/24597], Loss: 1.6744\n",
      "Epoch [27/100], Step [11300/24597], Loss: 1.5461\n",
      "Epoch [27/100], Step [11400/24597], Loss: 1.4543\n",
      "Epoch [27/100], Step [11500/24597], Loss: 1.6735\n",
      "Epoch [27/100], Step [11600/24597], Loss: 1.5675\n",
      "Epoch [27/100], Step [11700/24597], Loss: 1.7041\n",
      "Epoch [27/100], Step [11800/24597], Loss: 1.4574\n",
      "Epoch [27/100], Step [11900/24597], Loss: 1.7001\n",
      "Epoch [27/100], Step [12000/24597], Loss: 1.5025\n",
      "Epoch [27/100], Step [12100/24597], Loss: 1.4162\n",
      "Epoch [27/100], Step [12200/24597], Loss: 1.9005\n",
      "Epoch [27/100], Step [12300/24597], Loss: 1.3296\n",
      "Epoch [27/100], Step [12400/24597], Loss: 1.5312\n",
      "Epoch [27/100], Step [12500/24597], Loss: 1.5000\n",
      "Epoch [27/100], Step [12600/24597], Loss: 1.9011\n",
      "Epoch [27/100], Step [12700/24597], Loss: 1.5368\n",
      "Epoch [27/100], Step [12800/24597], Loss: 1.7363\n",
      "Epoch [27/100], Step [12900/24597], Loss: 1.3965\n",
      "Epoch [27/100], Step [13000/24597], Loss: 1.5443\n",
      "Epoch [27/100], Step [13100/24597], Loss: 1.8336\n",
      "Epoch [27/100], Step [13200/24597], Loss: 1.5606\n",
      "Epoch [27/100], Step [13300/24597], Loss: 1.6575\n",
      "Epoch [27/100], Step [13400/24597], Loss: 1.6707\n",
      "Epoch [27/100], Step [13500/24597], Loss: 1.4829\n",
      "Epoch [27/100], Step [13600/24597], Loss: 1.5300\n",
      "Epoch [27/100], Step [13700/24597], Loss: 1.6630\n",
      "Epoch [27/100], Step [13800/24597], Loss: 1.5607\n",
      "Epoch [27/100], Step [13900/24597], Loss: 1.4083\n",
      "Epoch [27/100], Step [14000/24597], Loss: 1.6140\n",
      "Epoch [27/100], Step [14100/24597], Loss: 1.7178\n",
      "Epoch [27/100], Step [14200/24597], Loss: 1.6652\n",
      "Epoch [27/100], Step [14300/24597], Loss: 1.7469\n",
      "Epoch [27/100], Step [14400/24597], Loss: 1.5819\n",
      "Epoch [27/100], Step [14500/24597], Loss: 1.7135\n",
      "Epoch [27/100], Step [14600/24597], Loss: 1.6517\n",
      "Epoch [27/100], Step [14700/24597], Loss: 1.6146\n",
      "Epoch [27/100], Step [14800/24597], Loss: 1.7976\n",
      "Epoch [27/100], Step [14900/24597], Loss: 1.6493\n",
      "Epoch [27/100], Step [15000/24597], Loss: 1.3881\n",
      "Epoch [27/100], Step [15100/24597], Loss: 1.6714\n",
      "Epoch [27/100], Step [15200/24597], Loss: 1.7960\n",
      "Epoch [27/100], Step [15300/24597], Loss: 1.6563\n",
      "Epoch [27/100], Step [15400/24597], Loss: 1.5220\n",
      "Epoch [27/100], Step [15500/24597], Loss: 1.6934\n",
      "Epoch [27/100], Step [15600/24597], Loss: 1.5853\n",
      "Epoch [27/100], Step [15700/24597], Loss: 1.6855\n",
      "Epoch [27/100], Step [15800/24597], Loss: 1.4851\n",
      "Epoch [27/100], Step [15900/24597], Loss: 1.5075\n",
      "Epoch [27/100], Step [16000/24597], Loss: 1.6637\n",
      "Epoch [27/100], Step [16100/24597], Loss: 1.4264\n",
      "Epoch [27/100], Step [16200/24597], Loss: 1.5437\n",
      "Epoch [27/100], Step [16300/24597], Loss: 1.5862\n",
      "Epoch [27/100], Step [16400/24597], Loss: 1.5944\n",
      "Epoch [27/100], Step [16500/24597], Loss: 1.6342\n",
      "Epoch [27/100], Step [16600/24597], Loss: 1.6098\n",
      "Epoch [27/100], Step [16700/24597], Loss: 1.6362\n",
      "Epoch [27/100], Step [16800/24597], Loss: 1.5312\n",
      "Epoch [27/100], Step [16900/24597], Loss: 1.6941\n",
      "Epoch [27/100], Step [17000/24597], Loss: 1.5611\n",
      "Epoch [27/100], Step [17100/24597], Loss: 1.6688\n",
      "Epoch [27/100], Step [17200/24597], Loss: 1.6587\n",
      "Epoch [27/100], Step [17300/24597], Loss: 1.6470\n",
      "Epoch [27/100], Step [17400/24597], Loss: 1.4925\n",
      "Epoch [27/100], Step [17500/24597], Loss: 1.6562\n",
      "Epoch [27/100], Step [17600/24597], Loss: 1.6028\n",
      "Epoch [27/100], Step [17700/24597], Loss: 1.7102\n",
      "Epoch [27/100], Step [17800/24597], Loss: 1.6299\n",
      "Epoch [27/100], Step [17900/24597], Loss: 1.5804\n",
      "Epoch [27/100], Step [18000/24597], Loss: 1.8617\n",
      "Epoch [27/100], Step [18100/24597], Loss: 1.7277\n",
      "Epoch [27/100], Step [18200/24597], Loss: 1.3906\n",
      "Epoch [27/100], Step [18300/24597], Loss: 1.4501\n",
      "Epoch [27/100], Step [18400/24597], Loss: 1.7950\n",
      "Epoch [27/100], Step [18500/24597], Loss: 1.6604\n",
      "Epoch [27/100], Step [18600/24597], Loss: 1.5117\n",
      "Epoch [27/100], Step [18700/24597], Loss: 1.4566\n",
      "Epoch [27/100], Step [18800/24597], Loss: 1.3673\n",
      "Epoch [27/100], Step [18900/24597], Loss: 1.5052\n",
      "Epoch [27/100], Step [19000/24597], Loss: 1.5262\n",
      "Epoch [27/100], Step [19100/24597], Loss: 1.6343\n",
      "Epoch [27/100], Step [19200/24597], Loss: 1.8231\n",
      "Epoch [27/100], Step [19300/24597], Loss: 1.6431\n",
      "Epoch [27/100], Step [19400/24597], Loss: 1.5751\n",
      "Epoch [27/100], Step [19500/24597], Loss: 1.6417\n",
      "Epoch [27/100], Step [19600/24597], Loss: 1.8166\n",
      "Epoch [27/100], Step [19700/24597], Loss: 1.4275\n",
      "Epoch [27/100], Step [19800/24597], Loss: 1.6939\n",
      "Epoch [27/100], Step [19900/24597], Loss: 1.6729\n",
      "Epoch [27/100], Step [20000/24597], Loss: 1.5434\n",
      "Epoch [27/100], Step [20100/24597], Loss: 1.5978\n",
      "Epoch [27/100], Step [20200/24597], Loss: 1.6281\n",
      "Epoch [27/100], Step [20300/24597], Loss: 1.5655\n",
      "Epoch [27/100], Step [20400/24597], Loss: 1.7594\n",
      "Epoch [27/100], Step [20500/24597], Loss: 1.4965\n",
      "Epoch [27/100], Step [20600/24597], Loss: 1.5509\n",
      "Epoch [27/100], Step [20700/24597], Loss: 1.6771\n",
      "Epoch [27/100], Step [20800/24597], Loss: 1.6961\n",
      "Epoch [27/100], Step [20900/24597], Loss: 1.4605\n",
      "Epoch [27/100], Step [21000/24597], Loss: 1.7647\n",
      "Epoch [27/100], Step [21100/24597], Loss: 1.4880\n",
      "Epoch [27/100], Step [21200/24597], Loss: 1.8965\n",
      "Epoch [27/100], Step [21300/24597], Loss: 1.7584\n",
      "Epoch [27/100], Step [21400/24597], Loss: 1.3742\n",
      "Epoch [27/100], Step [21500/24597], Loss: 1.7823\n",
      "Epoch [27/100], Step [21600/24597], Loss: 1.4204\n",
      "Epoch [27/100], Step [21700/24597], Loss: 1.5896\n",
      "Epoch [27/100], Step [21800/24597], Loss: 1.6197\n",
      "Epoch [27/100], Step [21900/24597], Loss: 1.5173\n",
      "Epoch [27/100], Step [22000/24597], Loss: 1.6612\n",
      "Epoch [27/100], Step [22100/24597], Loss: 1.5244\n",
      "Epoch [27/100], Step [22200/24597], Loss: 1.7291\n",
      "Epoch [27/100], Step [22300/24597], Loss: 1.4835\n",
      "Epoch [27/100], Step [22400/24597], Loss: 1.7268\n",
      "Epoch [27/100], Step [22500/24597], Loss: 1.6159\n",
      "Epoch [27/100], Step [22600/24597], Loss: 1.6564\n",
      "Epoch [27/100], Step [22700/24597], Loss: 1.6373\n",
      "Epoch [27/100], Step [22800/24597], Loss: 1.8664\n",
      "Epoch [27/100], Step [22900/24597], Loss: 1.5429\n",
      "Epoch [27/100], Step [23000/24597], Loss: 1.7126\n",
      "Epoch [27/100], Step [23100/24597], Loss: 1.5636\n",
      "Epoch [27/100], Step [23200/24597], Loss: 1.7076\n",
      "Epoch [27/100], Step [23300/24597], Loss: 1.8035\n",
      "Epoch [27/100], Step [23400/24597], Loss: 1.7273\n",
      "Epoch [27/100], Step [23500/24597], Loss: 1.5424\n",
      "Epoch [27/100], Step [23600/24597], Loss: 1.5416\n",
      "Epoch [27/100], Step [23700/24597], Loss: 1.6352\n",
      "Epoch [27/100], Step [23800/24597], Loss: 1.4683\n",
      "Epoch [27/100], Step [23900/24597], Loss: 1.7126\n",
      "Epoch [27/100], Step [24000/24597], Loss: 1.3823\n",
      "Epoch [27/100], Step [24100/24597], Loss: 1.6467\n",
      "Epoch [27/100], Step [24200/24597], Loss: 1.7387\n",
      "Epoch [27/100], Step [24300/24597], Loss: 1.7191\n",
      "Epoch [27/100], Step [24400/24597], Loss: 1.6043\n",
      "Epoch [27/100], Step [24500/24597], Loss: 1.5196\n",
      "Epoch [28/100], Step [100/24597], Loss: 1.7631\n",
      "Epoch [28/100], Step [200/24597], Loss: 1.5563\n",
      "Epoch [28/100], Step [300/24597], Loss: 1.6542\n",
      "Epoch [28/100], Step [400/24597], Loss: 1.6120\n",
      "Epoch [28/100], Step [500/24597], Loss: 1.7903\n",
      "Epoch [28/100], Step [600/24597], Loss: 1.4421\n",
      "Epoch [28/100], Step [700/24597], Loss: 1.5931\n",
      "Epoch [28/100], Step [800/24597], Loss: 1.6507\n",
      "Epoch [28/100], Step [900/24597], Loss: 1.5965\n",
      "Epoch [28/100], Step [1000/24597], Loss: 1.7156\n",
      "Epoch [28/100], Step [1100/24597], Loss: 1.4255\n",
      "Epoch [28/100], Step [1200/24597], Loss: 1.3809\n",
      "Epoch [28/100], Step [1300/24597], Loss: 1.9091\n",
      "Epoch [28/100], Step [1400/24597], Loss: 1.3725\n",
      "Epoch [28/100], Step [1500/24597], Loss: 1.7561\n",
      "Epoch [28/100], Step [1600/24597], Loss: 1.5932\n",
      "Epoch [28/100], Step [1700/24597], Loss: 1.5535\n",
      "Epoch [28/100], Step [1800/24597], Loss: 1.3408\n",
      "Epoch [28/100], Step [1900/24597], Loss: 1.5678\n",
      "Epoch [28/100], Step [2000/24597], Loss: 1.5994\n",
      "Epoch [28/100], Step [2100/24597], Loss: 1.5992\n",
      "Epoch [28/100], Step [2200/24597], Loss: 1.5423\n",
      "Epoch [28/100], Step [2300/24597], Loss: 1.6487\n",
      "Epoch [28/100], Step [2400/24597], Loss: 1.6617\n",
      "Epoch [28/100], Step [2500/24597], Loss: 1.5640\n",
      "Epoch [28/100], Step [2600/24597], Loss: 1.6993\n",
      "Epoch [28/100], Step [2700/24597], Loss: 1.6453\n",
      "Epoch [28/100], Step [2800/24597], Loss: 1.7536\n",
      "Epoch [28/100], Step [2900/24597], Loss: 1.4468\n",
      "Epoch [28/100], Step [3000/24597], Loss: 1.7158\n",
      "Epoch [28/100], Step [3100/24597], Loss: 1.5478\n",
      "Epoch [28/100], Step [3200/24597], Loss: 1.5628\n",
      "Epoch [28/100], Step [3300/24597], Loss: 1.4650\n",
      "Epoch [28/100], Step [3400/24597], Loss: 1.4377\n",
      "Epoch [28/100], Step [3500/24597], Loss: 1.5336\n",
      "Epoch [28/100], Step [3600/24597], Loss: 1.5886\n",
      "Epoch [28/100], Step [3700/24597], Loss: 1.7621\n",
      "Epoch [28/100], Step [3800/24597], Loss: 1.5518\n",
      "Epoch [28/100], Step [3900/24597], Loss: 1.7477\n",
      "Epoch [28/100], Step [4000/24597], Loss: 1.7340\n",
      "Epoch [28/100], Step [4100/24597], Loss: 1.5156\n",
      "Epoch [28/100], Step [4200/24597], Loss: 1.7347\n",
      "Epoch [28/100], Step [4300/24597], Loss: 1.5567\n",
      "Epoch [28/100], Step [4400/24597], Loss: 1.6268\n",
      "Epoch [28/100], Step [4500/24597], Loss: 1.4617\n",
      "Epoch [28/100], Step [4600/24597], Loss: 1.5645\n",
      "Epoch [28/100], Step [4700/24597], Loss: 1.2311\n",
      "Epoch [28/100], Step [4800/24597], Loss: 1.5703\n",
      "Epoch [28/100], Step [4900/24597], Loss: 1.5513\n",
      "Epoch [28/100], Step [5000/24597], Loss: 2.0490\n",
      "Epoch [28/100], Step [5100/24597], Loss: 1.4154\n",
      "Epoch [28/100], Step [5200/24597], Loss: 1.4861\n",
      "Epoch [28/100], Step [5300/24597], Loss: 1.6725\n",
      "Epoch [28/100], Step [5400/24597], Loss: 1.5537\n",
      "Epoch [28/100], Step [5500/24597], Loss: 1.5825\n",
      "Epoch [28/100], Step [5600/24597], Loss: 1.9288\n",
      "Epoch [28/100], Step [5700/24597], Loss: 1.4544\n",
      "Epoch [28/100], Step [5800/24597], Loss: 1.5498\n",
      "Epoch [28/100], Step [5900/24597], Loss: 1.5315\n",
      "Epoch [28/100], Step [6000/24597], Loss: 1.3898\n",
      "Epoch [28/100], Step [6100/24597], Loss: 1.3678\n",
      "Epoch [28/100], Step [6200/24597], Loss: 1.6330\n",
      "Epoch [28/100], Step [6300/24597], Loss: 1.7132\n",
      "Epoch [28/100], Step [6400/24597], Loss: 1.7674\n",
      "Epoch [28/100], Step [6500/24597], Loss: 1.7113\n",
      "Epoch [28/100], Step [6600/24597], Loss: 1.8077\n",
      "Epoch [28/100], Step [6700/24597], Loss: 1.4006\n",
      "Epoch [28/100], Step [6800/24597], Loss: 1.5693\n",
      "Epoch [28/100], Step [6900/24597], Loss: 1.5135\n",
      "Epoch [28/100], Step [7000/24597], Loss: 1.7486\n",
      "Epoch [28/100], Step [7100/24597], Loss: 1.6332\n",
      "Epoch [28/100], Step [7200/24597], Loss: 1.7082\n",
      "Epoch [28/100], Step [7300/24597], Loss: 1.5208\n",
      "Epoch [28/100], Step [7400/24597], Loss: 1.7280\n",
      "Epoch [28/100], Step [7500/24597], Loss: 1.6535\n",
      "Epoch [28/100], Step [7600/24597], Loss: 1.4656\n",
      "Epoch [28/100], Step [7700/24597], Loss: 1.4680\n",
      "Epoch [28/100], Step [7800/24597], Loss: 1.6243\n",
      "Epoch [28/100], Step [7900/24597], Loss: 1.5311\n",
      "Epoch [28/100], Step [8000/24597], Loss: 1.6088\n",
      "Epoch [28/100], Step [8100/24597], Loss: 1.5475\n",
      "Epoch [28/100], Step [8200/24597], Loss: 1.8546\n",
      "Epoch [28/100], Step [8300/24597], Loss: 1.5579\n",
      "Epoch [28/100], Step [8400/24597], Loss: 1.5611\n",
      "Epoch [28/100], Step [8500/24597], Loss: 1.6897\n",
      "Epoch [28/100], Step [8600/24597], Loss: 1.4104\n",
      "Epoch [28/100], Step [8700/24597], Loss: 1.7697\n",
      "Epoch [28/100], Step [8800/24597], Loss: 1.6663\n",
      "Epoch [28/100], Step [8900/24597], Loss: 1.6064\n",
      "Epoch [28/100], Step [9000/24597], Loss: 1.7802\n",
      "Epoch [28/100], Step [9100/24597], Loss: 1.5898\n",
      "Epoch [28/100], Step [9200/24597], Loss: 1.6513\n",
      "Epoch [28/100], Step [9300/24597], Loss: 1.5299\n",
      "Epoch [28/100], Step [9400/24597], Loss: 1.5346\n",
      "Epoch [28/100], Step [9500/24597], Loss: 1.7146\n",
      "Epoch [28/100], Step [9600/24597], Loss: 1.6962\n",
      "Epoch [28/100], Step [9700/24597], Loss: 1.6829\n",
      "Epoch [28/100], Step [9800/24597], Loss: 1.6644\n",
      "Epoch [28/100], Step [9900/24597], Loss: 1.7788\n",
      "Epoch [28/100], Step [10000/24597], Loss: 1.6247\n",
      "Epoch [28/100], Step [10100/24597], Loss: 1.8212\n",
      "Epoch [28/100], Step [10200/24597], Loss: 1.6750\n",
      "Epoch [28/100], Step [10300/24597], Loss: 1.6945\n",
      "Epoch [28/100], Step [10400/24597], Loss: 1.5926\n",
      "Epoch [28/100], Step [10500/24597], Loss: 1.6932\n",
      "Epoch [28/100], Step [10600/24597], Loss: 1.5173\n",
      "Epoch [28/100], Step [10700/24597], Loss: 1.5376\n",
      "Epoch [28/100], Step [10800/24597], Loss: 1.8012\n",
      "Epoch [28/100], Step [10900/24597], Loss: 1.6307\n",
      "Epoch [28/100], Step [11000/24597], Loss: 1.5999\n",
      "Epoch [28/100], Step [11100/24597], Loss: 1.3535\n",
      "Epoch [28/100], Step [11200/24597], Loss: 1.4724\n",
      "Epoch [28/100], Step [11300/24597], Loss: 1.5922\n",
      "Epoch [28/100], Step [11400/24597], Loss: 1.6519\n",
      "Epoch [28/100], Step [11500/24597], Loss: 1.6106\n",
      "Epoch [28/100], Step [11600/24597], Loss: 1.8154\n",
      "Epoch [28/100], Step [11700/24597], Loss: 1.3504\n",
      "Epoch [28/100], Step [11800/24597], Loss: 1.4673\n",
      "Epoch [28/100], Step [11900/24597], Loss: 1.6604\n",
      "Epoch [28/100], Step [12000/24597], Loss: 1.6131\n",
      "Epoch [28/100], Step [12100/24597], Loss: 1.4422\n",
      "Epoch [28/100], Step [12200/24597], Loss: 1.5816\n",
      "Epoch [28/100], Step [12300/24597], Loss: 1.5635\n",
      "Epoch [28/100], Step [12400/24597], Loss: 1.5917\n",
      "Epoch [28/100], Step [12500/24597], Loss: 1.6262\n",
      "Epoch [28/100], Step [12600/24597], Loss: 1.4899\n",
      "Epoch [28/100], Step [12700/24597], Loss: 1.8102\n",
      "Epoch [28/100], Step [12800/24597], Loss: 1.7165\n",
      "Epoch [28/100], Step [12900/24597], Loss: 1.9170\n",
      "Epoch [28/100], Step [13000/24597], Loss: 1.5151\n",
      "Epoch [28/100], Step [13100/24597], Loss: 1.5454\n",
      "Epoch [28/100], Step [13200/24597], Loss: 1.5492\n",
      "Epoch [28/100], Step [13300/24597], Loss: 1.5731\n",
      "Epoch [28/100], Step [13400/24597], Loss: 1.6200\n",
      "Epoch [28/100], Step [13500/24597], Loss: 1.7115\n",
      "Epoch [28/100], Step [13600/24597], Loss: 1.4774\n",
      "Epoch [28/100], Step [13700/24597], Loss: 1.5739\n",
      "Epoch [28/100], Step [13800/24597], Loss: 1.5377\n",
      "Epoch [28/100], Step [13900/24597], Loss: 1.5550\n",
      "Epoch [28/100], Step [14000/24597], Loss: 1.5302\n",
      "Epoch [28/100], Step [14100/24597], Loss: 1.6303\n",
      "Epoch [28/100], Step [14200/24597], Loss: 1.5870\n",
      "Epoch [28/100], Step [14300/24597], Loss: 1.8189\n",
      "Epoch [28/100], Step [14400/24597], Loss: 1.7763\n",
      "Epoch [28/100], Step [14500/24597], Loss: 1.8030\n",
      "Epoch [28/100], Step [14600/24597], Loss: 1.5265\n",
      "Epoch [28/100], Step [14700/24597], Loss: 1.6731\n",
      "Epoch [28/100], Step [14800/24597], Loss: 1.6236\n",
      "Epoch [28/100], Step [14900/24597], Loss: 1.4773\n",
      "Epoch [28/100], Step [15000/24597], Loss: 1.8257\n",
      "Epoch [28/100], Step [15100/24597], Loss: 1.7093\n",
      "Epoch [28/100], Step [15200/24597], Loss: 1.6775\n",
      "Epoch [28/100], Step [15300/24597], Loss: 1.7183\n",
      "Epoch [28/100], Step [15400/24597], Loss: 1.4093\n",
      "Epoch [28/100], Step [15500/24597], Loss: 1.6192\n",
      "Epoch [28/100], Step [15600/24597], Loss: 1.6031\n",
      "Epoch [28/100], Step [15700/24597], Loss: 1.4219\n",
      "Epoch [28/100], Step [15800/24597], Loss: 1.4231\n",
      "Epoch [28/100], Step [15900/24597], Loss: 1.4948\n",
      "Epoch [28/100], Step [16000/24597], Loss: 1.6173\n",
      "Epoch [28/100], Step [16100/24597], Loss: 1.5729\n",
      "Epoch [28/100], Step [16200/24597], Loss: 1.6035\n",
      "Epoch [28/100], Step [16300/24597], Loss: 1.7579\n",
      "Epoch [28/100], Step [16400/24597], Loss: 1.6476\n",
      "Epoch [28/100], Step [16500/24597], Loss: 1.5462\n",
      "Epoch [28/100], Step [16600/24597], Loss: 1.7367\n",
      "Epoch [28/100], Step [16700/24597], Loss: 1.7245\n",
      "Epoch [28/100], Step [16800/24597], Loss: 1.4711\n",
      "Epoch [28/100], Step [16900/24597], Loss: 1.3541\n",
      "Epoch [28/100], Step [17000/24597], Loss: 1.6725\n",
      "Epoch [28/100], Step [17100/24597], Loss: 1.5220\n",
      "Epoch [28/100], Step [17200/24597], Loss: 1.4975\n",
      "Epoch [28/100], Step [17300/24597], Loss: 1.6659\n",
      "Epoch [28/100], Step [17400/24597], Loss: 1.5700\n",
      "Epoch [28/100], Step [17500/24597], Loss: 1.6655\n",
      "Epoch [28/100], Step [17600/24597], Loss: 1.5180\n",
      "Epoch [28/100], Step [17700/24597], Loss: 1.6635\n",
      "Epoch [28/100], Step [17800/24597], Loss: 1.7827\n",
      "Epoch [28/100], Step [17900/24597], Loss: 1.6615\n",
      "Epoch [28/100], Step [18000/24597], Loss: 1.6932\n",
      "Epoch [28/100], Step [18100/24597], Loss: 1.6456\n",
      "Epoch [28/100], Step [18200/24597], Loss: 1.5249\n",
      "Epoch [28/100], Step [18300/24597], Loss: 1.3105\n",
      "Epoch [28/100], Step [18400/24597], Loss: 1.7566\n",
      "Epoch [28/100], Step [18500/24597], Loss: 1.4892\n",
      "Epoch [28/100], Step [18600/24597], Loss: 1.6444\n",
      "Epoch [28/100], Step [18700/24597], Loss: 1.6907\n",
      "Epoch [28/100], Step [18800/24597], Loss: 1.5289\n",
      "Epoch [28/100], Step [18900/24597], Loss: 1.6604\n",
      "Epoch [28/100], Step [19000/24597], Loss: 1.7269\n",
      "Epoch [28/100], Step [19100/24597], Loss: 1.8154\n",
      "Epoch [28/100], Step [19200/24597], Loss: 1.7435\n",
      "Epoch [28/100], Step [19300/24597], Loss: 1.7397\n",
      "Epoch [28/100], Step [19400/24597], Loss: 1.3725\n",
      "Epoch [28/100], Step [19500/24597], Loss: 1.5969\n",
      "Epoch [28/100], Step [19600/24597], Loss: 1.8071\n",
      "Epoch [28/100], Step [19700/24597], Loss: 1.6451\n",
      "Epoch [28/100], Step [19800/24597], Loss: 1.5320\n",
      "Epoch [28/100], Step [19900/24597], Loss: 1.7631\n",
      "Epoch [28/100], Step [20000/24597], Loss: 1.7733\n",
      "Epoch [28/100], Step [20100/24597], Loss: 1.4943\n",
      "Epoch [28/100], Step [20200/24597], Loss: 1.6275\n",
      "Epoch [28/100], Step [20300/24597], Loss: 1.7758\n",
      "Epoch [28/100], Step [20400/24597], Loss: 1.6690\n",
      "Epoch [28/100], Step [20500/24597], Loss: 1.6310\n",
      "Epoch [28/100], Step [20600/24597], Loss: 1.5572\n",
      "Epoch [28/100], Step [20700/24597], Loss: 2.0847\n",
      "Epoch [28/100], Step [20800/24597], Loss: 1.7379\n",
      "Epoch [28/100], Step [20900/24597], Loss: 1.6420\n",
      "Epoch [28/100], Step [21000/24597], Loss: 1.7740\n",
      "Epoch [28/100], Step [21100/24597], Loss: 1.8302\n",
      "Epoch [28/100], Step [21200/24597], Loss: 1.6786\n",
      "Epoch [28/100], Step [21300/24597], Loss: 1.7306\n",
      "Epoch [28/100], Step [21400/24597], Loss: 1.4986\n",
      "Epoch [28/100], Step [21500/24597], Loss: 1.5759\n",
      "Epoch [28/100], Step [21600/24597], Loss: 1.7679\n",
      "Epoch [28/100], Step [21700/24597], Loss: 1.6483\n",
      "Epoch [28/100], Step [21800/24597], Loss: 1.5710\n",
      "Epoch [28/100], Step [21900/24597], Loss: 1.7640\n",
      "Epoch [28/100], Step [22000/24597], Loss: 1.6290\n",
      "Epoch [28/100], Step [22100/24597], Loss: 1.6474\n",
      "Epoch [28/100], Step [22200/24597], Loss: 1.5845\n",
      "Epoch [28/100], Step [22300/24597], Loss: 1.6712\n",
      "Epoch [28/100], Step [22400/24597], Loss: 1.6528\n",
      "Epoch [28/100], Step [22500/24597], Loss: 1.6469\n",
      "Epoch [28/100], Step [22600/24597], Loss: 1.7392\n",
      "Epoch [28/100], Step [22700/24597], Loss: 1.5657\n",
      "Epoch [28/100], Step [22800/24597], Loss: 1.3515\n",
      "Epoch [28/100], Step [22900/24597], Loss: 1.5412\n",
      "Epoch [28/100], Step [23000/24597], Loss: 1.6654\n",
      "Epoch [28/100], Step [23100/24597], Loss: 1.6792\n",
      "Epoch [28/100], Step [23200/24597], Loss: 1.5351\n",
      "Epoch [28/100], Step [23300/24597], Loss: 1.6227\n",
      "Epoch [28/100], Step [23400/24597], Loss: 1.7614\n",
      "Epoch [28/100], Step [23500/24597], Loss: 1.6053\n",
      "Epoch [28/100], Step [23600/24597], Loss: 1.6084\n",
      "Epoch [28/100], Step [23700/24597], Loss: 1.6821\n",
      "Epoch [28/100], Step [23800/24597], Loss: 1.7344\n",
      "Epoch [28/100], Step [23900/24597], Loss: 1.6729\n",
      "Epoch [28/100], Step [24000/24597], Loss: 1.6127\n",
      "Epoch [28/100], Step [24100/24597], Loss: 1.6196\n",
      "Epoch [28/100], Step [24200/24597], Loss: 1.6164\n",
      "Epoch [28/100], Step [24300/24597], Loss: 1.3645\n",
      "Epoch [28/100], Step [24400/24597], Loss: 1.4183\n",
      "Epoch [28/100], Step [24500/24597], Loss: 1.6821\n",
      "Epoch [29/100], Step [100/24597], Loss: 1.8221\n",
      "Epoch [29/100], Step [200/24597], Loss: 1.6239\n",
      "Epoch [29/100], Step [300/24597], Loss: 1.5980\n",
      "Epoch [29/100], Step [400/24597], Loss: 1.5587\n",
      "Epoch [29/100], Step [500/24597], Loss: 1.5342\n",
      "Epoch [29/100], Step [600/24597], Loss: 1.9535\n",
      "Epoch [29/100], Step [700/24597], Loss: 1.5647\n",
      "Epoch [29/100], Step [800/24597], Loss: 1.5370\n",
      "Epoch [29/100], Step [900/24597], Loss: 1.6441\n",
      "Epoch [29/100], Step [1000/24597], Loss: 1.5650\n",
      "Epoch [29/100], Step [1100/24597], Loss: 1.8790\n",
      "Epoch [29/100], Step [1200/24597], Loss: 1.5537\n",
      "Epoch [29/100], Step [1300/24597], Loss: 1.6284\n",
      "Epoch [29/100], Step [1400/24597], Loss: 1.5540\n",
      "Epoch [29/100], Step [1500/24597], Loss: 1.7403\n",
      "Epoch [29/100], Step [1600/24597], Loss: 1.4884\n",
      "Epoch [29/100], Step [1700/24597], Loss: 1.6347\n",
      "Epoch [29/100], Step [1800/24597], Loss: 1.5250\n",
      "Epoch [29/100], Step [1900/24597], Loss: 1.4743\n",
      "Epoch [29/100], Step [2000/24597], Loss: 1.6266\n",
      "Epoch [29/100], Step [2100/24597], Loss: 1.7646\n",
      "Epoch [29/100], Step [2200/24597], Loss: 1.5849\n",
      "Epoch [29/100], Step [2300/24597], Loss: 1.5958\n",
      "Epoch [29/100], Step [2400/24597], Loss: 1.5374\n",
      "Epoch [29/100], Step [2500/24597], Loss: 1.5287\n",
      "Epoch [29/100], Step [2600/24597], Loss: 1.5831\n",
      "Epoch [29/100], Step [2700/24597], Loss: 1.5333\n",
      "Epoch [29/100], Step [2800/24597], Loss: 1.5403\n",
      "Epoch [29/100], Step [2900/24597], Loss: 1.7223\n",
      "Epoch [29/100], Step [3000/24597], Loss: 1.6441\n",
      "Epoch [29/100], Step [3100/24597], Loss: 1.5630\n",
      "Epoch [29/100], Step [3200/24597], Loss: 1.4199\n",
      "Epoch [29/100], Step [3300/24597], Loss: 1.5885\n",
      "Epoch [29/100], Step [3400/24597], Loss: 1.8912\n",
      "Epoch [29/100], Step [3500/24597], Loss: 1.6378\n",
      "Epoch [29/100], Step [3600/24597], Loss: 1.7468\n",
      "Epoch [29/100], Step [3700/24597], Loss: 1.5369\n",
      "Epoch [29/100], Step [3800/24597], Loss: 1.5602\n",
      "Epoch [29/100], Step [3900/24597], Loss: 1.7470\n",
      "Epoch [29/100], Step [4000/24597], Loss: 1.5827\n",
      "Epoch [29/100], Step [4100/24597], Loss: 1.9247\n",
      "Epoch [29/100], Step [4200/24597], Loss: 1.6693\n",
      "Epoch [29/100], Step [4300/24597], Loss: 1.5805\n",
      "Epoch [29/100], Step [4400/24597], Loss: 1.5007\n",
      "Epoch [29/100], Step [4500/24597], Loss: 1.5871\n",
      "Epoch [29/100], Step [4600/24597], Loss: 1.4173\n",
      "Epoch [29/100], Step [4700/24597], Loss: 1.6710\n",
      "Epoch [29/100], Step [4800/24597], Loss: 1.6629\n",
      "Epoch [29/100], Step [4900/24597], Loss: 1.9008\n",
      "Epoch [29/100], Step [5000/24597], Loss: 1.6847\n",
      "Epoch [29/100], Step [5100/24597], Loss: 1.6264\n",
      "Epoch [29/100], Step [5200/24597], Loss: 1.4868\n",
      "Epoch [29/100], Step [5300/24597], Loss: 1.6162\n",
      "Epoch [29/100], Step [5400/24597], Loss: 1.9294\n",
      "Epoch [29/100], Step [5500/24597], Loss: 1.6803\n",
      "Epoch [29/100], Step [5600/24597], Loss: 1.6064\n",
      "Epoch [29/100], Step [5700/24597], Loss: 1.4986\n",
      "Epoch [29/100], Step [5800/24597], Loss: 1.6022\n",
      "Epoch [29/100], Step [5900/24597], Loss: 1.6629\n",
      "Epoch [29/100], Step [6000/24597], Loss: 1.6229\n",
      "Epoch [29/100], Step [6100/24597], Loss: 1.5682\n",
      "Epoch [29/100], Step [6200/24597], Loss: 1.6339\n",
      "Epoch [29/100], Step [6300/24597], Loss: 1.5167\n",
      "Epoch [29/100], Step [6400/24597], Loss: 1.7010\n",
      "Epoch [29/100], Step [6500/24597], Loss: 1.4736\n",
      "Epoch [29/100], Step [6600/24597], Loss: 1.5521\n",
      "Epoch [29/100], Step [6700/24597], Loss: 1.4813\n",
      "Epoch [29/100], Step [6800/24597], Loss: 1.6882\n",
      "Epoch [29/100], Step [6900/24597], Loss: 1.4942\n",
      "Epoch [29/100], Step [7000/24597], Loss: 1.6074\n",
      "Epoch [29/100], Step [7100/24597], Loss: 1.4450\n",
      "Epoch [29/100], Step [7200/24597], Loss: 1.5392\n",
      "Epoch [29/100], Step [7300/24597], Loss: 1.7401\n",
      "Epoch [29/100], Step [7400/24597], Loss: 1.4881\n",
      "Epoch [29/100], Step [7500/24597], Loss: 1.7017\n",
      "Epoch [29/100], Step [7600/24597], Loss: 1.6594\n",
      "Epoch [29/100], Step [7700/24597], Loss: 1.6445\n",
      "Epoch [29/100], Step [7800/24597], Loss: 1.7137\n",
      "Epoch [29/100], Step [7900/24597], Loss: 1.4818\n",
      "Epoch [29/100], Step [8000/24597], Loss: 1.6275\n",
      "Epoch [29/100], Step [8100/24597], Loss: 1.7842\n",
      "Epoch [29/100], Step [8200/24597], Loss: 1.6664\n",
      "Epoch [29/100], Step [8300/24597], Loss: 1.4658\n",
      "Epoch [29/100], Step [8400/24597], Loss: 1.7390\n",
      "Epoch [29/100], Step [8500/24597], Loss: 1.6775\n",
      "Epoch [29/100], Step [8600/24597], Loss: 1.4966\n",
      "Epoch [29/100], Step [8700/24597], Loss: 1.4566\n",
      "Epoch [29/100], Step [8800/24597], Loss: 1.6074\n",
      "Epoch [29/100], Step [8900/24597], Loss: 1.6139\n",
      "Epoch [29/100], Step [9000/24597], Loss: 1.6624\n",
      "Epoch [29/100], Step [9100/24597], Loss: 1.5947\n",
      "Epoch [29/100], Step [9200/24597], Loss: 1.6413\n",
      "Epoch [29/100], Step [9300/24597], Loss: 1.6301\n",
      "Epoch [29/100], Step [9400/24597], Loss: 1.4737\n",
      "Epoch [29/100], Step [9500/24597], Loss: 1.8074\n",
      "Epoch [29/100], Step [9600/24597], Loss: 1.6340\n",
      "Epoch [29/100], Step [9700/24597], Loss: 1.6274\n",
      "Epoch [29/100], Step [9800/24597], Loss: 1.4254\n",
      "Epoch [29/100], Step [9900/24597], Loss: 1.5453\n",
      "Epoch [29/100], Step [10000/24597], Loss: 1.5463\n",
      "Epoch [29/100], Step [10100/24597], Loss: 1.5501\n",
      "Epoch [29/100], Step [10200/24597], Loss: 1.4490\n",
      "Epoch [29/100], Step [10300/24597], Loss: 1.8757\n",
      "Epoch [29/100], Step [10400/24597], Loss: 1.8182\n",
      "Epoch [29/100], Step [10500/24597], Loss: 1.7456\n",
      "Epoch [29/100], Step [10600/24597], Loss: 1.6886\n",
      "Epoch [29/100], Step [10700/24597], Loss: 1.5366\n",
      "Epoch [29/100], Step [10800/24597], Loss: 1.7739\n",
      "Epoch [29/100], Step [10900/24597], Loss: 1.7226\n",
      "Epoch [29/100], Step [11000/24597], Loss: 1.5542\n",
      "Epoch [29/100], Step [11100/24597], Loss: 1.5864\n",
      "Epoch [29/100], Step [11200/24597], Loss: 1.7556\n",
      "Epoch [29/100], Step [11300/24597], Loss: 1.8327\n",
      "Epoch [29/100], Step [11400/24597], Loss: 1.5045\n",
      "Epoch [29/100], Step [11500/24597], Loss: 1.8207\n",
      "Epoch [29/100], Step [11600/24597], Loss: 1.7708\n",
      "Epoch [29/100], Step [11700/24597], Loss: 1.6550\n",
      "Epoch [29/100], Step [11800/24597], Loss: 1.7791\n",
      "Epoch [29/100], Step [11900/24597], Loss: 1.4925\n",
      "Epoch [29/100], Step [12000/24597], Loss: 1.6339\n",
      "Epoch [29/100], Step [12100/24597], Loss: 1.6131\n",
      "Epoch [29/100], Step [12200/24597], Loss: 1.4935\n",
      "Epoch [29/100], Step [12300/24597], Loss: 1.6842\n",
      "Epoch [29/100], Step [12400/24597], Loss: 1.7364\n",
      "Epoch [29/100], Step [12500/24597], Loss: 1.6526\n",
      "Epoch [29/100], Step [12600/24597], Loss: 1.6261\n",
      "Epoch [29/100], Step [12700/24597], Loss: 1.4647\n",
      "Epoch [29/100], Step [12800/24597], Loss: 1.6527\n",
      "Epoch [29/100], Step [12900/24597], Loss: 1.9718\n",
      "Epoch [29/100], Step [13000/24597], Loss: 1.7147\n",
      "Epoch [29/100], Step [13100/24597], Loss: 1.4776\n",
      "Epoch [29/100], Step [13200/24597], Loss: 1.7737\n",
      "Epoch [29/100], Step [13300/24597], Loss: 1.4926\n",
      "Epoch [29/100], Step [13400/24597], Loss: 1.7939\n",
      "Epoch [29/100], Step [13500/24597], Loss: 1.5494\n",
      "Epoch [29/100], Step [13600/24597], Loss: 1.6446\n",
      "Epoch [29/100], Step [13700/24597], Loss: 1.7537\n",
      "Epoch [29/100], Step [13800/24597], Loss: 1.6009\n",
      "Epoch [29/100], Step [13900/24597], Loss: 1.6665\n",
      "Epoch [29/100], Step [14000/24597], Loss: 1.5935\n",
      "Epoch [29/100], Step [14100/24597], Loss: 1.3479\n",
      "Epoch [29/100], Step [14200/24597], Loss: 1.4959\n",
      "Epoch [29/100], Step [14300/24597], Loss: 1.4477\n",
      "Epoch [29/100], Step [14400/24597], Loss: 1.6238\n",
      "Epoch [29/100], Step [14500/24597], Loss: 1.7697\n",
      "Epoch [29/100], Step [14600/24597], Loss: 1.5610\n",
      "Epoch [29/100], Step [14700/24597], Loss: 1.5900\n",
      "Epoch [29/100], Step [14800/24597], Loss: 1.5796\n",
      "Epoch [29/100], Step [14900/24597], Loss: 1.5168\n",
      "Epoch [29/100], Step [15000/24597], Loss: 1.5505\n",
      "Epoch [29/100], Step [15100/24597], Loss: 1.6501\n",
      "Epoch [29/100], Step [15200/24597], Loss: 1.4166\n",
      "Epoch [29/100], Step [15300/24597], Loss: 1.8481\n",
      "Epoch [29/100], Step [15400/24597], Loss: 1.6057\n",
      "Epoch [29/100], Step [15500/24597], Loss: 1.7108\n",
      "Epoch [29/100], Step [15600/24597], Loss: 1.6885\n",
      "Epoch [29/100], Step [15700/24597], Loss: 1.6210\n",
      "Epoch [29/100], Step [15800/24597], Loss: 1.6107\n",
      "Epoch [29/100], Step [15900/24597], Loss: 1.6019\n",
      "Epoch [29/100], Step [16000/24597], Loss: 1.6227\n",
      "Epoch [29/100], Step [16100/24597], Loss: 1.6824\n",
      "Epoch [29/100], Step [16200/24597], Loss: 1.4042\n",
      "Epoch [29/100], Step [16300/24597], Loss: 1.4442\n",
      "Epoch [29/100], Step [16400/24597], Loss: 1.5966\n",
      "Epoch [29/100], Step [16500/24597], Loss: 1.5957\n",
      "Epoch [29/100], Step [16600/24597], Loss: 1.6321\n",
      "Epoch [29/100], Step [16700/24597], Loss: 1.9665\n",
      "Epoch [29/100], Step [16800/24597], Loss: 1.6648\n",
      "Epoch [29/100], Step [16900/24597], Loss: 1.4258\n",
      "Epoch [29/100], Step [17000/24597], Loss: 1.5708\n",
      "Epoch [29/100], Step [17100/24597], Loss: 1.8374\n",
      "Epoch [29/100], Step [17200/24597], Loss: 1.7346\n",
      "Epoch [29/100], Step [17300/24597], Loss: 1.5011\n",
      "Epoch [29/100], Step [17400/24597], Loss: 1.7230\n",
      "Epoch [29/100], Step [17500/24597], Loss: 1.5519\n",
      "Epoch [29/100], Step [17600/24597], Loss: 1.6244\n",
      "Epoch [29/100], Step [17700/24597], Loss: 1.6127\n",
      "Epoch [29/100], Step [17800/24597], Loss: 1.8427\n",
      "Epoch [29/100], Step [17900/24597], Loss: 1.6126\n",
      "Epoch [29/100], Step [18000/24597], Loss: 1.5604\n",
      "Epoch [29/100], Step [18100/24597], Loss: 1.4737\n",
      "Epoch [29/100], Step [18200/24597], Loss: 1.4521\n",
      "Epoch [29/100], Step [18300/24597], Loss: 1.7319\n",
      "Epoch [29/100], Step [18400/24597], Loss: 1.5826\n",
      "Epoch [29/100], Step [18500/24597], Loss: 1.7646\n",
      "Epoch [29/100], Step [18600/24597], Loss: 1.6432\n",
      "Epoch [29/100], Step [18700/24597], Loss: 1.7106\n",
      "Epoch [29/100], Step [18800/24597], Loss: 1.8381\n",
      "Epoch [29/100], Step [18900/24597], Loss: 1.7491\n",
      "Epoch [29/100], Step [19000/24597], Loss: 1.6150\n",
      "Epoch [29/100], Step [19100/24597], Loss: 1.7485\n",
      "Epoch [29/100], Step [19200/24597], Loss: 1.5916\n",
      "Epoch [29/100], Step [19300/24597], Loss: 1.6279\n",
      "Epoch [29/100], Step [19400/24597], Loss: 1.8040\n",
      "Epoch [29/100], Step [19500/24597], Loss: 1.5731\n",
      "Epoch [29/100], Step [19600/24597], Loss: 1.5797\n",
      "Epoch [29/100], Step [19700/24597], Loss: 1.5564\n",
      "Epoch [29/100], Step [19800/24597], Loss: 1.4963\n",
      "Epoch [29/100], Step [19900/24597], Loss: 1.5751\n",
      "Epoch [29/100], Step [20000/24597], Loss: 1.6689\n",
      "Epoch [29/100], Step [20100/24597], Loss: 1.5726\n",
      "Epoch [29/100], Step [20200/24597], Loss: 1.5724\n",
      "Epoch [29/100], Step [20300/24597], Loss: 1.6889\n",
      "Epoch [29/100], Step [20400/24597], Loss: 1.6871\n",
      "Epoch [29/100], Step [20500/24597], Loss: 1.4082\n",
      "Epoch [29/100], Step [20600/24597], Loss: 1.8205\n",
      "Epoch [29/100], Step [20700/24597], Loss: 1.8637\n",
      "Epoch [29/100], Step [20800/24597], Loss: 1.6118\n",
      "Epoch [29/100], Step [20900/24597], Loss: 1.6252\n",
      "Epoch [29/100], Step [21000/24597], Loss: 1.7356\n",
      "Epoch [29/100], Step [21100/24597], Loss: 1.3593\n",
      "Epoch [29/100], Step [21200/24597], Loss: 1.5486\n",
      "Epoch [29/100], Step [21300/24597], Loss: 1.4797\n",
      "Epoch [29/100], Step [21400/24597], Loss: 1.8322\n",
      "Epoch [29/100], Step [21500/24597], Loss: 1.8787\n",
      "Epoch [29/100], Step [21600/24597], Loss: 1.5745\n",
      "Epoch [29/100], Step [21700/24597], Loss: 1.6420\n",
      "Epoch [29/100], Step [21800/24597], Loss: 1.4860\n",
      "Epoch [29/100], Step [21900/24597], Loss: 1.5314\n",
      "Epoch [29/100], Step [22000/24597], Loss: 1.7644\n",
      "Epoch [29/100], Step [22100/24597], Loss: 1.8434\n",
      "Epoch [29/100], Step [22200/24597], Loss: 1.6701\n",
      "Epoch [29/100], Step [22300/24597], Loss: 1.4960\n",
      "Epoch [29/100], Step [22400/24597], Loss: 1.5298\n",
      "Epoch [29/100], Step [22500/24597], Loss: 1.4829\n",
      "Epoch [29/100], Step [22600/24597], Loss: 1.3639\n",
      "Epoch [29/100], Step [22700/24597], Loss: 1.4633\n",
      "Epoch [29/100], Step [22800/24597], Loss: 1.6212\n",
      "Epoch [29/100], Step [22900/24597], Loss: 1.3935\n",
      "Epoch [29/100], Step [23000/24597], Loss: 1.7408\n",
      "Epoch [29/100], Step [23100/24597], Loss: 1.5108\n",
      "Epoch [29/100], Step [23200/24597], Loss: 1.6132\n",
      "Epoch [29/100], Step [23300/24597], Loss: 1.6439\n",
      "Epoch [29/100], Step [23400/24597], Loss: 1.7513\n",
      "Epoch [29/100], Step [23500/24597], Loss: 1.5748\n",
      "Epoch [29/100], Step [23600/24597], Loss: 1.7111\n",
      "Epoch [29/100], Step [23700/24597], Loss: 1.4729\n",
      "Epoch [29/100], Step [23800/24597], Loss: 1.7705\n",
      "Epoch [29/100], Step [23900/24597], Loss: 1.4185\n",
      "Epoch [29/100], Step [24000/24597], Loss: 1.2877\n",
      "Epoch [29/100], Step [24100/24597], Loss: 1.5797\n",
      "Epoch [29/100], Step [24200/24597], Loss: 1.4726\n",
      "Epoch [29/100], Step [24300/24597], Loss: 1.7643\n",
      "Epoch [29/100], Step [24400/24597], Loss: 1.7922\n",
      "Epoch [29/100], Step [24500/24597], Loss: 1.4979\n",
      "Epoch [30/100], Step [100/24597], Loss: 1.5754\n",
      "Epoch [30/100], Step [200/24597], Loss: 1.4479\n",
      "Epoch [30/100], Step [300/24597], Loss: 1.5672\n",
      "Epoch [30/100], Step [400/24597], Loss: 1.6392\n",
      "Epoch [30/100], Step [500/24597], Loss: 1.5024\n",
      "Epoch [30/100], Step [600/24597], Loss: 1.5323\n",
      "Epoch [30/100], Step [700/24597], Loss: 1.7340\n",
      "Epoch [30/100], Step [800/24597], Loss: 1.8555\n",
      "Epoch [30/100], Step [900/24597], Loss: 1.5766\n",
      "Epoch [30/100], Step [1000/24597], Loss: 1.2850\n",
      "Epoch [30/100], Step [1100/24597], Loss: 1.5046\n",
      "Epoch [30/100], Step [1200/24597], Loss: 1.5055\n",
      "Epoch [30/100], Step [1300/24597], Loss: 1.5342\n",
      "Epoch [30/100], Step [1400/24597], Loss: 1.6140\n",
      "Epoch [30/100], Step [1500/24597], Loss: 1.6903\n",
      "Epoch [30/100], Step [1600/24597], Loss: 1.5017\n",
      "Epoch [30/100], Step [1700/24597], Loss: 1.5709\n",
      "Epoch [30/100], Step [1800/24597], Loss: 1.8338\n",
      "Epoch [30/100], Step [1900/24597], Loss: 1.6018\n",
      "Epoch [30/100], Step [2000/24597], Loss: 1.7656\n",
      "Epoch [30/100], Step [2100/24597], Loss: 1.7949\n",
      "Epoch [30/100], Step [2200/24597], Loss: 1.6591\n",
      "Epoch [30/100], Step [2300/24597], Loss: 1.6100\n",
      "Epoch [30/100], Step [2400/24597], Loss: 1.4954\n",
      "Epoch [30/100], Step [2500/24597], Loss: 1.6327\n",
      "Epoch [30/100], Step [2600/24597], Loss: 1.6827\n",
      "Epoch [30/100], Step [2700/24597], Loss: 1.6535\n",
      "Epoch [30/100], Step [2800/24597], Loss: 1.6405\n",
      "Epoch [30/100], Step [2900/24597], Loss: 1.7876\n",
      "Epoch [30/100], Step [3000/24597], Loss: 1.5842\n",
      "Epoch [30/100], Step [3100/24597], Loss: 1.8629\n",
      "Epoch [30/100], Step [3200/24597], Loss: 1.5807\n",
      "Epoch [30/100], Step [3300/24597], Loss: 1.7146\n",
      "Epoch [30/100], Step [3400/24597], Loss: 1.5662\n",
      "Epoch [30/100], Step [3500/24597], Loss: 1.5010\n",
      "Epoch [30/100], Step [3600/24597], Loss: 1.6555\n",
      "Epoch [30/100], Step [3700/24597], Loss: 1.7627\n",
      "Epoch [30/100], Step [3800/24597], Loss: 1.8258\n",
      "Epoch [30/100], Step [3900/24597], Loss: 1.6162\n",
      "Epoch [30/100], Step [4000/24597], Loss: 1.5331\n",
      "Epoch [30/100], Step [4100/24597], Loss: 1.7215\n",
      "Epoch [30/100], Step [4200/24597], Loss: 1.7179\n",
      "Epoch [30/100], Step [4300/24597], Loss: 1.6003\n",
      "Epoch [30/100], Step [4400/24597], Loss: 1.4397\n",
      "Epoch [30/100], Step [4500/24597], Loss: 1.7187\n",
      "Epoch [30/100], Step [4600/24597], Loss: 1.4957\n",
      "Epoch [30/100], Step [4700/24597], Loss: 1.5804\n",
      "Epoch [30/100], Step [4800/24597], Loss: 1.6354\n",
      "Epoch [30/100], Step [4900/24597], Loss: 1.5690\n",
      "Epoch [30/100], Step [5000/24597], Loss: 1.5900\n",
      "Epoch [30/100], Step [5100/24597], Loss: 1.5709\n",
      "Epoch [30/100], Step [5200/24597], Loss: 1.6135\n",
      "Epoch [30/100], Step [5300/24597], Loss: 1.6086\n",
      "Epoch [30/100], Step [5400/24597], Loss: 1.7151\n",
      "Epoch [30/100], Step [5500/24597], Loss: 1.6327\n",
      "Epoch [30/100], Step [5600/24597], Loss: 1.8296\n",
      "Epoch [30/100], Step [5700/24597], Loss: 1.5396\n",
      "Epoch [30/100], Step [5800/24597], Loss: 1.5225\n",
      "Epoch [30/100], Step [5900/24597], Loss: 1.3810\n",
      "Epoch [30/100], Step [6000/24597], Loss: 1.8021\n",
      "Epoch [30/100], Step [6100/24597], Loss: 1.7242\n",
      "Epoch [30/100], Step [6200/24597], Loss: 1.8326\n",
      "Epoch [30/100], Step [6300/24597], Loss: 1.3865\n",
      "Epoch [30/100], Step [6400/24597], Loss: 1.6376\n",
      "Epoch [30/100], Step [6500/24597], Loss: 1.5858\n",
      "Epoch [30/100], Step [6600/24597], Loss: 1.5556\n",
      "Epoch [30/100], Step [6700/24597], Loss: 1.5387\n",
      "Epoch [30/100], Step [6800/24597], Loss: 1.6042\n",
      "Epoch [30/100], Step [6900/24597], Loss: 1.5858\n",
      "Epoch [30/100], Step [7000/24597], Loss: 1.5965\n",
      "Epoch [30/100], Step [7100/24597], Loss: 1.5309\n",
      "Epoch [30/100], Step [7200/24597], Loss: 1.5760\n",
      "Epoch [30/100], Step [7300/24597], Loss: 1.5271\n",
      "Epoch [30/100], Step [7400/24597], Loss: 1.5400\n",
      "Epoch [30/100], Step [7500/24597], Loss: 1.7484\n",
      "Epoch [30/100], Step [7600/24597], Loss: 1.5612\n",
      "Epoch [30/100], Step [7700/24597], Loss: 1.8481\n",
      "Epoch [30/100], Step [7800/24597], Loss: 1.6990\n",
      "Epoch [30/100], Step [7900/24597], Loss: 1.5795\n",
      "Epoch [30/100], Step [8000/24597], Loss: 1.6839\n",
      "Epoch [30/100], Step [8100/24597], Loss: 1.5147\n",
      "Epoch [30/100], Step [8200/24597], Loss: 1.6596\n",
      "Epoch [30/100], Step [8300/24597], Loss: 1.7063\n",
      "Epoch [30/100], Step [8400/24597], Loss: 1.5715\n",
      "Epoch [30/100], Step [8500/24597], Loss: 1.4940\n",
      "Epoch [30/100], Step [8600/24597], Loss: 1.6386\n",
      "Epoch [30/100], Step [8700/24597], Loss: 1.7101\n",
      "Epoch [30/100], Step [8800/24597], Loss: 1.6151\n",
      "Epoch [30/100], Step [8900/24597], Loss: 1.5473\n",
      "Epoch [30/100], Step [9000/24597], Loss: 1.7234\n",
      "Epoch [30/100], Step [9100/24597], Loss: 1.6200\n",
      "Epoch [30/100], Step [9200/24597], Loss: 1.5588\n",
      "Epoch [30/100], Step [9300/24597], Loss: 1.8737\n",
      "Epoch [30/100], Step [9400/24597], Loss: 1.7376\n",
      "Epoch [30/100], Step [9500/24597], Loss: 1.5199\n",
      "Epoch [30/100], Step [9600/24597], Loss: 1.6803\n",
      "Epoch [30/100], Step [9700/24597], Loss: 1.6114\n",
      "Epoch [30/100], Step [9800/24597], Loss: 1.4655\n",
      "Epoch [30/100], Step [9900/24597], Loss: 1.5685\n",
      "Epoch [30/100], Step [10000/24597], Loss: 1.7311\n",
      "Epoch [30/100], Step [10100/24597], Loss: 1.5118\n",
      "Epoch [30/100], Step [10200/24597], Loss: 1.6173\n",
      "Epoch [30/100], Step [10300/24597], Loss: 1.6280\n",
      "Epoch [30/100], Step [10400/24597], Loss: 1.6289\n",
      "Epoch [30/100], Step [10500/24597], Loss: 1.8345\n",
      "Epoch [30/100], Step [10600/24597], Loss: 1.4788\n",
      "Epoch [30/100], Step [10700/24597], Loss: 1.8204\n",
      "Epoch [30/100], Step [10800/24597], Loss: 1.7064\n",
      "Epoch [30/100], Step [10900/24597], Loss: 1.9697\n",
      "Epoch [30/100], Step [11000/24597], Loss: 1.6001\n",
      "Epoch [30/100], Step [11100/24597], Loss: 1.6400\n",
      "Epoch [30/100], Step [11200/24597], Loss: 1.4653\n",
      "Epoch [30/100], Step [11300/24597], Loss: 1.5028\n",
      "Epoch [30/100], Step [11400/24597], Loss: 1.7033\n",
      "Epoch [30/100], Step [11500/24597], Loss: 1.4754\n",
      "Epoch [30/100], Step [11600/24597], Loss: 1.4758\n",
      "Epoch [30/100], Step [11700/24597], Loss: 1.6282\n",
      "Epoch [30/100], Step [11800/24597], Loss: 1.3845\n",
      "Epoch [30/100], Step [11900/24597], Loss: 1.6621\n",
      "Epoch [30/100], Step [12000/24597], Loss: 1.5339\n",
      "Epoch [30/100], Step [12100/24597], Loss: 1.4766\n",
      "Epoch [30/100], Step [12200/24597], Loss: 1.7361\n",
      "Epoch [30/100], Step [12300/24597], Loss: 1.5197\n",
      "Epoch [30/100], Step [12400/24597], Loss: 1.6057\n",
      "Epoch [30/100], Step [12500/24597], Loss: 1.5292\n",
      "Epoch [30/100], Step [12600/24597], Loss: 1.4949\n",
      "Epoch [30/100], Step [12700/24597], Loss: 1.7158\n",
      "Epoch [30/100], Step [12800/24597], Loss: 1.6522\n",
      "Epoch [30/100], Step [12900/24597], Loss: 1.4657\n",
      "Epoch [30/100], Step [13000/24597], Loss: 1.6092\n",
      "Epoch [30/100], Step [13100/24597], Loss: 1.4540\n",
      "Epoch [30/100], Step [13200/24597], Loss: 1.6119\n",
      "Epoch [30/100], Step [13300/24597], Loss: 1.6430\n",
      "Epoch [30/100], Step [13400/24597], Loss: 1.4343\n",
      "Epoch [30/100], Step [13500/24597], Loss: 1.7437\n",
      "Epoch [30/100], Step [13600/24597], Loss: 1.5596\n",
      "Epoch [30/100], Step [13700/24597], Loss: 1.5272\n",
      "Epoch [30/100], Step [13800/24597], Loss: 1.6916\n",
      "Epoch [30/100], Step [13900/24597], Loss: 1.5644\n",
      "Epoch [30/100], Step [14000/24597], Loss: 1.7241\n",
      "Epoch [30/100], Step [14100/24597], Loss: 1.6926\n",
      "Epoch [30/100], Step [14200/24597], Loss: 1.4220\n",
      "Epoch [30/100], Step [14300/24597], Loss: 1.4943\n",
      "Epoch [30/100], Step [14400/24597], Loss: 1.6088\n",
      "Epoch [30/100], Step [14500/24597], Loss: 1.5920\n",
      "Epoch [30/100], Step [14600/24597], Loss: 1.5095\n",
      "Epoch [30/100], Step [14700/24597], Loss: 1.5576\n",
      "Epoch [30/100], Step [14800/24597], Loss: 1.6073\n",
      "Epoch [30/100], Step [14900/24597], Loss: 1.3328\n",
      "Epoch [30/100], Step [15000/24597], Loss: 1.4623\n",
      "Epoch [30/100], Step [15100/24597], Loss: 1.6675\n",
      "Epoch [30/100], Step [15200/24597], Loss: 1.5561\n",
      "Epoch [30/100], Step [15300/24597], Loss: 1.5920\n",
      "Epoch [30/100], Step [15400/24597], Loss: 1.5855\n",
      "Epoch [30/100], Step [15500/24597], Loss: 1.4030\n",
      "Epoch [30/100], Step [15600/24597], Loss: 1.8279\n",
      "Epoch [30/100], Step [15700/24597], Loss: 1.5325\n",
      "Epoch [30/100], Step [15800/24597], Loss: 1.6089\n",
      "Epoch [30/100], Step [15900/24597], Loss: 1.7014\n",
      "Epoch [30/100], Step [16000/24597], Loss: 1.7862\n",
      "Epoch [30/100], Step [16100/24597], Loss: 1.7233\n",
      "Epoch [30/100], Step [16200/24597], Loss: 1.4689\n",
      "Epoch [30/100], Step [16300/24597], Loss: 1.4609\n",
      "Epoch [30/100], Step [16400/24597], Loss: 1.5099\n",
      "Epoch [30/100], Step [16500/24597], Loss: 1.6631\n",
      "Epoch [30/100], Step [16600/24597], Loss: 1.6297\n",
      "Epoch [30/100], Step [16700/24597], Loss: 1.6227\n",
      "Epoch [30/100], Step [16800/24597], Loss: 1.7270\n",
      "Epoch [30/100], Step [16900/24597], Loss: 1.4442\n",
      "Epoch [30/100], Step [17000/24597], Loss: 1.6457\n",
      "Epoch [30/100], Step [17100/24597], Loss: 1.7232\n",
      "Epoch [30/100], Step [17200/24597], Loss: 1.6660\n",
      "Epoch [30/100], Step [17300/24597], Loss: 1.4449\n",
      "Epoch [30/100], Step [17400/24597], Loss: 1.8087\n",
      "Epoch [30/100], Step [17500/24597], Loss: 1.6224\n",
      "Epoch [30/100], Step [17600/24597], Loss: 1.9834\n",
      "Epoch [30/100], Step [17700/24597], Loss: 1.6693\n",
      "Epoch [30/100], Step [17800/24597], Loss: 1.5451\n",
      "Epoch [30/100], Step [17900/24597], Loss: 1.6587\n",
      "Epoch [30/100], Step [18000/24597], Loss: 1.6494\n",
      "Epoch [30/100], Step [18100/24597], Loss: 1.5422\n",
      "Epoch [30/100], Step [18200/24597], Loss: 1.5988\n",
      "Epoch [30/100], Step [18300/24597], Loss: 1.5048\n",
      "Epoch [30/100], Step [18400/24597], Loss: 1.3992\n",
      "Epoch [30/100], Step [18500/24597], Loss: 1.5402\n",
      "Epoch [30/100], Step [18600/24597], Loss: 1.6332\n",
      "Epoch [30/100], Step [18700/24597], Loss: 1.5711\n",
      "Epoch [30/100], Step [18800/24597], Loss: 1.4628\n",
      "Epoch [30/100], Step [18900/24597], Loss: 1.6934\n",
      "Epoch [30/100], Step [19000/24597], Loss: 1.6219\n",
      "Epoch [30/100], Step [19100/24597], Loss: 1.8035\n",
      "Epoch [30/100], Step [19200/24597], Loss: 1.5060\n",
      "Epoch [30/100], Step [19300/24597], Loss: 1.6727\n",
      "Epoch [30/100], Step [19400/24597], Loss: 1.4870\n",
      "Epoch [30/100], Step [19500/24597], Loss: 1.7883\n",
      "Epoch [30/100], Step [19600/24597], Loss: 1.5654\n",
      "Epoch [30/100], Step [19700/24597], Loss: 1.8828\n",
      "Epoch [30/100], Step [19800/24597], Loss: 1.7913\n",
      "Epoch [30/100], Step [19900/24597], Loss: 1.5307\n",
      "Epoch [30/100], Step [20000/24597], Loss: 1.7624\n",
      "Epoch [30/100], Step [20100/24597], Loss: 1.6829\n",
      "Epoch [30/100], Step [20200/24597], Loss: 1.6756\n",
      "Epoch [30/100], Step [20300/24597], Loss: 1.4525\n",
      "Epoch [30/100], Step [20400/24597], Loss: 1.5079\n",
      "Epoch [30/100], Step [20500/24597], Loss: 1.8181\n",
      "Epoch [30/100], Step [20600/24597], Loss: 1.6624\n",
      "Epoch [30/100], Step [20700/24597], Loss: 1.6970\n",
      "Epoch [30/100], Step [20800/24597], Loss: 1.5263\n",
      "Epoch [30/100], Step [20900/24597], Loss: 1.8573\n",
      "Epoch [30/100], Step [21000/24597], Loss: 1.4609\n",
      "Epoch [30/100], Step [21100/24597], Loss: 1.7121\n",
      "Epoch [30/100], Step [21200/24597], Loss: 1.6246\n",
      "Epoch [30/100], Step [21300/24597], Loss: 1.3959\n",
      "Epoch [30/100], Step [21400/24597], Loss: 1.7607\n",
      "Epoch [30/100], Step [21500/24597], Loss: 1.6256\n",
      "Epoch [30/100], Step [21600/24597], Loss: 1.5130\n",
      "Epoch [30/100], Step [21700/24597], Loss: 1.5726\n",
      "Epoch [30/100], Step [21800/24597], Loss: 1.4752\n",
      "Epoch [30/100], Step [21900/24597], Loss: 1.5813\n",
      "Epoch [30/100], Step [22000/24597], Loss: 1.6922\n",
      "Epoch [30/100], Step [22100/24597], Loss: 1.7830\n",
      "Epoch [30/100], Step [22200/24597], Loss: 1.9136\n",
      "Epoch [30/100], Step [22300/24597], Loss: 1.5741\n",
      "Epoch [30/100], Step [22400/24597], Loss: 1.7628\n",
      "Epoch [30/100], Step [22500/24597], Loss: 1.7685\n",
      "Epoch [30/100], Step [22600/24597], Loss: 1.9537\n",
      "Epoch [30/100], Step [22700/24597], Loss: 1.4958\n",
      "Epoch [30/100], Step [22800/24597], Loss: 1.6004\n",
      "Epoch [30/100], Step [22900/24597], Loss: 1.3687\n",
      "Epoch [30/100], Step [23000/24597], Loss: 1.5628\n",
      "Epoch [30/100], Step [23100/24597], Loss: 1.3592\n",
      "Epoch [30/100], Step [23200/24597], Loss: 1.5059\n",
      "Epoch [30/100], Step [23300/24597], Loss: 1.6857\n",
      "Epoch [30/100], Step [23400/24597], Loss: 1.8379\n",
      "Epoch [30/100], Step [23500/24597], Loss: 1.6132\n",
      "Epoch [30/100], Step [23600/24597], Loss: 1.6488\n",
      "Epoch [30/100], Step [23700/24597], Loss: 1.8681\n",
      "Epoch [30/100], Step [23800/24597], Loss: 1.6749\n",
      "Epoch [30/100], Step [23900/24597], Loss: 1.7807\n",
      "Epoch [30/100], Step [24000/24597], Loss: 1.5590\n",
      "Epoch [30/100], Step [24100/24597], Loss: 1.8109\n",
      "Epoch [30/100], Step [24200/24597], Loss: 1.7247\n",
      "Epoch [30/100], Step [24300/24597], Loss: 1.5915\n",
      "Epoch [30/100], Step [24400/24597], Loss: 1.5393\n",
      "Epoch [30/100], Step [24500/24597], Loss: 1.4804\n",
      "Epoch [31/100], Step [100/24597], Loss: 1.4932\n",
      "Epoch [31/100], Step [200/24597], Loss: 1.6005\n",
      "Epoch [31/100], Step [300/24597], Loss: 1.5607\n",
      "Epoch [31/100], Step [400/24597], Loss: 1.6536\n",
      "Epoch [31/100], Step [500/24597], Loss: 1.6012\n",
      "Epoch [31/100], Step [600/24597], Loss: 1.5632\n",
      "Epoch [31/100], Step [700/24597], Loss: 1.8798\n",
      "Epoch [31/100], Step [800/24597], Loss: 1.4840\n",
      "Epoch [31/100], Step [900/24597], Loss: 1.7848\n",
      "Epoch [31/100], Step [1000/24597], Loss: 1.6614\n",
      "Epoch [31/100], Step [1100/24597], Loss: 1.5580\n",
      "Epoch [31/100], Step [1200/24597], Loss: 1.5933\n",
      "Epoch [31/100], Step [1300/24597], Loss: 1.3731\n",
      "Epoch [31/100], Step [1400/24597], Loss: 1.7429\n",
      "Epoch [31/100], Step [1500/24597], Loss: 1.5569\n",
      "Epoch [31/100], Step [1600/24597], Loss: 1.4737\n",
      "Epoch [31/100], Step [1700/24597], Loss: 1.6944\n",
      "Epoch [31/100], Step [1800/24597], Loss: 1.5886\n",
      "Epoch [31/100], Step [1900/24597], Loss: 1.5513\n",
      "Epoch [31/100], Step [2000/24597], Loss: 1.5490\n",
      "Epoch [31/100], Step [2100/24597], Loss: 1.4249\n",
      "Epoch [31/100], Step [2200/24597], Loss: 1.4987\n",
      "Epoch [31/100], Step [2300/24597], Loss: 1.5732\n",
      "Epoch [31/100], Step [2400/24597], Loss: 1.5101\n",
      "Epoch [31/100], Step [2500/24597], Loss: 1.4899\n",
      "Epoch [31/100], Step [2600/24597], Loss: 1.8043\n",
      "Epoch [31/100], Step [2700/24597], Loss: 1.6000\n",
      "Epoch [31/100], Step [2800/24597], Loss: 1.5996\n",
      "Epoch [31/100], Step [2900/24597], Loss: 1.6755\n",
      "Epoch [31/100], Step [3000/24597], Loss: 1.6982\n",
      "Epoch [31/100], Step [3100/24597], Loss: 1.8857\n",
      "Epoch [31/100], Step [3200/24597], Loss: 1.4821\n",
      "Epoch [31/100], Step [3300/24597], Loss: 1.5938\n",
      "Epoch [31/100], Step [3400/24597], Loss: 1.7442\n",
      "Epoch [31/100], Step [3500/24597], Loss: 1.6160\n",
      "Epoch [31/100], Step [3600/24597], Loss: 1.6000\n",
      "Epoch [31/100], Step [3700/24597], Loss: 1.5412\n",
      "Epoch [31/100], Step [3800/24597], Loss: 1.5638\n",
      "Epoch [31/100], Step [3900/24597], Loss: 1.5627\n",
      "Epoch [31/100], Step [4000/24597], Loss: 1.5694\n",
      "Epoch [31/100], Step [4100/24597], Loss: 1.5601\n",
      "Epoch [31/100], Step [4200/24597], Loss: 1.3949\n",
      "Epoch [31/100], Step [4300/24597], Loss: 1.6067\n",
      "Epoch [31/100], Step [4400/24597], Loss: 1.6600\n",
      "Epoch [31/100], Step [4500/24597], Loss: 1.3346\n",
      "Epoch [31/100], Step [4600/24597], Loss: 1.3296\n",
      "Epoch [31/100], Step [4700/24597], Loss: 1.5218\n",
      "Epoch [31/100], Step [4800/24597], Loss: 1.8730\n",
      "Epoch [31/100], Step [4900/24597], Loss: 1.5009\n",
      "Epoch [31/100], Step [5000/24597], Loss: 1.6531\n",
      "Epoch [31/100], Step [5100/24597], Loss: 1.4511\n",
      "Epoch [31/100], Step [5200/24597], Loss: 1.4620\n",
      "Epoch [31/100], Step [5300/24597], Loss: 1.5364\n",
      "Epoch [31/100], Step [5400/24597], Loss: 1.9432\n",
      "Epoch [31/100], Step [5500/24597], Loss: 1.5327\n",
      "Epoch [31/100], Step [5600/24597], Loss: 1.8197\n",
      "Epoch [31/100], Step [5700/24597], Loss: 1.8899\n",
      "Epoch [31/100], Step [5800/24597], Loss: 1.4262\n",
      "Epoch [31/100], Step [5900/24597], Loss: 1.4753\n",
      "Epoch [31/100], Step [6000/24597], Loss: 1.7828\n",
      "Epoch [31/100], Step [6100/24597], Loss: 1.6426\n",
      "Epoch [31/100], Step [6200/24597], Loss: 1.5191\n",
      "Epoch [31/100], Step [6300/24597], Loss: 1.7140\n",
      "Epoch [31/100], Step [6400/24597], Loss: 1.6091\n",
      "Epoch [31/100], Step [6500/24597], Loss: 1.8115\n",
      "Epoch [31/100], Step [6600/24597], Loss: 1.4607\n",
      "Epoch [31/100], Step [6700/24597], Loss: 1.6194\n",
      "Epoch [31/100], Step [6800/24597], Loss: 1.7714\n",
      "Epoch [31/100], Step [6900/24597], Loss: 1.7951\n",
      "Epoch [31/100], Step [7000/24597], Loss: 1.6598\n",
      "Epoch [31/100], Step [7100/24597], Loss: 1.8165\n",
      "Epoch [31/100], Step [7200/24597], Loss: 1.4658\n",
      "Epoch [31/100], Step [7300/24597], Loss: 1.6983\n",
      "Epoch [31/100], Step [7400/24597], Loss: 1.7258\n",
      "Epoch [31/100], Step [7500/24597], Loss: 1.6708\n",
      "Epoch [31/100], Step [7600/24597], Loss: 1.6497\n",
      "Epoch [31/100], Step [7700/24597], Loss: 1.9572\n",
      "Epoch [31/100], Step [7800/24597], Loss: 1.4581\n",
      "Epoch [31/100], Step [7900/24597], Loss: 1.5969\n",
      "Epoch [31/100], Step [8000/24597], Loss: 1.7476\n",
      "Epoch [31/100], Step [8100/24597], Loss: 1.5091\n",
      "Epoch [31/100], Step [8200/24597], Loss: 1.5559\n",
      "Epoch [31/100], Step [8300/24597], Loss: 1.5878\n",
      "Epoch [31/100], Step [8400/24597], Loss: 1.5426\n",
      "Epoch [31/100], Step [8500/24597], Loss: 1.6969\n",
      "Epoch [31/100], Step [8600/24597], Loss: 1.6887\n",
      "Epoch [31/100], Step [8700/24597], Loss: 1.8076\n",
      "Epoch [31/100], Step [8800/24597], Loss: 1.6610\n",
      "Epoch [31/100], Step [8900/24597], Loss: 1.4348\n",
      "Epoch [31/100], Step [9000/24597], Loss: 1.7508\n",
      "Epoch [31/100], Step [9100/24597], Loss: 1.5847\n",
      "Epoch [31/100], Step [9200/24597], Loss: 1.6893\n",
      "Epoch [31/100], Step [9300/24597], Loss: 1.5341\n",
      "Epoch [31/100], Step [9400/24597], Loss: 1.5776\n",
      "Epoch [31/100], Step [9500/24597], Loss: 1.7628\n",
      "Epoch [31/100], Step [9600/24597], Loss: 1.6685\n",
      "Epoch [31/100], Step [9700/24597], Loss: 1.8299\n",
      "Epoch [31/100], Step [9800/24597], Loss: 1.6089\n",
      "Epoch [31/100], Step [9900/24597], Loss: 1.6615\n",
      "Epoch [31/100], Step [10000/24597], Loss: 1.5744\n",
      "Epoch [31/100], Step [10100/24597], Loss: 1.7606\n",
      "Epoch [31/100], Step [10200/24597], Loss: 1.6870\n",
      "Epoch [31/100], Step [10300/24597], Loss: 1.6186\n",
      "Epoch [31/100], Step [10400/24597], Loss: 1.5588\n",
      "Epoch [31/100], Step [10500/24597], Loss: 1.7354\n",
      "Epoch [31/100], Step [10600/24597], Loss: 1.4944\n",
      "Epoch [31/100], Step [10700/24597], Loss: 1.6791\n",
      "Epoch [31/100], Step [10800/24597], Loss: 1.7645\n",
      "Epoch [31/100], Step [10900/24597], Loss: 1.6211\n",
      "Epoch [31/100], Step [11000/24597], Loss: 1.5695\n",
      "Epoch [31/100], Step [11100/24597], Loss: 1.5262\n",
      "Epoch [31/100], Step [11200/24597], Loss: 1.7374\n",
      "Epoch [31/100], Step [11300/24597], Loss: 1.5017\n",
      "Epoch [31/100], Step [11400/24597], Loss: 1.5224\n",
      "Epoch [31/100], Step [11500/24597], Loss: 1.4346\n",
      "Epoch [31/100], Step [11600/24597], Loss: 1.6487\n",
      "Epoch [31/100], Step [11700/24597], Loss: 1.5744\n",
      "Epoch [31/100], Step [11800/24597], Loss: 1.5158\n",
      "Epoch [31/100], Step [11900/24597], Loss: 1.4729\n",
      "Epoch [31/100], Step [12000/24597], Loss: 1.5051\n",
      "Epoch [31/100], Step [12100/24597], Loss: 1.4318\n",
      "Epoch [31/100], Step [12200/24597], Loss: 1.7911\n",
      "Epoch [31/100], Step [12300/24597], Loss: 1.6177\n",
      "Epoch [31/100], Step [12400/24597], Loss: 1.7819\n",
      "Epoch [31/100], Step [12500/24597], Loss: 1.6735\n",
      "Epoch [31/100], Step [12600/24597], Loss: 1.4561\n",
      "Epoch [31/100], Step [12700/24597], Loss: 1.6018\n",
      "Epoch [31/100], Step [12800/24597], Loss: 1.4537\n",
      "Epoch [31/100], Step [12900/24597], Loss: 1.5248\n",
      "Epoch [31/100], Step [13000/24597], Loss: 1.6512\n",
      "Epoch [31/100], Step [13100/24597], Loss: 1.6007\n",
      "Epoch [31/100], Step [13200/24597], Loss: 1.5854\n",
      "Epoch [31/100], Step [13300/24597], Loss: 1.5043\n",
      "Epoch [31/100], Step [13400/24597], Loss: 1.5171\n",
      "Epoch [31/100], Step [13500/24597], Loss: 1.5426\n",
      "Epoch [31/100], Step [13600/24597], Loss: 1.5738\n",
      "Epoch [31/100], Step [13700/24597], Loss: 1.6713\n",
      "Epoch [31/100], Step [13800/24597], Loss: 1.6566\n",
      "Epoch [31/100], Step [13900/24597], Loss: 1.6727\n",
      "Epoch [31/100], Step [14000/24597], Loss: 1.5752\n",
      "Epoch [31/100], Step [14100/24597], Loss: 1.6252\n",
      "Epoch [31/100], Step [14200/24597], Loss: 1.6346\n",
      "Epoch [31/100], Step [14300/24597], Loss: 1.7495\n",
      "Epoch [31/100], Step [14400/24597], Loss: 1.4793\n",
      "Epoch [31/100], Step [14500/24597], Loss: 1.7036\n",
      "Epoch [31/100], Step [14600/24597], Loss: 1.6674\n",
      "Epoch [31/100], Step [14700/24597], Loss: 1.6040\n",
      "Epoch [31/100], Step [14800/24597], Loss: 1.5925\n",
      "Epoch [31/100], Step [14900/24597], Loss: 1.8172\n",
      "Epoch [31/100], Step [15000/24597], Loss: 1.7072\n",
      "Epoch [31/100], Step [15100/24597], Loss: 1.5713\n",
      "Epoch [31/100], Step [15200/24597], Loss: 1.5093\n",
      "Epoch [31/100], Step [15300/24597], Loss: 1.7089\n",
      "Epoch [31/100], Step [15400/24597], Loss: 1.6690\n",
      "Epoch [31/100], Step [15500/24597], Loss: 1.6530\n",
      "Epoch [31/100], Step [15600/24597], Loss: 1.5735\n",
      "Epoch [31/100], Step [15700/24597], Loss: 1.7662\n",
      "Epoch [31/100], Step [15800/24597], Loss: 1.5298\n",
      "Epoch [31/100], Step [15900/24597], Loss: 1.9334\n",
      "Epoch [31/100], Step [16000/24597], Loss: 1.8106\n",
      "Epoch [31/100], Step [16100/24597], Loss: 1.4543\n",
      "Epoch [31/100], Step [16200/24597], Loss: 1.3927\n",
      "Epoch [31/100], Step [16300/24597], Loss: 1.6784\n",
      "Epoch [31/100], Step [16400/24597], Loss: 1.6288\n",
      "Epoch [31/100], Step [16500/24597], Loss: 1.6664\n",
      "Epoch [31/100], Step [16600/24597], Loss: 1.5354\n",
      "Epoch [31/100], Step [16700/24597], Loss: 1.6977\n",
      "Epoch [31/100], Step [16800/24597], Loss: 1.6723\n",
      "Epoch [31/100], Step [16900/24597], Loss: 1.9737\n",
      "Epoch [31/100], Step [17000/24597], Loss: 1.7873\n",
      "Epoch [31/100], Step [17100/24597], Loss: 1.4537\n",
      "Epoch [31/100], Step [17200/24597], Loss: 1.5599\n",
      "Epoch [31/100], Step [17300/24597], Loss: 1.5501\n",
      "Epoch [31/100], Step [17400/24597], Loss: 1.7265\n",
      "Epoch [31/100], Step [17500/24597], Loss: 1.7450\n",
      "Epoch [31/100], Step [17600/24597], Loss: 1.5697\n",
      "Epoch [31/100], Step [17700/24597], Loss: 1.5907\n",
      "Epoch [31/100], Step [17800/24597], Loss: 1.7808\n",
      "Epoch [31/100], Step [17900/24597], Loss: 1.6700\n",
      "Epoch [31/100], Step [18000/24597], Loss: 1.5888\n",
      "Epoch [31/100], Step [18100/24597], Loss: 1.4090\n",
      "Epoch [31/100], Step [18200/24597], Loss: 1.6594\n",
      "Epoch [31/100], Step [18300/24597], Loss: 1.8439\n",
      "Epoch [31/100], Step [18400/24597], Loss: 1.5710\n",
      "Epoch [31/100], Step [18500/24597], Loss: 1.8987\n",
      "Epoch [31/100], Step [18600/24597], Loss: 1.5438\n",
      "Epoch [31/100], Step [18700/24597], Loss: 1.7397\n",
      "Epoch [31/100], Step [18800/24597], Loss: 1.5384\n",
      "Epoch [31/100], Step [18900/24597], Loss: 1.7326\n",
      "Epoch [31/100], Step [19000/24597], Loss: 1.6507\n",
      "Epoch [31/100], Step [19100/24597], Loss: 1.7182\n",
      "Epoch [31/100], Step [19200/24597], Loss: 1.5181\n",
      "Epoch [31/100], Step [19300/24597], Loss: 1.8050\n",
      "Epoch [31/100], Step [19400/24597], Loss: 1.6577\n",
      "Epoch [31/100], Step [19500/24597], Loss: 1.6901\n",
      "Epoch [31/100], Step [19600/24597], Loss: 1.3814\n",
      "Epoch [31/100], Step [19700/24597], Loss: 1.6488\n",
      "Epoch [31/100], Step [19800/24597], Loss: 1.7103\n",
      "Epoch [31/100], Step [19900/24597], Loss: 1.5839\n",
      "Epoch [31/100], Step [20000/24597], Loss: 1.4225\n",
      "Epoch [31/100], Step [20100/24597], Loss: 1.6005\n",
      "Epoch [31/100], Step [20200/24597], Loss: 1.5982\n",
      "Epoch [31/100], Step [20300/24597], Loss: 1.6270\n",
      "Epoch [31/100], Step [20400/24597], Loss: 1.6776\n",
      "Epoch [31/100], Step [20500/24597], Loss: 1.6950\n",
      "Epoch [31/100], Step [20600/24597], Loss: 1.6435\n",
      "Epoch [31/100], Step [20700/24597], Loss: 1.6428\n",
      "Epoch [31/100], Step [20800/24597], Loss: 1.5150\n",
      "Epoch [31/100], Step [20900/24597], Loss: 1.5999\n",
      "Epoch [31/100], Step [21000/24597], Loss: 1.6528\n",
      "Epoch [31/100], Step [21100/24597], Loss: 1.3145\n",
      "Epoch [31/100], Step [21200/24597], Loss: 1.7895\n",
      "Epoch [31/100], Step [21300/24597], Loss: 1.4025\n",
      "Epoch [31/100], Step [21400/24597], Loss: 1.4657\n",
      "Epoch [31/100], Step [21500/24597], Loss: 1.8565\n",
      "Epoch [31/100], Step [21600/24597], Loss: 1.7928\n",
      "Epoch [31/100], Step [21700/24597], Loss: 1.3107\n",
      "Epoch [31/100], Step [21800/24597], Loss: 1.6159\n",
      "Epoch [31/100], Step [21900/24597], Loss: 1.3907\n",
      "Epoch [31/100], Step [22000/24597], Loss: 1.7480\n",
      "Epoch [31/100], Step [22100/24597], Loss: 1.5512\n",
      "Epoch [31/100], Step [22200/24597], Loss: 1.7237\n",
      "Epoch [31/100], Step [22300/24597], Loss: 1.5664\n",
      "Epoch [31/100], Step [22400/24597], Loss: 1.7018\n",
      "Epoch [31/100], Step [22500/24597], Loss: 1.3520\n",
      "Epoch [31/100], Step [22600/24597], Loss: 1.4854\n",
      "Epoch [31/100], Step [22700/24597], Loss: 1.6621\n",
      "Epoch [31/100], Step [22800/24597], Loss: 1.4709\n",
      "Epoch [31/100], Step [22900/24597], Loss: 1.7183\n",
      "Epoch [31/100], Step [23000/24597], Loss: 1.7633\n",
      "Epoch [31/100], Step [23100/24597], Loss: 1.6245\n",
      "Epoch [31/100], Step [23200/24597], Loss: 1.6420\n",
      "Epoch [31/100], Step [23300/24597], Loss: 1.5469\n",
      "Epoch [31/100], Step [23400/24597], Loss: 1.4206\n",
      "Epoch [31/100], Step [23500/24597], Loss: 1.5710\n",
      "Epoch [31/100], Step [23600/24597], Loss: 1.8266\n",
      "Epoch [31/100], Step [23700/24597], Loss: 1.4426\n",
      "Epoch [31/100], Step [23800/24597], Loss: 1.8823\n",
      "Epoch [31/100], Step [23900/24597], Loss: 1.5654\n",
      "Epoch [31/100], Step [24000/24597], Loss: 1.5959\n",
      "Epoch [31/100], Step [24100/24597], Loss: 1.5892\n",
      "Epoch [31/100], Step [24200/24597], Loss: 1.7539\n",
      "Epoch [31/100], Step [24300/24597], Loss: 1.4025\n",
      "Epoch [31/100], Step [24400/24597], Loss: 1.7072\n",
      "Epoch [31/100], Step [24500/24597], Loss: 1.9213\n",
      "Epoch [32/100], Step [100/24597], Loss: 1.4903\n",
      "Epoch [32/100], Step [200/24597], Loss: 1.8802\n",
      "Epoch [32/100], Step [300/24597], Loss: 1.5151\n",
      "Epoch [32/100], Step [400/24597], Loss: 1.6907\n",
      "Epoch [32/100], Step [500/24597], Loss: 1.5215\n",
      "Epoch [32/100], Step [600/24597], Loss: 1.6570\n",
      "Epoch [32/100], Step [700/24597], Loss: 1.6965\n",
      "Epoch [32/100], Step [800/24597], Loss: 1.3762\n",
      "Epoch [32/100], Step [900/24597], Loss: 1.6505\n",
      "Epoch [32/100], Step [1000/24597], Loss: 1.5663\n",
      "Epoch [32/100], Step [1100/24597], Loss: 1.9116\n",
      "Epoch [32/100], Step [1200/24597], Loss: 1.4609\n",
      "Epoch [32/100], Step [1300/24597], Loss: 1.7112\n",
      "Epoch [32/100], Step [1400/24597], Loss: 1.8197\n",
      "Epoch [32/100], Step [1500/24597], Loss: 1.5157\n",
      "Epoch [32/100], Step [1600/24597], Loss: 1.5630\n",
      "Epoch [32/100], Step [1700/24597], Loss: 1.4783\n",
      "Epoch [32/100], Step [1800/24597], Loss: 1.6628\n",
      "Epoch [32/100], Step [1900/24597], Loss: 1.5359\n",
      "Epoch [32/100], Step [2000/24597], Loss: 1.7614\n",
      "Epoch [32/100], Step [2100/24597], Loss: 1.5243\n",
      "Epoch [32/100], Step [2200/24597], Loss: 1.6713\n",
      "Epoch [32/100], Step [2300/24597], Loss: 1.7768\n",
      "Epoch [32/100], Step [2400/24597], Loss: 1.6841\n",
      "Epoch [32/100], Step [2500/24597], Loss: 1.6721\n",
      "Epoch [32/100], Step [2600/24597], Loss: 1.7181\n",
      "Epoch [32/100], Step [2700/24597], Loss: 1.6387\n",
      "Epoch [32/100], Step [2800/24597], Loss: 1.5721\n",
      "Epoch [32/100], Step [2900/24597], Loss: 1.3235\n",
      "Epoch [32/100], Step [3000/24597], Loss: 1.4361\n",
      "Epoch [32/100], Step [3100/24597], Loss: 1.5470\n",
      "Epoch [32/100], Step [3200/24597], Loss: 1.5129\n",
      "Epoch [32/100], Step [3300/24597], Loss: 1.4132\n",
      "Epoch [32/100], Step [3400/24597], Loss: 1.6713\n",
      "Epoch [32/100], Step [3500/24597], Loss: 1.3862\n",
      "Epoch [32/100], Step [3600/24597], Loss: 1.5621\n",
      "Epoch [32/100], Step [3700/24597], Loss: 1.9072\n",
      "Epoch [32/100], Step [3800/24597], Loss: 1.6831\n",
      "Epoch [32/100], Step [3900/24597], Loss: 1.4118\n",
      "Epoch [32/100], Step [4000/24597], Loss: 1.5630\n",
      "Epoch [32/100], Step [4100/24597], Loss: 1.8266\n",
      "Epoch [32/100], Step [4200/24597], Loss: 1.6610\n",
      "Epoch [32/100], Step [4300/24597], Loss: 1.7725\n",
      "Epoch [32/100], Step [4400/24597], Loss: 1.3913\n",
      "Epoch [32/100], Step [4500/24597], Loss: 1.5910\n",
      "Epoch [32/100], Step [4600/24597], Loss: 1.4886\n",
      "Epoch [32/100], Step [4700/24597], Loss: 1.5987\n",
      "Epoch [32/100], Step [4800/24597], Loss: 1.6505\n",
      "Epoch [32/100], Step [4900/24597], Loss: 1.9976\n",
      "Epoch [32/100], Step [5000/24597], Loss: 1.7599\n",
      "Epoch [32/100], Step [5100/24597], Loss: 1.4260\n",
      "Epoch [32/100], Step [5200/24597], Loss: 1.5680\n",
      "Epoch [32/100], Step [5300/24597], Loss: 1.6348\n",
      "Epoch [32/100], Step [5400/24597], Loss: 1.8218\n",
      "Epoch [32/100], Step [5500/24597], Loss: 1.6870\n",
      "Epoch [32/100], Step [5600/24597], Loss: 1.6738\n",
      "Epoch [32/100], Step [5700/24597], Loss: 1.5148\n",
      "Epoch [32/100], Step [5800/24597], Loss: 1.5940\n",
      "Epoch [32/100], Step [5900/24597], Loss: 1.6343\n",
      "Epoch [32/100], Step [6000/24597], Loss: 1.7218\n",
      "Epoch [32/100], Step [6100/24597], Loss: 1.5137\n",
      "Epoch [32/100], Step [6200/24597], Loss: 1.4567\n",
      "Epoch [32/100], Step [6300/24597], Loss: 1.5085\n",
      "Epoch [32/100], Step [6400/24597], Loss: 1.7039\n",
      "Epoch [32/100], Step [6500/24597], Loss: 1.5764\n",
      "Epoch [32/100], Step [6600/24597], Loss: 1.7241\n",
      "Epoch [32/100], Step [6700/24597], Loss: 1.7792\n",
      "Epoch [32/100], Step [6800/24597], Loss: 1.5737\n",
      "Epoch [32/100], Step [6900/24597], Loss: 1.9104\n",
      "Epoch [32/100], Step [7000/24597], Loss: 1.8317\n",
      "Epoch [32/100], Step [7100/24597], Loss: 1.8176\n",
      "Epoch [32/100], Step [7200/24597], Loss: 1.5624\n",
      "Epoch [32/100], Step [7300/24597], Loss: 1.5847\n",
      "Epoch [32/100], Step [7400/24597], Loss: 1.6633\n",
      "Epoch [32/100], Step [7500/24597], Loss: 1.6465\n",
      "Epoch [32/100], Step [7600/24597], Loss: 1.7471\n",
      "Epoch [32/100], Step [7700/24597], Loss: 1.7759\n",
      "Epoch [32/100], Step [7800/24597], Loss: 1.7533\n",
      "Epoch [32/100], Step [7900/24597], Loss: 1.5292\n",
      "Epoch [32/100], Step [8000/24597], Loss: 1.6875\n",
      "Epoch [32/100], Step [8100/24597], Loss: 1.7470\n",
      "Epoch [32/100], Step [8200/24597], Loss: 1.7142\n",
      "Epoch [32/100], Step [8300/24597], Loss: 1.4785\n",
      "Epoch [32/100], Step [8400/24597], Loss: 1.5785\n",
      "Epoch [32/100], Step [8500/24597], Loss: 1.8164\n",
      "Epoch [32/100], Step [8600/24597], Loss: 1.8424\n",
      "Epoch [32/100], Step [8700/24597], Loss: 1.6105\n",
      "Epoch [32/100], Step [8800/24597], Loss: 1.5628\n",
      "Epoch [32/100], Step [8900/24597], Loss: 1.8080\n",
      "Epoch [32/100], Step [9000/24597], Loss: 1.5301\n",
      "Epoch [32/100], Step [9100/24597], Loss: 1.5472\n",
      "Epoch [32/100], Step [9200/24597], Loss: 1.8222\n",
      "Epoch [32/100], Step [9300/24597], Loss: 1.6249\n",
      "Epoch [32/100], Step [9400/24597], Loss: 1.3831\n",
      "Epoch [32/100], Step [9500/24597], Loss: 1.6916\n",
      "Epoch [32/100], Step [9600/24597], Loss: 1.6825\n",
      "Epoch [32/100], Step [9700/24597], Loss: 1.5149\n",
      "Epoch [32/100], Step [9800/24597], Loss: 1.8945\n",
      "Epoch [32/100], Step [9900/24597], Loss: 1.6826\n",
      "Epoch [32/100], Step [10000/24597], Loss: 1.7836\n",
      "Epoch [32/100], Step [10100/24597], Loss: 1.5131\n",
      "Epoch [32/100], Step [10200/24597], Loss: 1.5537\n",
      "Epoch [32/100], Step [10300/24597], Loss: 1.5305\n",
      "Epoch [32/100], Step [10400/24597], Loss: 1.6995\n",
      "Epoch [32/100], Step [10500/24597], Loss: 1.6627\n",
      "Epoch [32/100], Step [10600/24597], Loss: 1.5725\n",
      "Epoch [32/100], Step [10700/24597], Loss: 1.6752\n",
      "Epoch [32/100], Step [10800/24597], Loss: 1.5238\n",
      "Epoch [32/100], Step [10900/24597], Loss: 1.7273\n",
      "Epoch [32/100], Step [11000/24597], Loss: 1.7124\n",
      "Epoch [32/100], Step [11100/24597], Loss: 1.5143\n",
      "Epoch [32/100], Step [11200/24597], Loss: 1.4348\n",
      "Epoch [32/100], Step [11300/24597], Loss: 1.6894\n",
      "Epoch [32/100], Step [11400/24597], Loss: 1.9672\n",
      "Epoch [32/100], Step [11500/24597], Loss: 1.6045\n",
      "Epoch [32/100], Step [11600/24597], Loss: 1.6598\n",
      "Epoch [32/100], Step [11700/24597], Loss: 1.6356\n",
      "Epoch [32/100], Step [11800/24597], Loss: 1.7628\n",
      "Epoch [32/100], Step [11900/24597], Loss: 1.5438\n",
      "Epoch [32/100], Step [12000/24597], Loss: 1.6487\n",
      "Epoch [32/100], Step [12100/24597], Loss: 1.7719\n",
      "Epoch [32/100], Step [12200/24597], Loss: 1.6426\n",
      "Epoch [32/100], Step [12300/24597], Loss: 1.8206\n",
      "Epoch [32/100], Step [12400/24597], Loss: 1.4685\n",
      "Epoch [32/100], Step [12500/24597], Loss: 1.8198\n",
      "Epoch [32/100], Step [12600/24597], Loss: 1.5669\n",
      "Epoch [32/100], Step [12700/24597], Loss: 1.7108\n",
      "Epoch [32/100], Step [12800/24597], Loss: 1.7170\n",
      "Epoch [32/100], Step [12900/24597], Loss: 1.5763\n",
      "Epoch [32/100], Step [13000/24597], Loss: 1.6546\n",
      "Epoch [32/100], Step [13100/24597], Loss: 1.6754\n",
      "Epoch [32/100], Step [13200/24597], Loss: 1.6320\n",
      "Epoch [32/100], Step [13300/24597], Loss: 1.2069\n",
      "Epoch [32/100], Step [13400/24597], Loss: 1.4584\n",
      "Epoch [32/100], Step [13500/24597], Loss: 1.6696\n",
      "Epoch [32/100], Step [13600/24597], Loss: 1.6961\n",
      "Epoch [32/100], Step [13700/24597], Loss: 1.7005\n",
      "Epoch [32/100], Step [13800/24597], Loss: 1.4775\n",
      "Epoch [32/100], Step [13900/24597], Loss: 1.6281\n",
      "Epoch [32/100], Step [14000/24597], Loss: 1.5684\n",
      "Epoch [32/100], Step [14100/24597], Loss: 1.7603\n",
      "Epoch [32/100], Step [14200/24597], Loss: 1.6583\n",
      "Epoch [32/100], Step [14300/24597], Loss: 1.6464\n",
      "Epoch [32/100], Step [14400/24597], Loss: 1.5585\n",
      "Epoch [32/100], Step [14500/24597], Loss: 1.6194\n",
      "Epoch [32/100], Step [14600/24597], Loss: 1.5367\n",
      "Epoch [32/100], Step [14700/24597], Loss: 1.5313\n",
      "Epoch [32/100], Step [14800/24597], Loss: 1.7224\n",
      "Epoch [32/100], Step [14900/24597], Loss: 1.3964\n",
      "Epoch [32/100], Step [15000/24597], Loss: 1.4702\n",
      "Epoch [32/100], Step [15100/24597], Loss: 1.8677\n",
      "Epoch [32/100], Step [15200/24597], Loss: 1.5166\n",
      "Epoch [32/100], Step [15300/24597], Loss: 1.7901\n",
      "Epoch [32/100], Step [15400/24597], Loss: 1.4944\n",
      "Epoch [32/100], Step [15500/24597], Loss: 1.7673\n",
      "Epoch [32/100], Step [15600/24597], Loss: 1.6396\n",
      "Epoch [32/100], Step [15700/24597], Loss: 1.6380\n",
      "Epoch [32/100], Step [15800/24597], Loss: 1.6211\n",
      "Epoch [32/100], Step [15900/24597], Loss: 1.5485\n",
      "Epoch [32/100], Step [16000/24597], Loss: 1.7442\n",
      "Epoch [32/100], Step [16100/24597], Loss: 1.8123\n",
      "Epoch [32/100], Step [16200/24597], Loss: 1.4994\n",
      "Epoch [32/100], Step [16300/24597], Loss: 1.5604\n",
      "Epoch [32/100], Step [16400/24597], Loss: 1.7627\n",
      "Epoch [32/100], Step [16500/24597], Loss: 1.5008\n",
      "Epoch [32/100], Step [16600/24597], Loss: 1.6791\n",
      "Epoch [32/100], Step [16700/24597], Loss: 1.6018\n",
      "Epoch [32/100], Step [16800/24597], Loss: 1.5584\n",
      "Epoch [32/100], Step [16900/24597], Loss: 1.6915\n",
      "Epoch [32/100], Step [17000/24597], Loss: 1.7283\n",
      "Epoch [32/100], Step [17100/24597], Loss: 1.4595\n",
      "Epoch [32/100], Step [17200/24597], Loss: 1.6607\n",
      "Epoch [32/100], Step [17300/24597], Loss: 1.7733\n",
      "Epoch [32/100], Step [17400/24597], Loss: 1.4931\n",
      "Epoch [32/100], Step [17500/24597], Loss: 1.5476\n",
      "Epoch [32/100], Step [17600/24597], Loss: 1.6723\n",
      "Epoch [32/100], Step [17700/24597], Loss: 1.7627\n",
      "Epoch [32/100], Step [17800/24597], Loss: 1.4683\n",
      "Epoch [32/100], Step [17900/24597], Loss: 1.8080\n",
      "Epoch [32/100], Step [18000/24597], Loss: 1.5465\n",
      "Epoch [32/100], Step [18100/24597], Loss: 1.6726\n",
      "Epoch [32/100], Step [18200/24597], Loss: 1.5751\n",
      "Epoch [32/100], Step [18300/24597], Loss: 1.6758\n",
      "Epoch [32/100], Step [18400/24597], Loss: 1.5173\n",
      "Epoch [32/100], Step [18500/24597], Loss: 1.6607\n",
      "Epoch [32/100], Step [18600/24597], Loss: 1.5437\n",
      "Epoch [32/100], Step [18700/24597], Loss: 1.7261\n",
      "Epoch [32/100], Step [18800/24597], Loss: 1.4978\n",
      "Epoch [32/100], Step [18900/24597], Loss: 1.6256\n",
      "Epoch [32/100], Step [19000/24597], Loss: 1.5208\n",
      "Epoch [32/100], Step [19100/24597], Loss: 1.5564\n",
      "Epoch [32/100], Step [19200/24597], Loss: 1.4598\n",
      "Epoch [32/100], Step [19300/24597], Loss: 1.4630\n",
      "Epoch [32/100], Step [19400/24597], Loss: 1.5964\n",
      "Epoch [32/100], Step [19500/24597], Loss: 1.7560\n",
      "Epoch [32/100], Step [19600/24597], Loss: 1.6187\n",
      "Epoch [32/100], Step [19700/24597], Loss: 1.6866\n",
      "Epoch [32/100], Step [19800/24597], Loss: 1.7258\n",
      "Epoch [32/100], Step [19900/24597], Loss: 1.5255\n",
      "Epoch [32/100], Step [20000/24597], Loss: 1.5550\n",
      "Epoch [32/100], Step [20100/24597], Loss: 1.7718\n",
      "Epoch [32/100], Step [20200/24597], Loss: 1.6139\n",
      "Epoch [32/100], Step [20300/24597], Loss: 1.4765\n",
      "Epoch [32/100], Step [20400/24597], Loss: 1.7034\n",
      "Epoch [32/100], Step [20500/24597], Loss: 1.6113\n",
      "Epoch [32/100], Step [20600/24597], Loss: 1.6998\n",
      "Epoch [32/100], Step [20700/24597], Loss: 1.9933\n",
      "Epoch [32/100], Step [20800/24597], Loss: 1.4797\n",
      "Epoch [32/100], Step [20900/24597], Loss: 1.7813\n",
      "Epoch [32/100], Step [21000/24597], Loss: 1.5451\n",
      "Epoch [32/100], Step [21100/24597], Loss: 1.7102\n",
      "Epoch [32/100], Step [21200/24597], Loss: 1.4066\n",
      "Epoch [32/100], Step [21300/24597], Loss: 1.6239\n",
      "Epoch [32/100], Step [21400/24597], Loss: 1.7102\n",
      "Epoch [32/100], Step [21500/24597], Loss: 1.6886\n",
      "Epoch [32/100], Step [21600/24597], Loss: 1.5479\n",
      "Epoch [32/100], Step [21700/24597], Loss: 1.5216\n",
      "Epoch [32/100], Step [21800/24597], Loss: 1.5597\n",
      "Epoch [32/100], Step [21900/24597], Loss: 1.4293\n",
      "Epoch [32/100], Step [22000/24597], Loss: 1.5139\n",
      "Epoch [32/100], Step [22100/24597], Loss: 1.7471\n",
      "Epoch [32/100], Step [22200/24597], Loss: 1.4728\n",
      "Epoch [32/100], Step [22300/24597], Loss: 1.4608\n",
      "Epoch [32/100], Step [22400/24597], Loss: 1.4971\n",
      "Epoch [32/100], Step [22500/24597], Loss: 1.6385\n",
      "Epoch [32/100], Step [22600/24597], Loss: 1.8386\n",
      "Epoch [32/100], Step [22700/24597], Loss: 1.5207\n",
      "Epoch [32/100], Step [22800/24597], Loss: 1.6955\n",
      "Epoch [32/100], Step [22900/24597], Loss: 1.4947\n",
      "Epoch [32/100], Step [23000/24597], Loss: 1.5711\n",
      "Epoch [32/100], Step [23100/24597], Loss: 1.8133\n",
      "Epoch [32/100], Step [23200/24597], Loss: 1.6818\n",
      "Epoch [32/100], Step [23300/24597], Loss: 1.5545\n",
      "Epoch [32/100], Step [23400/24597], Loss: 1.5075\n",
      "Epoch [32/100], Step [23500/24597], Loss: 1.5972\n",
      "Epoch [32/100], Step [23600/24597], Loss: 1.4797\n",
      "Epoch [32/100], Step [23700/24597], Loss: 1.7767\n",
      "Epoch [32/100], Step [23800/24597], Loss: 1.5615\n",
      "Epoch [32/100], Step [23900/24597], Loss: 1.5277\n",
      "Epoch [32/100], Step [24000/24597], Loss: 1.5081\n",
      "Epoch [32/100], Step [24100/24597], Loss: 1.8396\n",
      "Epoch [32/100], Step [24200/24597], Loss: 1.8617\n",
      "Epoch [32/100], Step [24300/24597], Loss: 1.6191\n",
      "Epoch [32/100], Step [24400/24597], Loss: 1.4995\n",
      "Epoch [32/100], Step [24500/24597], Loss: 1.6606\n",
      "Epoch [33/100], Step [100/24597], Loss: 1.6475\n",
      "Epoch [33/100], Step [200/24597], Loss: 1.4417\n",
      "Epoch [33/100], Step [300/24597], Loss: 1.6469\n",
      "Epoch [33/100], Step [400/24597], Loss: 1.6009\n",
      "Epoch [33/100], Step [500/24597], Loss: 1.6084\n",
      "Epoch [33/100], Step [600/24597], Loss: 1.6049\n",
      "Epoch [33/100], Step [700/24597], Loss: 1.2959\n",
      "Epoch [33/100], Step [800/24597], Loss: 1.8873\n",
      "Epoch [33/100], Step [900/24597], Loss: 1.7494\n",
      "Epoch [33/100], Step [1000/24597], Loss: 1.7391\n",
      "Epoch [33/100], Step [1100/24597], Loss: 1.8750\n",
      "Epoch [33/100], Step [1200/24597], Loss: 1.5104\n",
      "Epoch [33/100], Step [1300/24597], Loss: 1.5647\n",
      "Epoch [33/100], Step [1400/24597], Loss: 1.6244\n",
      "Epoch [33/100], Step [1500/24597], Loss: 1.4635\n",
      "Epoch [33/100], Step [1600/24597], Loss: 1.6752\n",
      "Epoch [33/100], Step [1700/24597], Loss: 1.6063\n",
      "Epoch [33/100], Step [1800/24597], Loss: 1.6037\n",
      "Epoch [33/100], Step [1900/24597], Loss: 1.4589\n",
      "Epoch [33/100], Step [2000/24597], Loss: 1.7480\n",
      "Epoch [33/100], Step [2100/24597], Loss: 1.6305\n",
      "Epoch [33/100], Step [2200/24597], Loss: 1.6705\n",
      "Epoch [33/100], Step [2300/24597], Loss: 1.4036\n",
      "Epoch [33/100], Step [2400/24597], Loss: 1.5468\n",
      "Epoch [33/100], Step [2500/24597], Loss: 1.7007\n",
      "Epoch [33/100], Step [2600/24597], Loss: 1.8297\n",
      "Epoch [33/100], Step [2700/24597], Loss: 1.4870\n",
      "Epoch [33/100], Step [2800/24597], Loss: 1.6351\n",
      "Epoch [33/100], Step [2900/24597], Loss: 1.5289\n",
      "Epoch [33/100], Step [3000/24597], Loss: 1.7943\n",
      "Epoch [33/100], Step [3100/24597], Loss: 1.6923\n",
      "Epoch [33/100], Step [3200/24597], Loss: 1.7013\n",
      "Epoch [33/100], Step [3300/24597], Loss: 1.5359\n",
      "Epoch [33/100], Step [3400/24597], Loss: 1.6194\n",
      "Epoch [33/100], Step [3500/24597], Loss: 1.6087\n",
      "Epoch [33/100], Step [3600/24597], Loss: 1.6199\n",
      "Epoch [33/100], Step [3700/24597], Loss: 1.7821\n",
      "Epoch [33/100], Step [3800/24597], Loss: 1.6093\n",
      "Epoch [33/100], Step [3900/24597], Loss: 1.6936\n",
      "Epoch [33/100], Step [4000/24597], Loss: 1.5692\n",
      "Epoch [33/100], Step [4100/24597], Loss: 1.3656\n",
      "Epoch [33/100], Step [4200/24597], Loss: 1.5413\n",
      "Epoch [33/100], Step [4300/24597], Loss: 1.6649\n",
      "Epoch [33/100], Step [4400/24597], Loss: 1.4090\n",
      "Epoch [33/100], Step [4500/24597], Loss: 1.6696\n",
      "Epoch [33/100], Step [4600/24597], Loss: 1.5191\n",
      "Epoch [33/100], Step [4700/24597], Loss: 1.6004\n",
      "Epoch [33/100], Step [4800/24597], Loss: 1.7454\n",
      "Epoch [33/100], Step [4900/24597], Loss: 1.8204\n",
      "Epoch [33/100], Step [5000/24597], Loss: 1.5937\n",
      "Epoch [33/100], Step [5100/24597], Loss: 1.5969\n",
      "Epoch [33/100], Step [5200/24597], Loss: 1.5483\n",
      "Epoch [33/100], Step [5300/24597], Loss: 1.6149\n",
      "Epoch [33/100], Step [5400/24597], Loss: 1.6283\n",
      "Epoch [33/100], Step [5500/24597], Loss: 1.6035\n",
      "Epoch [33/100], Step [5600/24597], Loss: 1.4339\n",
      "Epoch [33/100], Step [5700/24597], Loss: 1.4532\n",
      "Epoch [33/100], Step [5800/24597], Loss: 1.5566\n",
      "Epoch [33/100], Step [5900/24597], Loss: 1.7000\n",
      "Epoch [33/100], Step [6000/24597], Loss: 1.4672\n",
      "Epoch [33/100], Step [6100/24597], Loss: 1.6242\n",
      "Epoch [33/100], Step [6200/24597], Loss: 1.6342\n",
      "Epoch [33/100], Step [6300/24597], Loss: 1.3394\n",
      "Epoch [33/100], Step [6400/24597], Loss: 1.6469\n",
      "Epoch [33/100], Step [6500/24597], Loss: 1.6996\n",
      "Epoch [33/100], Step [6600/24597], Loss: 1.7134\n",
      "Epoch [33/100], Step [6700/24597], Loss: 1.6589\n",
      "Epoch [33/100], Step [6800/24597], Loss: 1.4530\n",
      "Epoch [33/100], Step [6900/24597], Loss: 1.7201\n",
      "Epoch [33/100], Step [7000/24597], Loss: 1.6002\n",
      "Epoch [33/100], Step [7100/24597], Loss: 1.5032\n",
      "Epoch [33/100], Step [7200/24597], Loss: 1.6975\n",
      "Epoch [33/100], Step [7300/24597], Loss: 1.5383\n",
      "Epoch [33/100], Step [7400/24597], Loss: 1.4285\n",
      "Epoch [33/100], Step [7500/24597], Loss: 1.6417\n",
      "Epoch [33/100], Step [7600/24597], Loss: 1.7336\n",
      "Epoch [33/100], Step [7700/24597], Loss: 1.7642\n",
      "Epoch [33/100], Step [7800/24597], Loss: 1.6579\n",
      "Epoch [33/100], Step [7900/24597], Loss: 1.5165\n",
      "Epoch [33/100], Step [8000/24597], Loss: 1.6253\n",
      "Epoch [33/100], Step [8100/24597], Loss: 1.4741\n",
      "Epoch [33/100], Step [8200/24597], Loss: 1.5919\n",
      "Epoch [33/100], Step [8300/24597], Loss: 1.7096\n",
      "Epoch [33/100], Step [8400/24597], Loss: 1.6781\n",
      "Epoch [33/100], Step [8500/24597], Loss: 1.6956\n",
      "Epoch [33/100], Step [8600/24597], Loss: 1.7922\n",
      "Epoch [33/100], Step [8700/24597], Loss: 1.7392\n",
      "Epoch [33/100], Step [8800/24597], Loss: 1.7021\n",
      "Epoch [33/100], Step [8900/24597], Loss: 1.1178\n",
      "Epoch [33/100], Step [9000/24597], Loss: 1.6038\n",
      "Epoch [33/100], Step [9100/24597], Loss: 1.7672\n",
      "Epoch [33/100], Step [9200/24597], Loss: 1.6789\n",
      "Epoch [33/100], Step [9300/24597], Loss: 1.5296\n",
      "Epoch [33/100], Step [9400/24597], Loss: 1.6358\n",
      "Epoch [33/100], Step [9500/24597], Loss: 1.7068\n",
      "Epoch [33/100], Step [9600/24597], Loss: 1.3926\n",
      "Epoch [33/100], Step [9700/24597], Loss: 1.6419\n",
      "Epoch [33/100], Step [9800/24597], Loss: 1.2916\n",
      "Epoch [33/100], Step [9900/24597], Loss: 1.6578\n",
      "Epoch [33/100], Step [10000/24597], Loss: 1.5397\n",
      "Epoch [33/100], Step [10100/24597], Loss: 1.5968\n",
      "Epoch [33/100], Step [10200/24597], Loss: 1.5581\n",
      "Epoch [33/100], Step [10300/24597], Loss: 1.6614\n",
      "Epoch [33/100], Step [10400/24597], Loss: 1.6369\n",
      "Epoch [33/100], Step [10500/24597], Loss: 1.8176\n",
      "Epoch [33/100], Step [10600/24597], Loss: 1.6536\n",
      "Epoch [33/100], Step [10700/24597], Loss: 1.7712\n",
      "Epoch [33/100], Step [10800/24597], Loss: 1.9351\n",
      "Epoch [33/100], Step [10900/24597], Loss: 1.5281\n",
      "Epoch [33/100], Step [11000/24597], Loss: 1.6978\n",
      "Epoch [33/100], Step [11100/24597], Loss: 1.7161\n",
      "Epoch [33/100], Step [11200/24597], Loss: 1.6127\n",
      "Epoch [33/100], Step [11300/24597], Loss: 1.4558\n",
      "Epoch [33/100], Step [11400/24597], Loss: 1.5040\n",
      "Epoch [33/100], Step [11500/24597], Loss: 1.5374\n",
      "Epoch [33/100], Step [11600/24597], Loss: 1.8533\n",
      "Epoch [33/100], Step [11700/24597], Loss: 1.8094\n",
      "Epoch [33/100], Step [11800/24597], Loss: 1.4710\n",
      "Epoch [33/100], Step [11900/24597], Loss: 1.4316\n",
      "Epoch [33/100], Step [12000/24597], Loss: 1.5460\n",
      "Epoch [33/100], Step [12100/24597], Loss: 1.5526\n",
      "Epoch [33/100], Step [12200/24597], Loss: 1.5953\n",
      "Epoch [33/100], Step [12300/24597], Loss: 1.7902\n",
      "Epoch [33/100], Step [12400/24597], Loss: 1.7502\n",
      "Epoch [33/100], Step [12500/24597], Loss: 1.7784\n",
      "Epoch [33/100], Step [12600/24597], Loss: 1.7532\n",
      "Epoch [33/100], Step [12700/24597], Loss: 1.6880\n",
      "Epoch [33/100], Step [12800/24597], Loss: 1.7659\n",
      "Epoch [33/100], Step [12900/24597], Loss: 1.5914\n",
      "Epoch [33/100], Step [13000/24597], Loss: 1.4369\n",
      "Epoch [33/100], Step [13100/24597], Loss: 1.6965\n",
      "Epoch [33/100], Step [13200/24597], Loss: 1.7591\n",
      "Epoch [33/100], Step [13300/24597], Loss: 1.5718\n",
      "Epoch [33/100], Step [13400/24597], Loss: 1.7456\n",
      "Epoch [33/100], Step [13500/24597], Loss: 1.5541\n",
      "Epoch [33/100], Step [13600/24597], Loss: 1.7152\n",
      "Epoch [33/100], Step [13700/24597], Loss: 1.6693\n",
      "Epoch [33/100], Step [13800/24597], Loss: 1.7215\n",
      "Epoch [33/100], Step [13900/24597], Loss: 1.3830\n",
      "Epoch [33/100], Step [14000/24597], Loss: 1.5102\n",
      "Epoch [33/100], Step [14100/24597], Loss: 1.6953\n",
      "Epoch [33/100], Step [14200/24597], Loss: 1.5847\n",
      "Epoch [33/100], Step [14300/24597], Loss: 1.6195\n",
      "Epoch [33/100], Step [14400/24597], Loss: 1.6803\n",
      "Epoch [33/100], Step [14500/24597], Loss: 1.5538\n",
      "Epoch [33/100], Step [14600/24597], Loss: 1.5007\n",
      "Epoch [33/100], Step [14700/24597], Loss: 1.5628\n",
      "Epoch [33/100], Step [14800/24597], Loss: 1.4662\n",
      "Epoch [33/100], Step [14900/24597], Loss: 1.5173\n",
      "Epoch [33/100], Step [15000/24597], Loss: 1.6095\n",
      "Epoch [33/100], Step [15100/24597], Loss: 1.5979\n",
      "Epoch [33/100], Step [15200/24597], Loss: 1.5311\n",
      "Epoch [33/100], Step [15300/24597], Loss: 1.7594\n",
      "Epoch [33/100], Step [15400/24597], Loss: 1.5060\n",
      "Epoch [33/100], Step [15500/24597], Loss: 1.5368\n",
      "Epoch [33/100], Step [15600/24597], Loss: 1.5995\n",
      "Epoch [33/100], Step [15700/24597], Loss: 1.3761\n",
      "Epoch [33/100], Step [15800/24597], Loss: 1.5314\n",
      "Epoch [33/100], Step [15900/24597], Loss: 1.5320\n",
      "Epoch [33/100], Step [16000/24597], Loss: 1.6323\n",
      "Epoch [33/100], Step [16100/24597], Loss: 1.4904\n",
      "Epoch [33/100], Step [16200/24597], Loss: 1.4533\n",
      "Epoch [33/100], Step [16300/24597], Loss: 1.6644\n",
      "Epoch [33/100], Step [16400/24597], Loss: 1.7801\n",
      "Epoch [33/100], Step [16500/24597], Loss: 1.5863\n",
      "Epoch [33/100], Step [16600/24597], Loss: 1.6379\n",
      "Epoch [33/100], Step [16700/24597], Loss: 1.6168\n",
      "Epoch [33/100], Step [16800/24597], Loss: 1.5983\n",
      "Epoch [33/100], Step [16900/24597], Loss: 1.6100\n",
      "Epoch [33/100], Step [17000/24597], Loss: 1.5635\n",
      "Epoch [33/100], Step [17100/24597], Loss: 1.2282\n",
      "Epoch [33/100], Step [17200/24597], Loss: 1.5444\n",
      "Epoch [33/100], Step [17300/24597], Loss: 1.8625\n",
      "Epoch [33/100], Step [17400/24597], Loss: 1.5296\n",
      "Epoch [33/100], Step [17500/24597], Loss: 1.5804\n",
      "Epoch [33/100], Step [17600/24597], Loss: 1.6016\n",
      "Epoch [33/100], Step [17700/24597], Loss: 1.7237\n",
      "Epoch [33/100], Step [17800/24597], Loss: 1.6388\n",
      "Epoch [33/100], Step [17900/24597], Loss: 1.6575\n",
      "Epoch [33/100], Step [18000/24597], Loss: 1.7801\n",
      "Epoch [33/100], Step [18100/24597], Loss: 1.6070\n",
      "Epoch [33/100], Step [18200/24597], Loss: 1.5833\n",
      "Epoch [33/100], Step [18300/24597], Loss: 1.6771\n",
      "Epoch [33/100], Step [18400/24597], Loss: 1.7063\n",
      "Epoch [33/100], Step [18500/24597], Loss: 1.4659\n",
      "Epoch [33/100], Step [18600/24597], Loss: 1.4136\n",
      "Epoch [33/100], Step [18700/24597], Loss: 1.5110\n",
      "Epoch [33/100], Step [18800/24597], Loss: 1.6969\n",
      "Epoch [33/100], Step [18900/24597], Loss: 1.6558\n",
      "Epoch [33/100], Step [19000/24597], Loss: 1.6984\n",
      "Epoch [33/100], Step [19100/24597], Loss: 1.6738\n",
      "Epoch [33/100], Step [19200/24597], Loss: 1.6051\n",
      "Epoch [33/100], Step [19300/24597], Loss: 1.6657\n",
      "Epoch [33/100], Step [19400/24597], Loss: 1.5311\n",
      "Epoch [33/100], Step [19500/24597], Loss: 1.4963\n",
      "Epoch [33/100], Step [19600/24597], Loss: 1.7445\n",
      "Epoch [33/100], Step [19700/24597], Loss: 1.4818\n",
      "Epoch [33/100], Step [19800/24597], Loss: 1.7164\n",
      "Epoch [33/100], Step [19900/24597], Loss: 1.5534\n",
      "Epoch [33/100], Step [20000/24597], Loss: 1.5922\n",
      "Epoch [33/100], Step [20100/24597], Loss: 1.4917\n",
      "Epoch [33/100], Step [20200/24597], Loss: 1.5955\n",
      "Epoch [33/100], Step [20300/24597], Loss: 1.7163\n",
      "Epoch [33/100], Step [20400/24597], Loss: 1.5484\n",
      "Epoch [33/100], Step [20500/24597], Loss: 1.6095\n",
      "Epoch [33/100], Step [20600/24597], Loss: 1.6199\n",
      "Epoch [33/100], Step [20700/24597], Loss: 1.6020\n",
      "Epoch [33/100], Step [20800/24597], Loss: 1.5587\n",
      "Epoch [33/100], Step [20900/24597], Loss: 1.6528\n",
      "Epoch [33/100], Step [21000/24597], Loss: 1.7500\n",
      "Epoch [33/100], Step [21100/24597], Loss: 1.6111\n",
      "Epoch [33/100], Step [21200/24597], Loss: 1.7259\n",
      "Epoch [33/100], Step [21300/24597], Loss: 1.4643\n",
      "Epoch [33/100], Step [21400/24597], Loss: 1.6036\n",
      "Epoch [33/100], Step [21500/24597], Loss: 1.5720\n",
      "Epoch [33/100], Step [21600/24597], Loss: 1.3893\n",
      "Epoch [33/100], Step [21700/24597], Loss: 1.7408\n",
      "Epoch [33/100], Step [21800/24597], Loss: 1.4425\n",
      "Epoch [33/100], Step [21900/24597], Loss: 1.4475\n",
      "Epoch [33/100], Step [22000/24597], Loss: 1.7194\n",
      "Epoch [33/100], Step [22100/24597], Loss: 1.7596\n",
      "Epoch [33/100], Step [22200/24597], Loss: 1.5984\n",
      "Epoch [33/100], Step [22300/24597], Loss: 1.5237\n",
      "Epoch [33/100], Step [22400/24597], Loss: 1.6780\n",
      "Epoch [33/100], Step [22500/24597], Loss: 1.4921\n",
      "Epoch [33/100], Step [22600/24597], Loss: 1.5239\n",
      "Epoch [33/100], Step [22700/24597], Loss: 1.6045\n",
      "Epoch [33/100], Step [22800/24597], Loss: 1.5443\n",
      "Epoch [33/100], Step [22900/24597], Loss: 1.4984\n",
      "Epoch [33/100], Step [23000/24597], Loss: 1.5848\n",
      "Epoch [33/100], Step [23100/24597], Loss: 1.3601\n",
      "Epoch [33/100], Step [23200/24597], Loss: 1.5111\n",
      "Epoch [33/100], Step [23300/24597], Loss: 1.6362\n",
      "Epoch [33/100], Step [23400/24597], Loss: 1.9953\n",
      "Epoch [33/100], Step [23500/24597], Loss: 1.8132\n",
      "Epoch [33/100], Step [23600/24597], Loss: 1.6962\n",
      "Epoch [33/100], Step [23700/24597], Loss: 1.3946\n",
      "Epoch [33/100], Step [23800/24597], Loss: 1.6349\n",
      "Epoch [33/100], Step [23900/24597], Loss: 1.4745\n",
      "Epoch [33/100], Step [24000/24597], Loss: 1.5130\n",
      "Epoch [33/100], Step [24100/24597], Loss: 1.6296\n",
      "Epoch [33/100], Step [24200/24597], Loss: 1.7536\n",
      "Epoch [33/100], Step [24300/24597], Loss: 1.6939\n",
      "Epoch [33/100], Step [24400/24597], Loss: 1.8703\n",
      "Epoch [33/100], Step [24500/24597], Loss: 1.6732\n",
      "Epoch [34/100], Step [100/24597], Loss: 1.4076\n",
      "Epoch [34/100], Step [200/24597], Loss: 1.8268\n",
      "Epoch [34/100], Step [300/24597], Loss: 1.5769\n",
      "Epoch [34/100], Step [400/24597], Loss: 1.8050\n",
      "Epoch [34/100], Step [500/24597], Loss: 1.7705\n",
      "Epoch [34/100], Step [600/24597], Loss: 1.6793\n",
      "Epoch [34/100], Step [700/24597], Loss: 1.4612\n",
      "Epoch [34/100], Step [800/24597], Loss: 1.6643\n",
      "Epoch [34/100], Step [900/24597], Loss: 1.6385\n",
      "Epoch [34/100], Step [1000/24597], Loss: 1.3716\n",
      "Epoch [34/100], Step [1100/24597], Loss: 1.4830\n",
      "Epoch [34/100], Step [1200/24597], Loss: 1.7381\n",
      "Epoch [34/100], Step [1300/24597], Loss: 1.5509\n",
      "Epoch [34/100], Step [1400/24597], Loss: 1.4139\n",
      "Epoch [34/100], Step [1500/24597], Loss: 1.6278\n",
      "Epoch [34/100], Step [1600/24597], Loss: 1.4504\n",
      "Epoch [34/100], Step [1700/24597], Loss: 1.5869\n",
      "Epoch [34/100], Step [1800/24597], Loss: 1.8245\n",
      "Epoch [34/100], Step [1900/24597], Loss: 1.6687\n",
      "Epoch [34/100], Step [2000/24597], Loss: 1.6951\n",
      "Epoch [34/100], Step [2100/24597], Loss: 1.7369\n",
      "Epoch [34/100], Step [2200/24597], Loss: 1.5544\n",
      "Epoch [34/100], Step [2300/24597], Loss: 1.5406\n",
      "Epoch [34/100], Step [2400/24597], Loss: 2.0018\n",
      "Epoch [34/100], Step [2500/24597], Loss: 1.5771\n",
      "Epoch [34/100], Step [2600/24597], Loss: 1.6586\n",
      "Epoch [34/100], Step [2700/24597], Loss: 1.4722\n",
      "Epoch [34/100], Step [2800/24597], Loss: 1.4605\n",
      "Epoch [34/100], Step [2900/24597], Loss: 1.7403\n",
      "Epoch [34/100], Step [3000/24597], Loss: 1.5457\n",
      "Epoch [34/100], Step [3100/24597], Loss: 1.7315\n",
      "Epoch [34/100], Step [3200/24597], Loss: 1.3946\n",
      "Epoch [34/100], Step [3300/24597], Loss: 1.6411\n",
      "Epoch [34/100], Step [3400/24597], Loss: 1.4253\n",
      "Epoch [34/100], Step [3500/24597], Loss: 1.9364\n",
      "Epoch [34/100], Step [3600/24597], Loss: 1.3298\n",
      "Epoch [34/100], Step [3700/24597], Loss: 1.4046\n",
      "Epoch [34/100], Step [3800/24597], Loss: 1.7561\n",
      "Epoch [34/100], Step [3900/24597], Loss: 1.4451\n",
      "Epoch [34/100], Step [4000/24597], Loss: 1.6199\n",
      "Epoch [34/100], Step [4100/24597], Loss: 1.5199\n",
      "Epoch [34/100], Step [4200/24597], Loss: 1.6903\n",
      "Epoch [34/100], Step [4300/24597], Loss: 1.5747\n",
      "Epoch [34/100], Step [4400/24597], Loss: 1.4274\n",
      "Epoch [34/100], Step [4500/24597], Loss: 1.6385\n",
      "Epoch [34/100], Step [4600/24597], Loss: 1.5697\n",
      "Epoch [34/100], Step [4700/24597], Loss: 1.5381\n",
      "Epoch [34/100], Step [4800/24597], Loss: 1.5742\n",
      "Epoch [34/100], Step [4900/24597], Loss: 1.4130\n",
      "Epoch [34/100], Step [5000/24597], Loss: 1.6180\n",
      "Epoch [34/100], Step [5100/24597], Loss: 1.4590\n",
      "Epoch [34/100], Step [5200/24597], Loss: 1.3891\n",
      "Epoch [34/100], Step [5300/24597], Loss: 1.6728\n",
      "Epoch [34/100], Step [5400/24597], Loss: 1.5829\n",
      "Epoch [34/100], Step [5500/24597], Loss: 1.7805\n",
      "Epoch [34/100], Step [5600/24597], Loss: 1.6747\n",
      "Epoch [34/100], Step [5700/24597], Loss: 1.6328\n",
      "Epoch [34/100], Step [5800/24597], Loss: 1.7061\n",
      "Epoch [34/100], Step [5900/24597], Loss: 1.4360\n",
      "Epoch [34/100], Step [6000/24597], Loss: 1.5761\n",
      "Epoch [34/100], Step [6100/24597], Loss: 1.7925\n",
      "Epoch [34/100], Step [6200/24597], Loss: 1.8558\n",
      "Epoch [34/100], Step [6300/24597], Loss: 1.5489\n",
      "Epoch [34/100], Step [6400/24597], Loss: 1.5776\n",
      "Epoch [34/100], Step [6500/24597], Loss: 1.6177\n",
      "Epoch [34/100], Step [6600/24597], Loss: 1.5258\n",
      "Epoch [34/100], Step [6700/24597], Loss: 1.6465\n",
      "Epoch [34/100], Step [6800/24597], Loss: 1.5673\n",
      "Epoch [34/100], Step [6900/24597], Loss: 1.4052\n",
      "Epoch [34/100], Step [7000/24597], Loss: 1.5525\n",
      "Epoch [34/100], Step [7100/24597], Loss: 1.7719\n",
      "Epoch [34/100], Step [7200/24597], Loss: 1.7550\n",
      "Epoch [34/100], Step [7300/24597], Loss: 1.4471\n",
      "Epoch [34/100], Step [7400/24597], Loss: 1.7785\n",
      "Epoch [34/100], Step [7500/24597], Loss: 1.3788\n",
      "Epoch [34/100], Step [7600/24597], Loss: 1.7509\n",
      "Epoch [34/100], Step [7700/24597], Loss: 1.6261\n",
      "Epoch [34/100], Step [7800/24597], Loss: 1.5774\n",
      "Epoch [34/100], Step [7900/24597], Loss: 1.8018\n",
      "Epoch [34/100], Step [8000/24597], Loss: 1.5784\n",
      "Epoch [34/100], Step [8100/24597], Loss: 1.4316\n",
      "Epoch [34/100], Step [8200/24597], Loss: 1.5791\n",
      "Epoch [34/100], Step [8300/24597], Loss: 1.3266\n",
      "Epoch [34/100], Step [8400/24597], Loss: 1.5191\n",
      "Epoch [34/100], Step [8500/24597], Loss: 1.6601\n",
      "Epoch [34/100], Step [8600/24597], Loss: 1.7848\n",
      "Epoch [34/100], Step [8700/24597], Loss: 1.5921\n",
      "Epoch [34/100], Step [8800/24597], Loss: 1.3801\n",
      "Epoch [34/100], Step [8900/24597], Loss: 1.5917\n",
      "Epoch [34/100], Step [9000/24597], Loss: 1.7986\n",
      "Epoch [34/100], Step [9100/24597], Loss: 1.6206\n",
      "Epoch [34/100], Step [9200/24597], Loss: 1.8186\n",
      "Epoch [34/100], Step [9300/24597], Loss: 1.6447\n",
      "Epoch [34/100], Step [9400/24597], Loss: 1.5812\n",
      "Epoch [34/100], Step [9500/24597], Loss: 1.8452\n",
      "Epoch [34/100], Step [9600/24597], Loss: 1.3724\n",
      "Epoch [34/100], Step [9700/24597], Loss: 1.8516\n",
      "Epoch [34/100], Step [9800/24597], Loss: 1.8390\n",
      "Epoch [34/100], Step [9900/24597], Loss: 1.6349\n",
      "Epoch [34/100], Step [10000/24597], Loss: 1.5752\n",
      "Epoch [34/100], Step [10100/24597], Loss: 1.6133\n",
      "Epoch [34/100], Step [10200/24597], Loss: 1.6028\n",
      "Epoch [34/100], Step [10300/24597], Loss: 1.6597\n",
      "Epoch [34/100], Step [10400/24597], Loss: 1.5805\n",
      "Epoch [34/100], Step [10500/24597], Loss: 1.6202\n",
      "Epoch [34/100], Step [10600/24597], Loss: 1.6607\n",
      "Epoch [34/100], Step [10700/24597], Loss: 1.6137\n",
      "Epoch [34/100], Step [10800/24597], Loss: 1.7126\n",
      "Epoch [34/100], Step [10900/24597], Loss: 1.7338\n",
      "Epoch [34/100], Step [11000/24597], Loss: 1.4909\n",
      "Epoch [34/100], Step [11100/24597], Loss: 2.0246\n",
      "Epoch [34/100], Step [11200/24597], Loss: 1.5699\n",
      "Epoch [34/100], Step [11300/24597], Loss: 1.5061\n",
      "Epoch [34/100], Step [11400/24597], Loss: 1.6784\n",
      "Epoch [34/100], Step [11500/24597], Loss: 1.5942\n",
      "Epoch [34/100], Step [11600/24597], Loss: 1.5197\n",
      "Epoch [34/100], Step [11700/24597], Loss: 1.6709\n",
      "Epoch [34/100], Step [11800/24597], Loss: 1.5117\n",
      "Epoch [34/100], Step [11900/24597], Loss: 1.5994\n",
      "Epoch [34/100], Step [12000/24597], Loss: 1.7193\n",
      "Epoch [34/100], Step [12100/24597], Loss: 1.8116\n",
      "Epoch [34/100], Step [12200/24597], Loss: 1.6591\n",
      "Epoch [34/100], Step [12300/24597], Loss: 1.4810\n",
      "Epoch [34/100], Step [12400/24597], Loss: 1.7838\n",
      "Epoch [34/100], Step [12500/24597], Loss: 1.7254\n",
      "Epoch [34/100], Step [12600/24597], Loss: 1.5090\n",
      "Epoch [34/100], Step [12700/24597], Loss: 1.6192\n",
      "Epoch [34/100], Step [12800/24597], Loss: 1.6550\n",
      "Epoch [34/100], Step [12900/24597], Loss: 1.4110\n",
      "Epoch [34/100], Step [13000/24597], Loss: 1.6784\n",
      "Epoch [34/100], Step [13100/24597], Loss: 1.6400\n",
      "Epoch [34/100], Step [13200/24597], Loss: 1.6600\n",
      "Epoch [34/100], Step [13300/24597], Loss: 1.4621\n",
      "Epoch [34/100], Step [13400/24597], Loss: 1.6426\n",
      "Epoch [34/100], Step [13500/24597], Loss: 1.4961\n",
      "Epoch [34/100], Step [13600/24597], Loss: 1.7789\n",
      "Epoch [34/100], Step [13700/24597], Loss: 1.5868\n",
      "Epoch [34/100], Step [13800/24597], Loss: 1.5413\n",
      "Epoch [34/100], Step [13900/24597], Loss: 1.6259\n",
      "Epoch [34/100], Step [14000/24597], Loss: 1.6858\n",
      "Epoch [34/100], Step [14100/24597], Loss: 1.6751\n",
      "Epoch [34/100], Step [14200/24597], Loss: 1.5516\n",
      "Epoch [34/100], Step [14300/24597], Loss: 1.7229\n",
      "Epoch [34/100], Step [14400/24597], Loss: 1.3678\n",
      "Epoch [34/100], Step [14500/24597], Loss: 1.6081\n",
      "Epoch [34/100], Step [14600/24597], Loss: 1.6592\n",
      "Epoch [34/100], Step [14700/24597], Loss: 1.7310\n",
      "Epoch [34/100], Step [14800/24597], Loss: 1.6204\n",
      "Epoch [34/100], Step [14900/24597], Loss: 1.5205\n",
      "Epoch [34/100], Step [15000/24597], Loss: 1.6458\n",
      "Epoch [34/100], Step [15100/24597], Loss: 1.5307\n",
      "Epoch [34/100], Step [15200/24597], Loss: 1.7476\n",
      "Epoch [34/100], Step [15300/24597], Loss: 1.6076\n",
      "Epoch [34/100], Step [15400/24597], Loss: 1.6054\n",
      "Epoch [34/100], Step [15500/24597], Loss: 1.4863\n",
      "Epoch [34/100], Step [15600/24597], Loss: 1.8506\n",
      "Epoch [34/100], Step [15700/24597], Loss: 1.6813\n",
      "Epoch [34/100], Step [15800/24597], Loss: 1.4559\n",
      "Epoch [34/100], Step [15900/24597], Loss: 1.5341\n",
      "Epoch [34/100], Step [16000/24597], Loss: 1.8679\n",
      "Epoch [34/100], Step [16100/24597], Loss: 1.5738\n",
      "Epoch [34/100], Step [16200/24597], Loss: 1.5708\n",
      "Epoch [34/100], Step [16300/24597], Loss: 1.5278\n",
      "Epoch [34/100], Step [16400/24597], Loss: 1.3369\n",
      "Epoch [34/100], Step [16500/24597], Loss: 1.6723\n",
      "Epoch [34/100], Step [16600/24597], Loss: 1.7105\n",
      "Epoch [34/100], Step [16700/24597], Loss: 1.5944\n",
      "Epoch [34/100], Step [16800/24597], Loss: 1.4131\n",
      "Epoch [34/100], Step [16900/24597], Loss: 1.6208\n",
      "Epoch [34/100], Step [17000/24597], Loss: 1.6652\n",
      "Epoch [34/100], Step [17100/24597], Loss: 1.8132\n",
      "Epoch [34/100], Step [17200/24597], Loss: 1.6379\n",
      "Epoch [34/100], Step [17300/24597], Loss: 1.4993\n",
      "Epoch [34/100], Step [17400/24597], Loss: 1.5589\n",
      "Epoch [34/100], Step [17500/24597], Loss: 1.5904\n",
      "Epoch [34/100], Step [17600/24597], Loss: 1.6062\n",
      "Epoch [34/100], Step [17700/24597], Loss: 1.7171\n",
      "Epoch [34/100], Step [17800/24597], Loss: 1.6740\n",
      "Epoch [34/100], Step [17900/24597], Loss: 1.7507\n",
      "Epoch [34/100], Step [18000/24597], Loss: 1.5248\n",
      "Epoch [34/100], Step [18100/24597], Loss: 1.8371\n",
      "Epoch [34/100], Step [18200/24597], Loss: 1.6824\n",
      "Epoch [34/100], Step [18300/24597], Loss: 1.8248\n",
      "Epoch [34/100], Step [18400/24597], Loss: 1.6288\n",
      "Epoch [34/100], Step [18500/24597], Loss: 1.5914\n",
      "Epoch [34/100], Step [18600/24597], Loss: 1.6549\n",
      "Epoch [34/100], Step [18700/24597], Loss: 1.7401\n",
      "Epoch [34/100], Step [18800/24597], Loss: 1.6614\n",
      "Epoch [34/100], Step [18900/24597], Loss: 1.7974\n",
      "Epoch [34/100], Step [19000/24597], Loss: 1.8479\n",
      "Epoch [34/100], Step [19100/24597], Loss: 1.5822\n",
      "Epoch [34/100], Step [19200/24597], Loss: 1.6066\n",
      "Epoch [34/100], Step [19300/24597], Loss: 1.5326\n",
      "Epoch [34/100], Step [19400/24597], Loss: 1.8876\n",
      "Epoch [34/100], Step [19500/24597], Loss: 1.6298\n",
      "Epoch [34/100], Step [19600/24597], Loss: 1.7816\n",
      "Epoch [34/100], Step [19700/24597], Loss: 1.6255\n",
      "Epoch [34/100], Step [19800/24597], Loss: 1.5418\n",
      "Epoch [34/100], Step [19900/24597], Loss: 1.4767\n",
      "Epoch [34/100], Step [20000/24597], Loss: 1.4530\n",
      "Epoch [34/100], Step [20100/24597], Loss: 1.6873\n",
      "Epoch [34/100], Step [20200/24597], Loss: 1.7853\n",
      "Epoch [34/100], Step [20300/24597], Loss: 1.3801\n",
      "Epoch [34/100], Step [20400/24597], Loss: 1.6797\n",
      "Epoch [34/100], Step [20500/24597], Loss: 1.5737\n",
      "Epoch [34/100], Step [20600/24597], Loss: 1.5662\n",
      "Epoch [34/100], Step [20700/24597], Loss: 1.6565\n",
      "Epoch [34/100], Step [20800/24597], Loss: 1.4300\n",
      "Epoch [34/100], Step [20900/24597], Loss: 1.6553\n",
      "Epoch [34/100], Step [21000/24597], Loss: 1.4738\n",
      "Epoch [34/100], Step [21100/24597], Loss: 1.5439\n",
      "Epoch [34/100], Step [21200/24597], Loss: 1.6280\n",
      "Epoch [34/100], Step [21300/24597], Loss: 1.6193\n",
      "Epoch [34/100], Step [21400/24597], Loss: 1.5696\n",
      "Epoch [34/100], Step [21500/24597], Loss: 1.7450\n",
      "Epoch [34/100], Step [21600/24597], Loss: 1.4234\n",
      "Epoch [34/100], Step [21700/24597], Loss: 1.6866\n",
      "Epoch [34/100], Step [21800/24597], Loss: 1.8134\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m num_epochs \u001b[39m=\u001b[39m \u001b[39m100\u001b[39m\n\u001b[1;32m      4\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(num_epochs):\n\u001b[0;32m----> 5\u001b[0m     \u001b[39mfor\u001b[39;00m i, (features, labels) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(dataloader):\n\u001b[1;32m      6\u001b[0m         features \u001b[39m=\u001b[39m features\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m      7\u001b[0m         labels \u001b[39m=\u001b[39m labels\u001b[39m.\u001b[39mto(device)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.2/lib/python3.11/site-packages/torch/utils/data/dataloader.py:634\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    631\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    632\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    633\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 634\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    635\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    636\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    637\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    638\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.2/lib/python3.11/site-packages/torch/utils/data/dataloader.py:678\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    676\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    677\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 678\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    679\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[1;32m    680\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.2/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[idx] \u001b[39mfor\u001b[39;49;00m idx \u001b[39min\u001b[39;49;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.2/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "Cell \u001b[0;32mIn[30], line 13\u001b[0m, in \u001b[0;36mCrimeDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[39mif\u001b[39;00m idx \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata):\n\u001b[1;32m     11\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mIndexError\u001b[39;00m\n\u001b[1;32m     12\u001b[0m features \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor(\n\u001b[0;32m---> 13\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdata\u001b[39m.\u001b[39;49mloc[idx, [\u001b[39m'\u001b[39;49m\u001b[39mTime\u001b[39;49m\u001b[39m'\u001b[39;49m,\u001b[39m'\u001b[39;49m\u001b[39mDay_of_Week\u001b[39;49m\u001b[39m'\u001b[39;49m,\u001b[39m'\u001b[39;49m\u001b[39mPart_of_Day\u001b[39;49m\u001b[39m'\u001b[39;49m,\u001b[39m'\u001b[39;49m\u001b[39mLatitude\u001b[39;49m\u001b[39m'\u001b[39;49m,\u001b[39m'\u001b[39;49m\u001b[39mLongitude\u001b[39;49m\u001b[39m'\u001b[39;49m]]\u001b[39m.\u001b[39mvalues, dtype\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mfloat\n\u001b[1;32m     14\u001b[0m )\n\u001b[1;32m     15\u001b[0m label \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mloc[idx, \u001b[39m'\u001b[39m\u001b[39mCategory\u001b[39m\u001b[39m'\u001b[39m], dtype\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mlong)\n\u001b[1;32m     16\u001b[0m \u001b[39mreturn\u001b[39;00m features, label\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.2/lib/python3.11/site-packages/pandas/core/indexing.py:1067\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1065\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_is_scalar_access(key):\n\u001b[1;32m   1066\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj\u001b[39m.\u001b[39m_get_value(\u001b[39m*\u001b[39mkey, takeable\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_takeable)\n\u001b[0;32m-> 1067\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_getitem_tuple(key)\n\u001b[1;32m   1068\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1069\u001b[0m     \u001b[39m# we by definition only have the 0th axis\u001b[39;00m\n\u001b[1;32m   1070\u001b[0m     axis \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maxis \u001b[39mor\u001b[39;00m \u001b[39m0\u001b[39m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.2/lib/python3.11/site-packages/pandas/core/indexing.py:1247\u001b[0m, in \u001b[0;36m_LocIndexer._getitem_tuple\u001b[0;34m(self, tup)\u001b[0m\n\u001b[1;32m   1245\u001b[0m \u001b[39mwith\u001b[39;00m suppress(IndexingError):\n\u001b[1;32m   1246\u001b[0m     tup \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_expand_ellipsis(tup)\n\u001b[0;32m-> 1247\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_getitem_lowerdim(tup)\n\u001b[1;32m   1249\u001b[0m \u001b[39m# no multi-index, so validate all of the indexers\u001b[39;00m\n\u001b[1;32m   1250\u001b[0m tup \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_tuple_indexer(tup)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.2/lib/python3.11/site-packages/pandas/core/indexing.py:967\u001b[0m, in \u001b[0;36m_LocationIndexer._getitem_lowerdim\u001b[0;34m(self, tup)\u001b[0m\n\u001b[1;32m    963\u001b[0m \u001b[39mfor\u001b[39;00m i, key \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(tup):\n\u001b[1;32m    964\u001b[0m     \u001b[39mif\u001b[39;00m is_label_like(key):\n\u001b[1;32m    965\u001b[0m         \u001b[39m# We don't need to check for tuples here because those are\u001b[39;00m\n\u001b[1;32m    966\u001b[0m         \u001b[39m#  caught by the _is_nested_tuple_indexer check above.\u001b[39;00m\n\u001b[0;32m--> 967\u001b[0m         section \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_getitem_axis(key, axis\u001b[39m=\u001b[39;49mi)\n\u001b[1;32m    969\u001b[0m         \u001b[39m# We should never have a scalar section here, because\u001b[39;00m\n\u001b[1;32m    970\u001b[0m         \u001b[39m#  _getitem_lowerdim is only called after a check for\u001b[39;00m\n\u001b[1;32m    971\u001b[0m         \u001b[39m#  is_scalar_access, which that would be.\u001b[39;00m\n\u001b[1;32m    972\u001b[0m         \u001b[39mif\u001b[39;00m section\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mndim:\n\u001b[1;32m    973\u001b[0m             \u001b[39m# we're in the middle of slicing through a MultiIndex\u001b[39;00m\n\u001b[1;32m    974\u001b[0m             \u001b[39m# revise the key wrt to `section` by inserting an _NS\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.2/lib/python3.11/site-packages/pandas/core/indexing.py:1312\u001b[0m, in \u001b[0;36m_LocIndexer._getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1310\u001b[0m \u001b[39m# fall thru to straight lookup\u001b[39;00m\n\u001b[1;32m   1311\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_key(key, axis)\n\u001b[0;32m-> 1312\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_label(key, axis\u001b[39m=\u001b[39;49maxis)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.2/lib/python3.11/site-packages/pandas/core/indexing.py:1260\u001b[0m, in \u001b[0;36m_LocIndexer._get_label\u001b[0;34m(self, label, axis)\u001b[0m\n\u001b[1;32m   1258\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_get_label\u001b[39m(\u001b[39mself\u001b[39m, label, axis: \u001b[39mint\u001b[39m):\n\u001b[1;32m   1259\u001b[0m     \u001b[39m# GH#5567 this will fail if the label is not present in the axis.\u001b[39;00m\n\u001b[0;32m-> 1260\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mobj\u001b[39m.\u001b[39;49mxs(label, axis\u001b[39m=\u001b[39;49maxis)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.2/lib/python3.11/site-packages/pandas/core/generic.py:4015\u001b[0m, in \u001b[0;36mNDFrame.xs\u001b[0;34m(self, key, axis, level, drop_level)\u001b[0m\n\u001b[1;32m   3916\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   3917\u001b[0m \u001b[39mReturn cross-section from the Series/DataFrame.\u001b[39;00m\n\u001b[1;32m   3918\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4012\u001b[0m \u001b[39mName: num_wings, dtype: int64\u001b[39;00m\n\u001b[1;32m   4013\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   4014\u001b[0m axis \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_axis_number(axis)\n\u001b[0;32m-> 4015\u001b[0m labels \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_axis(axis)\n\u001b[1;32m   4017\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(key, \u001b[39mlist\u001b[39m):\n\u001b[1;32m   4018\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m   4019\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mPassing lists as key for xs is deprecated and will be removed in a \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   4020\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mfuture version. Pass key as a tuple instead.\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   4021\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[1;32m   4022\u001b[0m         stacklevel\u001b[39m=\u001b[39mfind_stack_level(),\n\u001b[1;32m   4023\u001b[0m     )\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.2/lib/python3.11/site-packages/pandas/core/generic.py:564\u001b[0m, in \u001b[0;36mNDFrame._get_axis\u001b[0;34m(self, axis)\u001b[0m\n\u001b[1;32m    561\u001b[0m     axis_number \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m_get_axis_number(axis)\n\u001b[1;32m    562\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m_AXIS_ORDERS[axis_number]\n\u001b[0;32m--> 564\u001b[0m \u001b[39m@final\u001b[39m\n\u001b[1;32m    565\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_get_axis\u001b[39m(\u001b[39mself\u001b[39m, axis: Axis) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Index:\n\u001b[1;32m    566\u001b[0m     axis_number \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_axis_number(axis)\n\u001b[1;32m    567\u001b[0m     \u001b[39massert\u001b[39;00m axis_number \u001b[39min\u001b[39;00m {\u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m}\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "# Train the model\n",
    "num_epochs = 5\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (features, labels) in enumerate(dataloader):\n",
    "        features = features.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(features)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if (i + 1) % 100 == 0:\n",
    "            print(\n",
    "                f\"Epoch [{epoch + 1}/{num_epochs}], Step [{i + 1}/{len(dataloader)}], Loss: {loss.item():.4f}\"\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the model\n",
    "model.eval()\n",
    "all_labels = []\n",
    "all_predictions = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for features, labels in test_dataloader:\n",
    "        features = features.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = model(features)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "        all_predictions.extend(predicted.cpu().numpy())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained model\n",
    "torch.save(model.state_dict(), \"model.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[26914  1208 10607     0     0     0  3339]\n",
      " [11105  2670 10041     0     0     0  2270]\n",
      " [14641  1562 20876     0     0     0  2722]\n",
      " [ 3579   318  2338     0     0     0  1068]\n",
      " [ 9003   497  3165     0     0     0  1352]\n",
      " [ 1746   165   984     0     0     0   157]\n",
      " [10406   957  8723     0     0     0  5004]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.35      0.64      0.45     42068\n",
      "           1       0.36      0.10      0.16     26086\n",
      "           2       0.37      0.52      0.43     39801\n",
      "           3       0.00      0.00      0.00      7303\n",
      "           4       0.00      0.00      0.00     14017\n",
      "           5       0.00      0.00      0.00      3052\n",
      "           6       0.31      0.20      0.24     25090\n",
      "\n",
      "    accuracy                           0.35    157417\n",
      "   macro avg       0.20      0.21      0.18    157417\n",
      "weighted avg       0.30      0.35      0.30    157417\n",
      "\n",
      "Accuracy: 0.3523380575160243\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jerryliu/.pyenv/versions/3.11.2/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/jerryliu/.pyenv/versions/3.11.2/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/jerryliu/.pyenv/versions/3.11.2/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Calculate accuracy, confusion matrix, and classification report\n",
    "conf_matrix = confusion_matrix(all_labels, all_predictions)\n",
    "class_report = classification_report(all_labels, all_predictions)\n",
    "accuracy = accuracy_score(all_labels, all_predictions)\n",
    "\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix)\n",
    "print(\"Classification Report:\\n\", class_report)\n",
    "print(\"Accuracy:\", accuracy)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
